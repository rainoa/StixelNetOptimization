{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########now part 2: decode and train#######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10221797607208102258\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11273646900\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 950242212643483049\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/noa_raindel/.TFgpu/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.contrib.layers.python.layers import utils\n",
    "#from preprocess_func_new import *\n",
    "from matplotlib.image import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os.path import expanduser\n",
    "from sklearn import metrics\n",
    "import sys\n",
    "from skimage.transform import resize\n",
    "# from tensorflow.python import keras\n",
    "# from tensorflow.keras.applications.mobileNet import DepthwiseConv2D\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#tf.enable_eager_execution()\n",
    "\n",
    "#tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../datasets/stixels'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path = os.path.join('..','datasets','stixels')\n",
    "img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "percent=2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfrec_batch_size=1 #for path name only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../datasets/stixels/train/tfrec_batch_size_1_precent_2'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfrec_train_directory = os.path.join('..','datasets','stixels','train','tfrec_batch_size_'\n",
    "                                     +str(tfrec_batch_size)+'_precent_'+str(percent))\n",
    "#### note there is a misspelling \"precent\"\n",
    "tfrec_train_directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#creating a list of paths to train tfrecs:\n",
    "path_tfrecords_train_lst=[]\n",
    "path_tfrecords_train = os.path.join(img_path, 'train')\n",
    "for root, dirs, files in os.walk(tfrec_train_directory):\n",
    "    for file in files:\n",
    "        if '.tfrecord' in file:\n",
    "            path_tfrecords_train_lst.append(os.path.join(tfrec_train_directory,file))\n",
    "        else:\n",
    "            print('WARNING: file ' + file + 'looks suspicious. does it belong here?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#shortening the list for experiments\n",
    "path_tfrecords_train_lst = path_tfrecords_train_lst[:128]\n",
    "##################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#params\n",
    "H=370 \n",
    "W=24\n",
    "C=3\n",
    "img_shape = (H, W, C)\n",
    "num_classes = 47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(serialized):\n",
    "    # Define a dict with the data-names and types we expect to\n",
    "    # find in the TFRecords file.\n",
    "    # It is a bit awkward that this needs to be specified again,\n",
    "    # because it could have been written in the header of the\n",
    "    # TFRecords file instead.\n",
    "    features = \\\n",
    "        {\n",
    "            'image': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.int64)\n",
    "        }\n",
    "\n",
    "    # Parse the serialized data so we get a dict with our data.\n",
    "    parsed_example = tf.parse_single_example(serialized=serialized,\n",
    "                                             features=features)\n",
    "\n",
    "    # Get the image as raw bytes.\n",
    "    image_raw = parsed_example['image']\n",
    "\n",
    "    # Decode the raw bytes so it becomes a tensor with type.\n",
    "    #######image = tf.decode_raw(image_raw, tf.int32) ####\n",
    "    image = tf.image.decode_png(image_raw, channels=3, dtype=tf.uint8) \n",
    "    #image = tf.cast(image, tf.int32)\n",
    "\n",
    "    # The type is now uint8 but we need it to be float.\n",
    "    \n",
    "    image = tf.cast(image, tf.float32) ####\n",
    "    \n",
    "    # Get the label associated with the image.\n",
    "    label = parsed_example['label']\n",
    "    \n",
    "    \n",
    "    # The image and label are now correct TensorFlow types.\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########## a function to print tensor values\n",
    "def print_tensor(tensor):\n",
    "    dataset = tf.data.TFRecordDataset(filenames=[tensor])\n",
    "    dataset = dataset.map(parse)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    images_batch, labels_batch = iterator.get_next()\n",
    "    x = {'image': images_batch}\n",
    "    y = labels_batch\n",
    "    init_op = tf.initialize_all_variables()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "#         print (sess.run(y))\n",
    "        #print (sess.run(x))\n",
    "        #return(sess.run(x))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_fn(filenames, train, batch_size=batch_size, buffer_size=100000): \n",
    "    # Args:\n",
    "    # filenames:   Filenames for the TFRecords files.\n",
    "    # train:       Boolean whether training (True) or testing (False).\n",
    "    # batch_size:  Return batches of this size.\n",
    "    # buffer_size: Read buffers of this size. The random shuffling\n",
    "    #              is done on the buffer, so it must be big enough.\n",
    "\n",
    "    # Create a TensorFlow Dataset-object which has functionality\n",
    "    # for reading and shuffling data from TFRecords files.\n",
    "    dataset = tf.data.TFRecordDataset(filenames=filenames)\n",
    "\n",
    "    # Parse the serialized data in the TFRecords files.\n",
    "    # This returns TensorFlow tensors for the image and labels.\n",
    "    dataset = dataset.map(parse)\n",
    "    \n",
    "    if train:\n",
    "        # If training then read a buffer of the given size and\n",
    "        # randomly shuffle it.\n",
    "        ######dataset = dataset.shuffle(buffer_size=buffer_size)\n",
    "\n",
    "        # Allow infinite reading of the data.\n",
    "        num_repeat = None #-1\n",
    "    else:\n",
    "        # If testing then don't shuffle the data.\n",
    "        \n",
    "        # Only go through the data once.\n",
    "        num_repeat = 1\n",
    "\n",
    "    # Repeat the dataset the given number of times.\n",
    "    dataset = dataset.repeat(num_repeat)\n",
    "    \n",
    "    # Get a batch of data with the given size.\n",
    "    #dataset = dataset.batch(batch_size)\n",
    "    #dataset = tf.contrib.data.batch_and_drop_remainder(batch_size)\n",
    "    dataset = dataset.apply(tf.contrib.data.batch_and_drop_remainder(batch_size))\n",
    "    print('@@@')\n",
    "    print(dataset.output_shapes)  # ==> \"(16,)\" (the batch dimension is known)\n",
    "    print('@@@')\n",
    "    # Create an iterator for the dataset and the above modifications.\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "    # Get the next batch of images and labels.\n",
    "    images_batch, labels_batch = iterator.get_next()\n",
    "\n",
    "    # The input-function must return a dict wrapping the images.\n",
    "    x = {'image': images_batch}\n",
    "    y = labels_batch\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_input_fn():\n",
    "    return input_fn(filenames=path_tfrecords_train_lst, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the next four cells are a modification of https://github.com/xiaochus/MobileNetV2/blob/master/mobilenet_v2.py\n",
    "def _conv_block(inputs, filters, kernel, strides, is_training):\n",
    "    \"\"\"Convolution Block\n",
    "    This function defines a 2D convolution operation with BN and relu6.\n",
    "    # Arguments\n",
    "        inputs: Tensor, input tensor of conv layer.\n",
    "        filters: Integer, the dimensionality of the output space.\n",
    "        kernel: An integer or tuple/list of 2 integers, specifying the\n",
    "            width and height of the 2D convolution window.\n",
    "        strides: An integer or tuple/list of 2 integers,\n",
    "            specifying the strides of the convolution along the width and height.\n",
    "            Can be a single integer to specify the same value for\n",
    "            all spatial dimensions.\n",
    "    # Returns\n",
    "        Output tensor.\n",
    "    \"\"\"\n",
    "    x = tf.layers.conv2d(inputs=inputs, \n",
    "                         filters=filters, \n",
    "                         kernel_size=kernel,\n",
    "                         activation=None, \n",
    "                         strides=strides,\n",
    "                         kernel_initializer=tf.contrib.layers.xavier_initializer(seed=481),\n",
    "                         padding='same'\n",
    "                        )\n",
    "    \n",
    "    x = tf.layers.batch_normalization(inputs=x,\n",
    "                                      training=is_training\n",
    "                                     )\n",
    "    \n",
    "    x = tf.nn.relu6(features=x)\n",
    "       \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _bottleneck(inputs, filters, kernel, t, s, is_training, r=False):\n",
    "    \"\"\"Bottleneck\n",
    "    This function defines a basic bottleneck structure.\n",
    "    # Arguments\n",
    "        inputs: Tensor, input tensor of conv layer.\n",
    "        filters: Integer, the dimensionality of the output space.\n",
    "        kernel: An integer or tuple/list of 2 integers, specifying the\n",
    "            width and height of the 2D convolution window.\n",
    "        t: Integer, expansion factor.\n",
    "            t is always applied to the input size.\n",
    "        s: An integer or tuple/list of 2 integers,specifying the strides\n",
    "            of the convolution along the width and height.Can be a single\n",
    "            integer to specify the same value for all spatial dimensions.\n",
    "        r: Boolean, Whether to use the residuals.\n",
    "    # Returns\n",
    "        Output tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    num_filters_in = utils.last_dimension(inputs.get_shape(), min_rank=4)\n",
    "    \n",
    "    # \"Expension layer\" + BN + activation\n",
    "    x = _conv_block(inputs=inputs, \n",
    "                    filters=num_filters_in*t, \n",
    "                    kernel=(1, 1), \n",
    "                    strides=(1, 1), \n",
    "                    is_training=is_training)\n",
    "    \n",
    "    # Depthwise convolution + BN + activation\n",
    "    x = tf.contrib.layers.separable_conv2d(inputs=x,\n",
    "                                           num_outputs=None,\n",
    "                                           kernel_size=kernel,\n",
    "                                           depth_multiplier=1,\n",
    "                                           stride=(s,s),\n",
    "                                           padding='SAME',\n",
    "                                           activation_fn=tf.nn.relu6,\n",
    "                                           weights_initializer=tf.contrib.layers.xavier_initializer(seed=481),\n",
    "                                           normalizer_fn=None\n",
    "                                          )\n",
    "     \n",
    "    x = tf.layers.batch_normalization(inputs=x, \n",
    "                                      training=is_training\n",
    "                                     )\n",
    "    \n",
    "    x = tf.nn.relu6(features=x)\n",
    "    \n",
    "    # \"Projection\" layer + BN\n",
    "    x = tf.layers.conv2d(inputs=x,\n",
    "                         filters = filters,\n",
    "                         kernel_size = (1, 1),\n",
    "                         strides=(1, 1),\n",
    "                         padding='same',\n",
    "                         kernel_initializer=tf.contrib.layers.xavier_initializer(seed=481)\n",
    "                        )\n",
    "    x = tf.layers.batch_normalization(inputs=x,\n",
    "                                      training=is_training\n",
    "                                     )\n",
    "    \n",
    "    if r:\n",
    "        x = tf.add(x, inputs)\n",
    "        \n",
    "    '''\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "    tchannel = K.int_shape(inputs)[channel_axis] * t\n",
    "    x = _conv_block(inputs, tchannel, (1, 1), (1, 1))\n",
    "    x = DepthwiseConv2D(kernel, strides=(s, s), depth_multiplier=1, padding='same')(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation(relu6)(x)\n",
    "\n",
    "    x = Conv2D(filters, (1, 1), strides=(1, 1), padding='same')(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    '''\n",
    "    \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _inverted_residual_block(inputs, filters, kernel, t, strides, n, is_training):\n",
    "    \"\"\"Inverted Residual Block\n",
    "    This function defines a sequence of 1 or more identical layers.\n",
    "    # Arguments\n",
    "        inputs: Tensor, input tensor of conv layer.\n",
    "        filters: Integer, the dimensionality of the output space.\n",
    "        kernel: An integer or tuple/list of 2 integers, specifying the\n",
    "            width and height of the 2D convolution window.\n",
    "        t: Integer, expansion factor.\n",
    "            t is always applied to the input size.\n",
    "        s: An integer or tuple/list of 2 integers,specifying the strides\n",
    "            of the convolution along the width and height.Can be a single\n",
    "            integer to specify the same value for all spatial dimensions.\n",
    "        n: Integer, layer repeat times.\n",
    "    # Returns\n",
    "        Output tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    x = _bottleneck(inputs=inputs, \n",
    "                    filters=filters, \n",
    "                    kernel=kernel, \n",
    "                    t=t, \n",
    "                    s=strides, \n",
    "                    is_training=is_training\n",
    "                   )\n",
    "        \n",
    "    for i in range(1, n):\n",
    "        x = _bottleneck(inputs=x, \n",
    "                        filters=filters, \n",
    "                        kernel=kernel, \n",
    "                        t=t, \n",
    "                        s=1, \n",
    "                        is_training=is_training, \n",
    "                        r=True\n",
    "                       )\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MobileNetV2(inputs, k, is_training):\n",
    "    \"\"\"MobileNetV2\n",
    "    This function defines a MobileNetV2 architectures.\n",
    "    # Arguments\n",
    "        inputs: A tensor of the input of shape [-1,W,H,C].\n",
    "        k: Integer, number of classes.\n",
    "        is_training: boolean indication training or prediction\n",
    "    # Returns\n",
    "        MobileNetV2 model.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    x = _conv_block(inputs=inputs, filters=32, kernel=(3, 3), strides=(2, 2), is_training=is_training)\n",
    "        \n",
    "    x = _inverted_residual_block(inputs=x, filters=16,  kernel=(7, 3), t=1, strides=1, n=1, is_training=is_training)\n",
    "    x = _inverted_residual_block(inputs=x, filters=24,  kernel=(7, 3), t=6, strides=2, n=2, is_training=is_training)\n",
    "    x = _inverted_residual_block(inputs=x, filters=32,  kernel=(7, 3), t=6, strides=2, n=3, is_training=is_training)\n",
    "    x = _inverted_residual_block(inputs=x, filters=64,  kernel=(7, 3), t=6, strides=2, n=4, is_training=is_training)\n",
    "    x = _inverted_residual_block(inputs=x, filters=96,  kernel=(7, 3), t=6, strides=1, n=3, is_training=is_training)\n",
    "#     x = _inverted_residual_block(inputs=x, filters=160, kernel=(3, 3), t=6, strides=2, n=3, is_training=is_training)\n",
    "#     x = _inverted_residual_block(inputs=x, filters=320, kernel=(3, 3), t=6, strides=1, n=1, is_training=is_training)\n",
    "    \n",
    "    x = tf.layers.average_pooling2d(inputs=x, pool_size=(24,2), strides=(1,1))\n",
    "    \n",
    "    # Eventually this should be replaced with:\n",
    "    x = tf.layers.flatten(x)\n",
    "\n",
    "\n",
    "    # This is the last layer so it does not use an activation function.\n",
    "    x = tf.layers.dense(inputs=x, name='layer_fc6',\n",
    "                          units=k,\n",
    "                          kernel_initializer=tf.contrib.layers.xavier_initializer()\n",
    "                          ) \n",
    "    '''\n",
    "    x = _conv_block(inputs=x, filters=1280, kernel=(1, 1), strides=(1, 1), is_training=is_training)\n",
    "    x = tf.layers.average_pooling2d(inputs=x, pool_size=(2000,2000), strides=(1,1), padding='same')\n",
    "    x = tf.reshape(x, [-1,1,1,1280])\n",
    "    #x = tf.layers.dropout(inputs=x, rate=0.3, seed=481, training=is_training)\n",
    "    x = tf.layers.conv2d(inputs=x,\n",
    "                         filters = k,\n",
    "                         kernel_size = (1, 1),\n",
    "                         padding='same',\n",
    "                         kernel_initializer=tf.contrib.layers.xavier_initializer(seed=481)\n",
    "                        )\n",
    "    '''\n",
    "    '''\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Reshape((1, 1, 1280))(x)\n",
    "    x = Dropout(0.3, name='Dropout')(x)\n",
    "    x = Conv2D(k, (1, 1), padding='same')(x)\n",
    "    x = Activation('softmax', name='softmax')(x)\n",
    "    output = Reshape((k,))(x)\n",
    "    '''\n",
    "    \n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "    # Args:\n",
    "    #\n",
    "    # features: This is the x-arg from the input_fn.\n",
    "    # labels:   This is the y-arg from the input_fn.\n",
    "    # mode:     Either TRAIN, EVAL, or PREDICT\n",
    "    # params:   User-defined hyper-parameters, e.g. learning-rate.\n",
    "    \n",
    "   \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        is_training = True\n",
    "    else:\n",
    "        is_training = False\n",
    "    \n",
    "    # Reference to the tensor named \"image\" in the input-function.    \n",
    "    x = features[\"image\"]\n",
    "    # The convolutional layers expect 4-rank tensors\n",
    "    # but x is a 2-rank tensor, so reshape it.\n",
    "    inputs = tf.reshape(x, [-1,H,W,C])\n",
    "    \n",
    "    net = MobileNetV2(inputs=inputs, k=47, is_training=is_training)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Logits output of the neural network.\n",
    "    logits = net\n",
    "\n",
    "    # Softmax output of the neural network.\n",
    "    y_pred = tf.nn.softmax(logits=logits)\n",
    "    \n",
    "    # Classification output of the neural network.\n",
    "    y_pred_cls = tf.argmax(y_pred, axis=1) \n",
    "   \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        # If the estimator is supposed to be in prediction-mode\n",
    "        # then use the predicted class-number that is output by\n",
    "        # the neural network. Optimization etc. is not needed.\n",
    "        \n",
    "        spec = tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                          predictions=y_pred_cls)\n",
    "    else:\n",
    "        # Otherwise the estimator is supposed to be in either\n",
    "        # training or evaluation-mode. Note that the loss-function\n",
    "        # is also required in Evaluation mode.\n",
    "        \n",
    "        # Define the loss-function to be optimized, by first\n",
    "        # calculating the cross-entropy between the output of\n",
    "        # the neural network and the true labels for the input data.\n",
    "        # This gives the cross-entropy for each image in the batch.\n",
    "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels,\n",
    "                                                                       logits=logits)\n",
    "\n",
    "        # Reduce the cross-entropy batch-tensor to a single number\n",
    "        # which can be used in optimization of the neural network.\n",
    "        tf.argmax(logits)\n",
    "        #loss = tf.losses.mean_squared_error(labels=labels, predictions=logits)\n",
    "        loss = tf.reduce_mean(cross_entropy)\n",
    "#######################\n",
    "        lr = 1e-4\n",
    "        step_rate = 5000\n",
    "        decay = 0.7 #if this equals 1 the lr stays the same\n",
    "\n",
    "        #global_step = tf.Variable(0, trainable=False)\n",
    "        #increment_global_step = tf.assign(global_step, global_step + 1)\n",
    "\n",
    "        learning_rate = tf.train.exponential_decay(lr, global_step=tf.train.get_or_create_global_step(), \n",
    "                                           decay_steps=step_rate, decay_rate=decay, staircase=True)\n",
    "        \n",
    "        # Define the optimizer for improving the neural network.\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "#         optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate) \n",
    "        \n",
    "        ''' original\n",
    "        # Get the TensorFlow op for doing a single optimization step.\n",
    "        train_op = optimizer.minimize(loss=loss, global_step = tf.train.get_or_create_global_step())\n",
    "        '''\n",
    "        # for learning parameters of batch normalization:\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            train_op = optimizer.minimize(loss, global_step=tf.train.get_or_create_global_step())\n",
    "        \n",
    "        \n",
    "#############################        \n",
    "\n",
    "\n",
    "        # Define the evaluation metrics,\n",
    "        # in this case the classification accuracy.\n",
    "        metrics = \\\n",
    "        {\n",
    "            \"accuracy\": tf.metrics.accuracy(labels, y_pred_cls) #TODO change acc method\n",
    "        }\n",
    "\n",
    "        # Wrap all of this in an EstimatorSpec.\n",
    "        spec = tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            loss=loss,\n",
    "            train_op=train_op,\n",
    "            eval_metric_ops=metrics)\n",
    "\n",
    "\n",
    "        tf.summary.scalar(\"accuracy\", metrics[\"accuracy\"][1]) \n",
    "        merge_summary_op = tf.summary.merge_all()\n",
    "\n",
    "\n",
    "            \n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {} #{\"learning_rate\": 1e-5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_dir_and_comment(model_dir):\n",
    "    home = expanduser(\"~\")\n",
    "    log_name=os.path.join('logs/', model_dir + '.txt')\n",
    "    \n",
    "    if os.path.isdir(model_dir):\n",
    "        print('INFO: dir with name ' + model_dir + ' already exist.')\n",
    "    \n",
    "    new_comment=input('Please add a comment\\n')\n",
    "    \n",
    "    if os.path.exists(log_name):\n",
    "        append_write = 'a' # append if already exists\n",
    "    else:\n",
    "        append_write = 'w' # make a new file if not\n",
    "    \n",
    "    model_log = open(log_name,append_write)\n",
    "    model_log.write(home +' : '+ new_comment + '\\n')\n",
    "    model_log.close()\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: dir with name ./ckpts_30_5_mobilenetV2_47bins_03_swap_1 already exist.\n",
      "Please add a comment\n",
      "  .\n",
      "INFO:tensorflow:Using config: {'_master': '', '_num_worker_replicas': 1, '_num_ps_replicas': 0, '_save_summary_steps': 10, '_tf_random_seed': None, '_keep_checkpoint_max': 5, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0eea954dd8>, '_service': None, '_keep_checkpoint_every_n_hours': 10000, '_global_id_in_cluster': 0, '_save_checkpoints_secs': None, '_task_id': 0, '_is_chief': True, '_evaluation_master': '', '_session_config': None, '_save_checkpoints_steps': 1000, '_model_dir': './ckpts_30_5_mobilenetV2_47bins_03_swap_1', '_log_step_count_steps': 100, '_task_type': 'worker'}\n"
     ]
    }
   ],
   "source": [
    "model_dir = './ckpts_30_5_mobilenetV2_47bins_03_swap_1' #./ckpts_<day>_<month>_<architecture>_<main_change>'\n",
    "make_dir_and_comment(model_dir) \n",
    "# model = tf.estimator.Estimator(model_fn=model_fn,\n",
    "#                                params=params,\n",
    "#                                model_dir=model_dir)\n",
    "\n",
    "model = tf.estimator.Estimator(model_fn=model_fn,\n",
    "                               params=params,\n",
    "                               model_dir=model_dir,\n",
    "                               #config=tf.estimator.RunConfig(save_checkpoints_steps=1000, save_summary_steps=100)\n",
    "                               config=tf.estimator.RunConfig().replace(save_checkpoints_steps=1000,save_summary_steps=10)\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@\n",
      "(TensorShape([Dimension(64), Dimension(None), Dimension(None), Dimension(3)]), TensorShape([Dimension(64)]))\n",
      "@@@\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:loss = 4.3309174, step = 0\n",
      "INFO:tensorflow:global_step/sec: 3.45465\n",
      "INFO:tensorflow:loss = 3.8548107, step = 100 (28.948 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32832\n",
      "INFO:tensorflow:loss = 3.7545733, step = 200 (23.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31143\n",
      "INFO:tensorflow:loss = 3.6983666, step = 300 (23.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30606\n",
      "INFO:tensorflow:loss = 3.6275144, step = 400 (23.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31494\n",
      "INFO:tensorflow:loss = 3.5712523, step = 500 (23.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31027\n",
      "INFO:tensorflow:loss = 3.646501, step = 600 (23.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3182\n",
      "INFO:tensorflow:loss = 3.518549, step = 700 (23.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32611\n",
      "INFO:tensorflow:loss = 3.502111, step = 800 (23.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.28357\n",
      "INFO:tensorflow:loss = 3.4727278, step = 900 (23.344 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.07602\n",
      "INFO:tensorflow:loss = 3.5144694, step = 1000 (24.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.27836\n",
      "INFO:tensorflow:loss = 3.4074478, step = 1100 (23.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31454\n",
      "INFO:tensorflow:loss = 3.4487343, step = 1200 (23.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1386\n",
      "INFO:tensorflow:loss = 3.2948503, step = 1300 (87.827 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.714222\n",
      "INFO:tensorflow:loss = 3.1486626, step = 1400 (140.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.716009\n",
      "INFO:tensorflow:loss = 3.0115058, step = 1500 (139.663 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.740604\n",
      "INFO:tensorflow:loss = 2.8969433, step = 1600 (135.025 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.729737\n",
      "INFO:tensorflow:loss = 2.9580274, step = 1700 (137.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.737727\n",
      "INFO:tensorflow:loss = 2.6366122, step = 1800 (135.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.735791\n",
      "INFO:tensorflow:loss = 2.5967548, step = 1900 (135.908 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.730414\n",
      "INFO:tensorflow:loss = 2.618236, step = 2000 (136.908 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.738819\n",
      "INFO:tensorflow:loss = 2.522998, step = 2100 (135.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.72852\n",
      "INFO:tensorflow:loss = 2.614063, step = 2200 (137.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.723612\n",
      "INFO:tensorflow:loss = 2.4860616, step = 2300 (138.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.723392\n",
      "INFO:tensorflow:loss = 2.5792108, step = 2400 (138.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.7232\n",
      "INFO:tensorflow:loss = 2.2452984, step = 2500 (138.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.736926\n",
      "INFO:tensorflow:loss = 2.3421633, step = 2600 (135.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.733195\n",
      "INFO:tensorflow:loss = 1.9749784, step = 2700 (136.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.727552\n",
      "INFO:tensorflow:loss = 2.3201213, step = 2800 (137.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.721576\n",
      "INFO:tensorflow:loss = 2.36209, step = 2900 (138.586 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.724115\n",
      "INFO:tensorflow:loss = 2.2564607, step = 3000 (138.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.732475\n",
      "INFO:tensorflow:loss = 1.9607451, step = 3100 (136.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.724923\n",
      "INFO:tensorflow:loss = 2.3580828, step = 3200 (137.945 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.712127\n",
      "INFO:tensorflow:loss = 1.8943152, step = 3300 (140.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.706214\n",
      "INFO:tensorflow:loss = 2.319848, step = 3400 (141.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.70993\n",
      "INFO:tensorflow:loss = 2.227653, step = 3500 (140.858 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.712065\n",
      "INFO:tensorflow:loss = 1.9356518, step = 3600 (140.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.722124\n",
      "INFO:tensorflow:loss = 2.0864592, step = 3700 (138.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.723625\n",
      "INFO:tensorflow:loss = 2.016952, step = 3800 (138.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.742472\n",
      "INFO:tensorflow:loss = 2.0948641, step = 3900 (134.685 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.74709\n",
      "INFO:tensorflow:loss = 2.156364, step = 4000 (133.852 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.748039\n",
      "INFO:tensorflow:loss = 1.7132871, step = 4100 (133.683 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.725261\n",
      "INFO:tensorflow:loss = 2.1315715, step = 4200 (137.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.750253\n",
      "INFO:tensorflow:loss = 2.1923938, step = 4300 (133.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.721028\n",
      "INFO:tensorflow:loss = 1.9940981, step = 4400 (138.691 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.715445\n",
      "INFO:tensorflow:loss = 1.8281033, step = 4500 (139.773 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.690641\n",
      "INFO:tensorflow:loss = 2.0559273, step = 4600 (144.793 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.689483\n",
      "INFO:tensorflow:loss = 1.7830186, step = 4700 (145.037 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.690446\n",
      "INFO:tensorflow:loss = 1.7810324, step = 4800 (144.833 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.68238\n",
      "INFO:tensorflow:loss = 1.9196494, step = 4900 (146.546 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.66134\n",
      "INFO:tensorflow:loss = 1.7178893, step = 5000 (151.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.679132\n",
      "INFO:tensorflow:loss = 1.9465709, step = 5100 (147.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.675353\n",
      "INFO:tensorflow:loss = 1.7988999, step = 5200 (148.072 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.69809\n",
      "INFO:tensorflow:loss = 1.5464568, step = 5300 (143.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.699408\n",
      "INFO:tensorflow:loss = 1.9853696, step = 5400 (142.978 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.676543\n",
      "INFO:tensorflow:loss = 2.1489482, step = 5500 (147.810 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.684\n",
      "INFO:tensorflow:loss = 1.721438, step = 5600 (146.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.687931\n",
      "INFO:tensorflow:loss = 1.8621923, step = 5700 (145.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.674263\n",
      "INFO:tensorflow:loss = 1.588731, step = 5800 (148.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.674196\n",
      "INFO:tensorflow:loss = 1.727572, step = 5900 (148.325 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.671383\n",
      "INFO:tensorflow:loss = 1.8267317, step = 6000 (148.946 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.686446\n",
      "INFO:tensorflow:loss = 1.7332063, step = 6100 (145.678 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.686182\n",
      "INFO:tensorflow:loss = 1.8872616, step = 6200 (145.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.77634\n",
      "INFO:tensorflow:loss = 1.8424613, step = 6300 (56.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33542\n",
      "INFO:tensorflow:loss = 1.8088627, step = 6400 (23.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.34081\n",
      "INFO:tensorflow:loss = 1.6299933, step = 6500 (23.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33512\n",
      "INFO:tensorflow:loss = 1.7221969, step = 6600 (23.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.34471\n",
      "INFO:tensorflow:loss = 1.5731784, step = 6700 (23.017 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.35437\n",
      "INFO:tensorflow:loss = 1.8511477, step = 6800 (22.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3027\n",
      "INFO:tensorflow:loss = 1.608591, step = 6900 (23.240 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.05296\n",
      "INFO:tensorflow:loss = 1.7059321, step = 7000 (24.674 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31599\n",
      "INFO:tensorflow:loss = 1.9950199, step = 7100 (23.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3103\n",
      "INFO:tensorflow:loss = 1.7202957, step = 7200 (23.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30931\n",
      "INFO:tensorflow:loss = 1.6898715, step = 7300 (23.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32755\n",
      "INFO:tensorflow:loss = 1.9254576, step = 7400 (23.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.28266\n",
      "INFO:tensorflow:loss = 1.7009196, step = 7500 (23.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.2847\n",
      "INFO:tensorflow:loss = 1.5864079, step = 7600 (23.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31071\n",
      "INFO:tensorflow:loss = 1.7021441, step = 7700 (23.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30324\n",
      "INFO:tensorflow:loss = 1.7192261, step = 7800 (23.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3047\n",
      "INFO:tensorflow:loss = 1.6287516, step = 7900 (23.231 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.11034\n",
      "INFO:tensorflow:loss = 1.8607316, step = 8000 (24.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31262\n",
      "INFO:tensorflow:loss = 1.5859814, step = 8100 (23.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31052\n",
      "INFO:tensorflow:loss = 1.9434118, step = 8200 (23.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.34069\n",
      "INFO:tensorflow:loss = 1.8012869, step = 8300 (23.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.36527\n",
      "INFO:tensorflow:loss = 1.5210758, step = 8400 (22.909 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.34866\n",
      "INFO:tensorflow:loss = 1.7838974, step = 8500 (22.995 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32252\n",
      "INFO:tensorflow:loss = 1.5127845, step = 8600 (23.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30933\n",
      "INFO:tensorflow:loss = 1.8605874, step = 8700 (23.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30767\n",
      "INFO:tensorflow:loss = 1.6475886, step = 8800 (23.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29906\n",
      "INFO:tensorflow:loss = 1.830455, step = 8900 (23.261 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.0672\n",
      "INFO:tensorflow:loss = 1.7444811, step = 9000 (24.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32338\n",
      "INFO:tensorflow:loss = 1.83844, step = 9100 (23.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3338\n",
      "INFO:tensorflow:loss = 1.7116709, step = 9200 (23.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32544\n",
      "INFO:tensorflow:loss = 1.7678665, step = 9300 (23.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32717\n",
      "INFO:tensorflow:loss = 1.4188492, step = 9400 (23.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31572\n",
      "INFO:tensorflow:loss = 1.5116167, step = 9500 (23.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31273\n",
      "INFO:tensorflow:loss = 1.5169985, step = 9600 (23.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32641\n",
      "INFO:tensorflow:loss = 1.5726157, step = 9700 (23.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31137\n",
      "INFO:tensorflow:loss = 1.7564473, step = 9800 (23.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30389\n",
      "INFO:tensorflow:loss = 1.8455197, step = 9900 (23.235 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.08069\n",
      "INFO:tensorflow:loss = 1.5278448, step = 10000 (24.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30079\n",
      "INFO:tensorflow:loss = 1.8247786, step = 10100 (23.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30676\n",
      "INFO:tensorflow:loss = 1.8507926, step = 10200 (23.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30835\n",
      "INFO:tensorflow:loss = 1.6555198, step = 10300 (23.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32958\n",
      "INFO:tensorflow:loss = 1.7524648, step = 10400 (23.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30155\n",
      "INFO:tensorflow:loss = 1.4682182, step = 10500 (23.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33926\n",
      "INFO:tensorflow:loss = 1.8927723, step = 10600 (23.045 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.36774\n",
      "INFO:tensorflow:loss = 1.7607445, step = 10700 (22.895 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33903\n",
      "INFO:tensorflow:loss = 1.3889997, step = 10800 (23.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.2983\n",
      "INFO:tensorflow:loss = 1.5160415, step = 10900 (23.264 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.08254\n",
      "INFO:tensorflow:loss = 1.5280589, step = 11000 (24.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32671\n",
      "INFO:tensorflow:loss = 1.917171, step = 11100 (23.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32345\n",
      "INFO:tensorflow:loss = 1.5101509, step = 11200 (23.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30985\n",
      "INFO:tensorflow:loss = 1.4953601, step = 11300 (23.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.304\n",
      "INFO:tensorflow:loss = 1.9115782, step = 11400 (23.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30152\n",
      "INFO:tensorflow:loss = 1.8515643, step = 11500 (23.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31096\n",
      "INFO:tensorflow:loss = 1.8015623, step = 11600 (23.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31457\n",
      "INFO:tensorflow:loss = 1.5969331, step = 11700 (23.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31802\n",
      "INFO:tensorflow:loss = 1.7350944, step = 11800 (23.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30627\n",
      "INFO:tensorflow:loss = 1.5360792, step = 11900 (23.222 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.0526\n",
      "INFO:tensorflow:loss = 1.6495851, step = 12000 (24.675 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30118\n",
      "INFO:tensorflow:loss = 1.518969, step = 12100 (23.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30202\n",
      "INFO:tensorflow:loss = 1.8920226, step = 12200 (23.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30323\n",
      "INFO:tensorflow:loss = 1.7153044, step = 12300 (23.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30072\n",
      "INFO:tensorflow:loss = 1.641952, step = 12400 (23.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30679\n",
      "INFO:tensorflow:loss = 1.695528, step = 12500 (23.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31849\n",
      "INFO:tensorflow:loss = 1.5408553, step = 12600 (23.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31462\n",
      "INFO:tensorflow:loss = 1.7305368, step = 12700 (23.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32172\n",
      "INFO:tensorflow:loss = 1.5855999, step = 12800 (23.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31313\n",
      "INFO:tensorflow:loss = 1.5207493, step = 12900 (23.184 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.11639\n",
      "INFO:tensorflow:loss = 1.6807474, step = 13000 (24.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33778\n",
      "INFO:tensorflow:loss = 1.7159951, step = 13100 (23.054 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3368\n",
      "INFO:tensorflow:loss = 1.5863795, step = 13200 (23.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29999\n",
      "INFO:tensorflow:loss = 1.6898941, step = 13300 (23.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30394\n",
      "INFO:tensorflow:loss = 1.491179, step = 13400 (23.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30616\n",
      "INFO:tensorflow:loss = 1.5389409, step = 13500 (23.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32414\n",
      "INFO:tensorflow:loss = 1.5353956, step = 13600 (23.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32309\n",
      "INFO:tensorflow:loss = 1.8620529, step = 13700 (23.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32193\n",
      "INFO:tensorflow:loss = 1.5710621, step = 13800 (23.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32824\n",
      "INFO:tensorflow:loss = 1.7406578, step = 13900 (23.104 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.0262\n",
      "INFO:tensorflow:loss = 1.5930728, step = 14000 (24.837 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32356\n",
      "INFO:tensorflow:loss = 1.4507202, step = 14100 (23.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32\n",
      "INFO:tensorflow:loss = 1.6397868, step = 14200 (23.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31275\n",
      "INFO:tensorflow:loss = 1.7998598, step = 14300 (23.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32198\n",
      "INFO:tensorflow:loss = 1.7662518, step = 14400 (23.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32534\n",
      "INFO:tensorflow:loss = 1.7020757, step = 14500 (23.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32706\n",
      "INFO:tensorflow:loss = 1.5703318, step = 14600 (23.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31823\n",
      "INFO:tensorflow:loss = 1.6795619, step = 14700 (23.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31955\n",
      "INFO:tensorflow:loss = 1.5914922, step = 14800 (23.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32046\n",
      "INFO:tensorflow:loss = 1.667631, step = 14900 (23.145 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 15001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.07861\n",
      "INFO:tensorflow:loss = 1.3573139, step = 15000 (24.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32326\n",
      "INFO:tensorflow:loss = 1.4726573, step = 15100 (23.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33106\n",
      "INFO:tensorflow:loss = 1.6305072, step = 15200 (23.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32542\n",
      "INFO:tensorflow:loss = 1.6199031, step = 15300 (23.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32992\n",
      "INFO:tensorflow:loss = 1.5262592, step = 15400 (23.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33585\n",
      "INFO:tensorflow:loss = 1.6441978, step = 15500 (23.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.34762\n",
      "INFO:tensorflow:loss = 1.4725325, step = 15600 (23.000 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33449\n",
      "INFO:tensorflow:loss = 1.6324553, step = 15700 (23.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.35802\n",
      "INFO:tensorflow:loss = 1.5501435, step = 15800 (22.946 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33124\n",
      "INFO:tensorflow:loss = 1.5290282, step = 15900 (23.088 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.08007\n",
      "INFO:tensorflow:loss = 1.5120928, step = 16000 (24.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32575\n",
      "INFO:tensorflow:loss = 1.5758903, step = 16100 (23.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32276\n",
      "INFO:tensorflow:loss = 1.7513543, step = 16200 (23.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32805\n",
      "INFO:tensorflow:loss = 1.4294204, step = 16300 (23.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33416\n",
      "INFO:tensorflow:loss = 1.6101792, step = 16400 (23.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.2992\n",
      "INFO:tensorflow:loss = 1.5669651, step = 16500 (23.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.26135\n",
      "INFO:tensorflow:loss = 1.7114507, step = 16600 (23.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.26053\n",
      "INFO:tensorflow:loss = 1.4311104, step = 16700 (23.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.27301\n",
      "INFO:tensorflow:loss = 1.9881052, step = 16800 (23.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.28854\n",
      "INFO:tensorflow:loss = 1.5421609, step = 16900 (23.318 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 17001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.0756\n",
      "INFO:tensorflow:loss = 1.4555764, step = 17000 (24.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.27543\n",
      "INFO:tensorflow:loss = 1.5790548, step = 17100 (23.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.27264\n",
      "INFO:tensorflow:loss = 1.4171069, step = 17200 (23.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.28147\n",
      "INFO:tensorflow:loss = 1.7104214, step = 17300 (23.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.27347\n",
      "INFO:tensorflow:loss = 1.6519933, step = 17400 (23.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29517\n",
      "INFO:tensorflow:loss = 1.3835766, step = 17500 (23.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.27353\n",
      "INFO:tensorflow:loss = 1.4559621, step = 17600 (23.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.2846\n",
      "INFO:tensorflow:loss = 1.6070962, step = 17700 (23.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.28872\n",
      "INFO:tensorflow:loss = 1.5218639, step = 17800 (23.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.28377\n",
      "INFO:tensorflow:loss = 1.57505, step = 17900 (23.344 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.07374\n",
      "INFO:tensorflow:loss = 1.5535719, step = 18000 (24.547 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.35055\n",
      "INFO:tensorflow:loss = 1.6455431, step = 18100 (22.986 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3402\n",
      "INFO:tensorflow:loss = 1.737286, step = 18200 (23.040 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3324\n",
      "INFO:tensorflow:loss = 1.4019707, step = 18300 (23.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29708\n",
      "INFO:tensorflow:loss = 1.4377933, step = 18400 (23.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31818\n",
      "INFO:tensorflow:loss = 1.4050589, step = 18500 (23.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32373\n",
      "INFO:tensorflow:loss = 1.4326949, step = 18600 (23.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3311\n",
      "INFO:tensorflow:loss = 1.4928515, step = 18700 (23.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33116\n",
      "INFO:tensorflow:loss = 1.5817902, step = 18800 (23.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3378\n",
      "INFO:tensorflow:loss = 1.367775, step = 18900 (23.053 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 19001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.09519\n",
      "INFO:tensorflow:loss = 1.5336356, step = 19000 (24.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32899\n",
      "INFO:tensorflow:loss = 1.4257929, step = 19100 (23.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32136\n",
      "INFO:tensorflow:loss = 1.3685505, step = 19200 (23.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31531\n",
      "INFO:tensorflow:loss = 1.3867681, step = 19300 (23.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32232\n",
      "INFO:tensorflow:loss = 1.3401635, step = 19400 (23.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32064\n",
      "INFO:tensorflow:loss = 1.3488525, step = 19500 (23.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32928\n",
      "INFO:tensorflow:loss = 1.4803005, step = 19600 (23.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32824\n",
      "INFO:tensorflow:loss = 1.7100768, step = 19700 (23.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33301\n",
      "INFO:tensorflow:loss = 1.3380384, step = 19800 (23.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33678\n",
      "INFO:tensorflow:loss = 1.4788475, step = 19900 (23.058 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.09019\n",
      "INFO:tensorflow:loss = 1.6157379, step = 20000 (24.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.2988\n",
      "INFO:tensorflow:loss = 1.7362857, step = 20100 (23.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30621\n",
      "INFO:tensorflow:loss = 1.3357966, step = 20200 (23.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33873\n",
      "INFO:tensorflow:loss = 1.3093132, step = 20300 (23.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33531\n",
      "INFO:tensorflow:loss = 1.4448758, step = 20400 (23.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.34847\n",
      "INFO:tensorflow:loss = 1.5798854, step = 20500 (22.997 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29616\n",
      "INFO:tensorflow:loss = 1.3132014, step = 20600 (23.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32649\n",
      "INFO:tensorflow:loss = 1.4500742, step = 20700 (23.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30668\n",
      "INFO:tensorflow:loss = 1.7644541, step = 20800 (23.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30471\n",
      "INFO:tensorflow:loss = 1.3914217, step = 20900 (23.231 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 21001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.06515\n",
      "INFO:tensorflow:loss = 1.3367376, step = 21000 (24.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31731\n",
      "INFO:tensorflow:loss = 1.4594221, step = 21100 (23.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30686\n",
      "INFO:tensorflow:loss = 1.4909267, step = 21200 (23.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33952\n",
      "INFO:tensorflow:loss = 1.5192497, step = 21300 (23.045 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.34148\n",
      "INFO:tensorflow:loss = 1.3425877, step = 21400 (23.033 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33079\n",
      "INFO:tensorflow:loss = 1.5915043, step = 21500 (23.090 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33551\n",
      "INFO:tensorflow:loss = 1.3854625, step = 21600 (23.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33716\n",
      "INFO:tensorflow:loss = 1.3887405, step = 21700 (23.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3297\n",
      "INFO:tensorflow:loss = 1.3481549, step = 21800 (23.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33576\n",
      "INFO:tensorflow:loss = 1.5292974, step = 21900 (23.064 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 22001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.08864\n",
      "INFO:tensorflow:loss = 1.3901083, step = 22000 (24.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31633\n",
      "INFO:tensorflow:loss = 1.3648252, step = 22100 (23.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31236\n",
      "INFO:tensorflow:loss = 1.544835, step = 22200 (23.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32726\n",
      "INFO:tensorflow:loss = 1.4380395, step = 22300 (23.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32568\n",
      "INFO:tensorflow:loss = 1.4647663, step = 22400 (23.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33827\n",
      "INFO:tensorflow:loss = 1.3646324, step = 22500 (23.051 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.34179\n",
      "INFO:tensorflow:loss = 1.7697785, step = 22600 (23.031 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33786\n",
      "INFO:tensorflow:loss = 1.4861908, step = 22700 (23.053 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32993\n",
      "INFO:tensorflow:loss = 1.859302, step = 22800 (23.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3031\n",
      "INFO:tensorflow:loss = 1.1776814, step = 22900 (23.239 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 23001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.07261\n",
      "INFO:tensorflow:loss = 1.6636494, step = 23000 (24.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3232\n",
      "INFO:tensorflow:loss = 1.4255238, step = 23100 (23.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33041\n",
      "INFO:tensorflow:loss = 1.3772793, step = 23200 (23.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31915\n",
      "INFO:tensorflow:loss = 1.5477266, step = 23300 (23.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30886\n",
      "INFO:tensorflow:loss = 1.3992192, step = 23400 (23.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31031\n",
      "INFO:tensorflow:loss = 1.2248969, step = 23500 (23.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31524\n",
      "INFO:tensorflow:loss = 1.3917221, step = 23600 (23.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31063\n",
      "INFO:tensorflow:loss = 1.2677968, step = 23700 (23.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30603\n",
      "INFO:tensorflow:loss = 1.3792659, step = 23800 (23.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32228\n",
      "INFO:tensorflow:loss = 1.3994691, step = 23900 (23.136 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.0818\n",
      "INFO:tensorflow:loss = 1.3541553, step = 24000 (24.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32362\n",
      "INFO:tensorflow:loss = 1.2917705, step = 24100 (23.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32632\n",
      "INFO:tensorflow:loss = 1.2773954, step = 24200 (23.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30103\n",
      "INFO:tensorflow:loss = 1.3924518, step = 24300 (23.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31827\n",
      "INFO:tensorflow:loss = 1.3165755, step = 24400 (23.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32722\n",
      "INFO:tensorflow:loss = 1.591312, step = 24500 (23.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32012\n",
      "INFO:tensorflow:loss = 1.4565563, step = 24600 (23.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30429\n",
      "INFO:tensorflow:loss = 1.4208417, step = 24700 (23.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30438\n",
      "INFO:tensorflow:loss = 1.1927009, step = 24800 (23.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33423\n",
      "INFO:tensorflow:loss = 1.4538698, step = 24900 (23.066 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 25001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.12487\n",
      "INFO:tensorflow:loss = 1.3931117, step = 25000 (24.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.34979\n",
      "INFO:tensorflow:loss = 1.7540561, step = 25100 (22.990 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32205\n",
      "INFO:tensorflow:loss = 1.317922, step = 25200 (23.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31026\n",
      "INFO:tensorflow:loss = 1.2986186, step = 25300 (23.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33562\n",
      "INFO:tensorflow:loss = 1.4040134, step = 25400 (23.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31062\n",
      "INFO:tensorflow:loss = 1.4683862, step = 25500 (23.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32549\n",
      "INFO:tensorflow:loss = 1.5130959, step = 25600 (23.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32418\n",
      "INFO:tensorflow:loss = 1.3100358, step = 25700 (23.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31716\n",
      "INFO:tensorflow:loss = 1.452445, step = 25800 (23.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31556\n",
      "INFO:tensorflow:loss = 1.5764811, step = 25900 (23.172 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 26001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.08607\n",
      "INFO:tensorflow:loss = 1.2698112, step = 26000 (24.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3252\n",
      "INFO:tensorflow:loss = 1.5749761, step = 26100 (23.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29853\n",
      "INFO:tensorflow:loss = 1.5621212, step = 26200 (23.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30228\n",
      "INFO:tensorflow:loss = 1.5709233, step = 26300 (23.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30644\n",
      "INFO:tensorflow:loss = 1.403916, step = 26400 (23.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3048\n",
      "INFO:tensorflow:loss = 1.5748816, step = 26500 (23.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31631\n",
      "INFO:tensorflow:loss = 1.4614463, step = 26600 (23.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31338\n",
      "INFO:tensorflow:loss = 1.6474043, step = 26700 (23.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29628\n",
      "INFO:tensorflow:loss = 1.4394689, step = 26800 (23.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3225\n",
      "INFO:tensorflow:loss = 1.2787224, step = 26900 (23.135 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 27001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.07604\n",
      "INFO:tensorflow:loss = 1.3813916, step = 27000 (24.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32574\n",
      "INFO:tensorflow:loss = 1.3510934, step = 27100 (23.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32008\n",
      "INFO:tensorflow:loss = 1.4367853, step = 27200 (23.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.34446\n",
      "INFO:tensorflow:loss = 1.4298108, step = 27300 (23.018 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.36397\n",
      "INFO:tensorflow:loss = 1.5751675, step = 27400 (22.915 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.36432\n",
      "INFO:tensorflow:loss = 1.3311192, step = 27500 (22.914 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3364\n",
      "INFO:tensorflow:loss = 1.2190355, step = 27600 (23.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32892\n",
      "INFO:tensorflow:loss = 1.3571095, step = 27700 (23.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33234\n",
      "INFO:tensorflow:loss = 1.4119029, step = 27800 (23.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32166\n",
      "INFO:tensorflow:loss = 1.5880351, step = 27900 (23.140 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 28001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.07795\n",
      "INFO:tensorflow:loss = 1.5994359, step = 28000 (24.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33079\n",
      "INFO:tensorflow:loss = 1.4737508, step = 28100 (23.090 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30876\n",
      "INFO:tensorflow:loss = 1.1617117, step = 28200 (23.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33783\n",
      "INFO:tensorflow:loss = 1.5861253, step = 28300 (23.054 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31703\n",
      "INFO:tensorflow:loss = 1.3641424, step = 28400 (23.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29774\n",
      "INFO:tensorflow:loss = 1.5620501, step = 28500 (23.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32355\n",
      "INFO:tensorflow:loss = 1.444308, step = 28600 (23.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32194\n",
      "INFO:tensorflow:loss = 1.5300536, step = 28700 (23.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3249\n",
      "INFO:tensorflow:loss = 1.6322224, step = 28800 (23.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.311\n",
      "INFO:tensorflow:loss = 1.4317858, step = 28900 (23.197 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 29001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.07347\n",
      "INFO:tensorflow:loss = 1.7805622, step = 29000 (24.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33474\n",
      "INFO:tensorflow:loss = 1.5290892, step = 29100 (23.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.34065\n",
      "INFO:tensorflow:loss = 1.476042, step = 29200 (23.038 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33335\n",
      "INFO:tensorflow:loss = 1.5379304, step = 29300 (23.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33444\n",
      "INFO:tensorflow:loss = 1.418503, step = 29400 (23.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.34014\n",
      "INFO:tensorflow:loss = 1.3035213, step = 29500 (23.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30752\n",
      "INFO:tensorflow:loss = 1.37574, step = 29600 (23.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33638\n",
      "INFO:tensorflow:loss = 1.2965302, step = 29700 (23.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.36541\n",
      "INFO:tensorflow:loss = 1.5028512, step = 29800 (22.907 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.36906\n",
      "INFO:tensorflow:loss = 1.313863, step = 29900 (22.888 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 30001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.09933\n",
      "INFO:tensorflow:loss = 1.088881, step = 30000 (24.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33482\n",
      "INFO:tensorflow:loss = 1.6599674, step = 30100 (23.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33365\n",
      "INFO:tensorflow:loss = 1.2838483, step = 30200 (23.075 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3207\n",
      "INFO:tensorflow:loss = 1.4175605, step = 30300 (23.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30344\n",
      "INFO:tensorflow:loss = 1.3971117, step = 30400 (23.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.27786\n",
      "INFO:tensorflow:loss = 1.3799968, step = 30500 (23.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29385\n",
      "INFO:tensorflow:loss = 1.3636211, step = 30600 (23.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.27709\n",
      "INFO:tensorflow:loss = 1.3368369, step = 30700 (23.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31113\n",
      "INFO:tensorflow:loss = 1.2053111, step = 30800 (23.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.28557\n",
      "INFO:tensorflow:loss = 1.4223899, step = 30900 (23.334 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 31001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.07119\n",
      "INFO:tensorflow:loss = 1.3546672, step = 31000 (24.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29323\n",
      "INFO:tensorflow:loss = 1.5046616, step = 31100 (23.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3014\n",
      "INFO:tensorflow:loss = 1.2683132, step = 31200 (23.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31824\n",
      "INFO:tensorflow:loss = 1.3568312, step = 31300 (23.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31181\n",
      "INFO:tensorflow:loss = 1.3603554, step = 31400 (23.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32086\n",
      "INFO:tensorflow:loss = 1.6096168, step = 31500 (23.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29094\n",
      "INFO:tensorflow:loss = 1.3633714, step = 31600 (23.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30684\n",
      "INFO:tensorflow:loss = 1.4275846, step = 31700 (23.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29423\n",
      "INFO:tensorflow:loss = 1.1920342, step = 31800 (23.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30053\n",
      "INFO:tensorflow:loss = 1.2668885, step = 31900 (23.253 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 32001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.09894\n",
      "INFO:tensorflow:loss = 1.3152535, step = 32000 (24.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.36468\n",
      "INFO:tensorflow:loss = 1.4093523, step = 32100 (22.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.37291\n",
      "INFO:tensorflow:loss = 1.535304, step = 32200 (22.868 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.34298\n",
      "INFO:tensorflow:loss = 1.3046021, step = 32300 (23.026 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32279\n",
      "INFO:tensorflow:loss = 1.2519146, step = 32400 (23.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32687\n",
      "INFO:tensorflow:loss = 1.5967456, step = 32500 (23.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29897\n",
      "INFO:tensorflow:loss = 1.3323629, step = 32600 (23.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30985\n",
      "INFO:tensorflow:loss = 1.3286858, step = 32700 (23.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30932\n",
      "INFO:tensorflow:loss = 1.3052323, step = 32800 (23.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30487\n",
      "INFO:tensorflow:loss = 1.3774061, step = 32900 (23.230 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 33001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.08958\n",
      "INFO:tensorflow:loss = 1.298136, step = 33000 (24.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32212\n",
      "INFO:tensorflow:loss = 1.5897729, step = 33100 (23.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31244\n",
      "INFO:tensorflow:loss = 1.3907385, step = 33200 (23.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32289\n",
      "INFO:tensorflow:loss = 1.5377413, step = 33300 (23.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30804\n",
      "INFO:tensorflow:loss = 1.4869974, step = 33400 (23.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31513\n",
      "INFO:tensorflow:loss = 1.4170802, step = 33500 (23.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31843\n",
      "INFO:tensorflow:loss = 1.3815442, step = 33600 (23.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29387\n",
      "INFO:tensorflow:loss = 1.3602008, step = 33700 (23.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30209\n",
      "INFO:tensorflow:loss = 1.4587407, step = 33800 (23.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30736\n",
      "INFO:tensorflow:loss = 1.7170801, step = 33900 (23.216 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 34001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.05819\n",
      "INFO:tensorflow:loss = 1.414257, step = 34000 (24.641 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31683\n",
      "INFO:tensorflow:loss = 1.6050904, step = 34100 (23.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.35224\n",
      "INFO:tensorflow:loss = 1.5162956, step = 34200 (22.977 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3717\n",
      "INFO:tensorflow:loss = 1.3585585, step = 34300 (22.874 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.35576\n",
      "INFO:tensorflow:loss = 1.1080164, step = 34400 (22.959 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.35707\n",
      "INFO:tensorflow:loss = 1.3232812, step = 34500 (22.951 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33806\n",
      "INFO:tensorflow:loss = 1.656903, step = 34600 (23.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32305\n",
      "INFO:tensorflow:loss = 1.2861288, step = 34700 (23.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31174\n",
      "INFO:tensorflow:loss = 1.4370633, step = 34800 (23.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32805\n",
      "INFO:tensorflow:loss = 1.5491092, step = 34900 (23.105 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 35001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.08585\n",
      "INFO:tensorflow:loss = 1.4125332, step = 35000 (24.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32895\n",
      "INFO:tensorflow:loss = 1.4493783, step = 35100 (23.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31402\n",
      "INFO:tensorflow:loss = 1.0287988, step = 35200 (23.180 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31331\n",
      "INFO:tensorflow:loss = 1.2796412, step = 35300 (23.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30694\n",
      "INFO:tensorflow:loss = 1.4410536, step = 35400 (23.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32114\n",
      "INFO:tensorflow:loss = 1.5716562, step = 35500 (23.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33169\n",
      "INFO:tensorflow:loss = 1.3650547, step = 35600 (23.085 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32722\n",
      "INFO:tensorflow:loss = 1.2524827, step = 35700 (23.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33071\n",
      "INFO:tensorflow:loss = 1.2232854, step = 35800 (23.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3369\n",
      "INFO:tensorflow:loss = 1.4531206, step = 35900 (23.059 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 36001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.05236\n",
      "INFO:tensorflow:loss = 1.2768428, step = 36000 (24.676 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30287\n",
      "INFO:tensorflow:loss = 1.4567747, step = 36100 (23.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.2809\n",
      "INFO:tensorflow:loss = 1.354699, step = 36200 (23.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29013\n",
      "INFO:tensorflow:loss = 1.3244518, step = 36300 (23.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.2891\n",
      "INFO:tensorflow:loss = 1.34321, step = 36400 (23.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31079\n",
      "INFO:tensorflow:loss = 1.3345506, step = 36500 (23.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31316\n",
      "INFO:tensorflow:loss = 1.4396486, step = 36600 (23.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.34687\n",
      "INFO:tensorflow:loss = 1.3058187, step = 36700 (23.005 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.35097\n",
      "INFO:tensorflow:loss = 1.3747739, step = 36800 (22.983 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33336\n",
      "INFO:tensorflow:loss = 1.2504642, step = 36900 (23.077 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 37001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.06693\n",
      "INFO:tensorflow:loss = 1.3602756, step = 37000 (24.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29562\n",
      "INFO:tensorflow:loss = 1.4204575, step = 37100 (23.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32033\n",
      "INFO:tensorflow:loss = 1.2695651, step = 37200 (23.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32588\n",
      "INFO:tensorflow:loss = 1.5548241, step = 37300 (23.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3232\n",
      "INFO:tensorflow:loss = 1.204399, step = 37400 (23.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32635\n",
      "INFO:tensorflow:loss = 1.3032577, step = 37500 (23.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3278\n",
      "INFO:tensorflow:loss = 1.4189129, step = 37600 (23.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32731\n",
      "INFO:tensorflow:loss = 1.2870772, step = 37700 (23.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32079\n",
      "INFO:tensorflow:loss = 1.3927807, step = 37800 (23.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32405\n",
      "INFO:tensorflow:loss = 1.2587221, step = 37900 (23.127 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 38001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.07503\n",
      "INFO:tensorflow:loss = 1.3247244, step = 38000 (24.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31134\n",
      "INFO:tensorflow:loss = 1.359658, step = 38100 (23.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29984\n",
      "INFO:tensorflow:loss = 1.5222647, step = 38200 (23.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30575\n",
      "INFO:tensorflow:loss = 1.4043665, step = 38300 (23.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31035\n",
      "INFO:tensorflow:loss = 1.3544651, step = 38400 (23.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30961\n",
      "INFO:tensorflow:loss = 1.2376153, step = 38500 (23.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30616\n",
      "INFO:tensorflow:loss = 1.4336736, step = 38600 (23.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33272\n",
      "INFO:tensorflow:loss = 1.4614272, step = 38700 (23.081 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31359\n",
      "INFO:tensorflow:loss = 1.5486684, step = 38800 (23.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32857\n",
      "INFO:tensorflow:loss = 1.2441113, step = 38900 (23.102 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 39001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.11907\n",
      "INFO:tensorflow:loss = 1.4587877, step = 39000 (24.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3603\n",
      "INFO:tensorflow:loss = 1.2541634, step = 39100 (22.934 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32215\n",
      "INFO:tensorflow:loss = 1.1487348, step = 39200 (23.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33222\n",
      "INFO:tensorflow:loss = 1.3347142, step = 39300 (23.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32934\n",
      "INFO:tensorflow:loss = 1.2643545, step = 39400 (23.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32563\n",
      "INFO:tensorflow:loss = 1.2660465, step = 39500 (23.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31748\n",
      "INFO:tensorflow:loss = 1.37393, step = 39600 (23.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31306\n",
      "INFO:tensorflow:loss = 1.2415138, step = 39700 (23.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32336\n",
      "INFO:tensorflow:loss = 1.2831442, step = 39800 (23.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3298\n",
      "INFO:tensorflow:loss = 1.3565319, step = 39900 (23.095 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.07215\n",
      "INFO:tensorflow:loss = 1.579164, step = 40000 (24.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31691\n",
      "INFO:tensorflow:loss = 1.3344586, step = 40100 (23.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31669\n",
      "INFO:tensorflow:loss = 1.3376706, step = 40200 (23.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30956\n",
      "INFO:tensorflow:loss = 1.4493406, step = 40300 (23.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31716\n",
      "INFO:tensorflow:loss = 1.2036008, step = 40400 (23.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31098\n",
      "INFO:tensorflow:loss = 1.2789979, step = 40500 (23.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32347\n",
      "INFO:tensorflow:loss = 1.2533938, step = 40600 (23.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31183\n",
      "INFO:tensorflow:loss = 1.2013302, step = 40700 (23.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30657\n",
      "INFO:tensorflow:loss = 1.0718073, step = 40800 (23.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31721\n",
      "INFO:tensorflow:loss = 1.4505045, step = 40900 (23.162 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 41001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.07195\n",
      "INFO:tensorflow:loss = 1.1978492, step = 41000 (24.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3052\n",
      "INFO:tensorflow:loss = 1.465419, step = 41100 (23.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.36375\n",
      "INFO:tensorflow:loss = 1.3492297, step = 41200 (22.916 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.37053\n",
      "INFO:tensorflow:loss = 1.3455312, step = 41300 (22.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.34393\n",
      "INFO:tensorflow:loss = 1.1335979, step = 41400 (23.021 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31812\n",
      "INFO:tensorflow:loss = 1.4355202, step = 41500 (23.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31196\n",
      "INFO:tensorflow:loss = 1.2816603, step = 41600 (23.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30304\n",
      "INFO:tensorflow:loss = 1.2931532, step = 41700 (23.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31416\n",
      "INFO:tensorflow:loss = 1.3135715, step = 41800 (23.180 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31716\n",
      "INFO:tensorflow:loss = 1.4559846, step = 41900 (23.163 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 42001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.0699\n",
      "INFO:tensorflow:loss = 1.4631021, step = 42000 (24.571 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31177\n",
      "INFO:tensorflow:loss = 1.2982761, step = 42100 (23.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31224\n",
      "INFO:tensorflow:loss = 1.2877986, step = 42200 (23.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31117\n",
      "INFO:tensorflow:loss = 1.4065909, step = 42300 (23.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31305\n",
      "INFO:tensorflow:loss = 1.3499702, step = 42400 (23.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3079\n",
      "INFO:tensorflow:loss = 1.5770698, step = 42500 (23.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.2986\n",
      "INFO:tensorflow:loss = 1.255235, step = 42600 (23.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30291\n",
      "INFO:tensorflow:loss = 1.3885816, step = 42700 (23.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31151\n",
      "INFO:tensorflow:loss = 1.4863489, step = 42800 (23.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32673\n",
      "INFO:tensorflow:loss = 1.3315363, step = 42900 (23.112 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 43001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.07156\n",
      "INFO:tensorflow:loss = 1.3467604, step = 43000 (24.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32916\n",
      "INFO:tensorflow:loss = 1.2127844, step = 43100 (23.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3309\n",
      "INFO:tensorflow:loss = 1.3350799, step = 43200 (23.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3469\n",
      "INFO:tensorflow:loss = 1.3828189, step = 43300 (23.005 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.36055\n",
      "INFO:tensorflow:loss = 1.127715, step = 43400 (22.933 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.36474\n",
      "INFO:tensorflow:loss = 1.2583094, step = 43500 (22.910 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32953\n",
      "INFO:tensorflow:loss = 1.5558443, step = 43600 (23.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32002\n",
      "INFO:tensorflow:loss = 1.3063271, step = 43700 (23.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32602\n",
      "INFO:tensorflow:loss = 1.2154183, step = 43800 (23.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33014\n",
      "INFO:tensorflow:loss = 1.4698837, step = 43900 (23.095 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 44001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.07711\n",
      "INFO:tensorflow:loss = 1.5992161, step = 44000 (24.527 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32878\n",
      "INFO:tensorflow:loss = 1.441952, step = 44100 (23.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32228\n",
      "INFO:tensorflow:loss = 1.5438493, step = 44200 (23.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3123\n",
      "INFO:tensorflow:loss = 1.3555202, step = 44300 (23.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29975\n",
      "INFO:tensorflow:loss = 0.9922984, step = 44400 (23.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.331\n",
      "INFO:tensorflow:loss = 1.2499485, step = 44500 (23.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33243\n",
      "INFO:tensorflow:loss = 1.1499839, step = 44600 (23.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32844\n",
      "INFO:tensorflow:loss = 1.3846111, step = 44700 (23.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32514\n",
      "INFO:tensorflow:loss = 1.3244996, step = 44800 (23.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32595\n",
      "INFO:tensorflow:loss = 1.1895876, step = 44900 (23.116 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 45001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.07886\n",
      "INFO:tensorflow:loss = 1.4846152, step = 45000 (24.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31375\n",
      "INFO:tensorflow:loss = 1.2206976, step = 45100 (23.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31385\n",
      "INFO:tensorflow:loss = 1.1794274, step = 45200 (23.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.25827\n",
      "INFO:tensorflow:loss = 1.2897598, step = 45300 (23.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29366\n",
      "INFO:tensorflow:loss = 1.2189194, step = 45400 (23.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.27341\n",
      "INFO:tensorflow:loss = 1.5036097, step = 45500 (23.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32664\n",
      "INFO:tensorflow:loss = 1.1776255, step = 45600 (23.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32929\n",
      "INFO:tensorflow:loss = 1.1613402, step = 45700 (23.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33463\n",
      "INFO:tensorflow:loss = 1.2104917, step = 45800 (23.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30652\n",
      "INFO:tensorflow:loss = 1.2144206, step = 45900 (23.220 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 46001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.07934\n",
      "INFO:tensorflow:loss = 1.4273145, step = 46000 (24.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30303\n",
      "INFO:tensorflow:loss = 1.2177571, step = 46100 (23.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29322\n",
      "INFO:tensorflow:loss = 1.5420713, step = 46200 (23.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.27778\n",
      "INFO:tensorflow:loss = 1.6189337, step = 46300 (23.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29724\n",
      "INFO:tensorflow:loss = 1.421635, step = 46400 (23.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29987\n",
      "INFO:tensorflow:loss = 1.4260664, step = 46500 (23.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.28659\n",
      "INFO:tensorflow:loss = 1.5319047, step = 46600 (23.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3072\n",
      "INFO:tensorflow:loss = 1.2497393, step = 46700 (23.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30674\n",
      "INFO:tensorflow:loss = 1.2831506, step = 46800 (23.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31588\n",
      "INFO:tensorflow:loss = 1.4080136, step = 46900 (23.170 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 47001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.10461\n",
      "INFO:tensorflow:loss = 1.2177631, step = 47000 (24.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32248\n",
      "INFO:tensorflow:loss = 1.2738986, step = 47100 (23.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31509\n",
      "INFO:tensorflow:loss = 1.211409, step = 47200 (23.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33074\n",
      "INFO:tensorflow:loss = 1.5056989, step = 47300 (23.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31934\n",
      "INFO:tensorflow:loss = 1.2258581, step = 47400 (23.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32884\n",
      "INFO:tensorflow:loss = 1.3632325, step = 47500 (23.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.34344\n",
      "INFO:tensorflow:loss = 1.2972255, step = 47600 (23.024 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3083\n",
      "INFO:tensorflow:loss = 1.3299505, step = 47700 (23.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30032\n",
      "INFO:tensorflow:loss = 1.4054404, step = 47800 (23.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31214\n",
      "INFO:tensorflow:loss = 1.2371557, step = 47900 (23.190 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 48001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.06635\n",
      "INFO:tensorflow:loss = 1.2386612, step = 48000 (24.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33013\n",
      "INFO:tensorflow:loss = 1.4332747, step = 48100 (23.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30917\n",
      "INFO:tensorflow:loss = 1.2944014, step = 48200 (23.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29306\n",
      "INFO:tensorflow:loss = 1.3266729, step = 48300 (23.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30324\n",
      "INFO:tensorflow:loss = 1.2613744, step = 48400 (23.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31966\n",
      "INFO:tensorflow:loss = 1.3712906, step = 48500 (23.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32458\n",
      "INFO:tensorflow:loss = 1.3343496, step = 48600 (23.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31506\n",
      "INFO:tensorflow:loss = 1.1460335, step = 48700 (23.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31852\n",
      "INFO:tensorflow:loss = 1.5747102, step = 48800 (23.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3072\n",
      "INFO:tensorflow:loss = 1.3041637, step = 48900 (23.216 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 49001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.09628\n",
      "INFO:tensorflow:loss = 1.11906, step = 49000 (24.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30661\n",
      "INFO:tensorflow:loss = 1.2321419, step = 49100 (23.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.28965\n",
      "INFO:tensorflow:loss = 1.5144262, step = 49200 (23.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30185\n",
      "INFO:tensorflow:loss = 1.2529216, step = 49300 (23.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32427\n",
      "INFO:tensorflow:loss = 1.2004411, step = 49400 (23.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33321\n",
      "INFO:tensorflow:loss = 1.1946418, step = 49500 (23.078 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33379\n",
      "INFO:tensorflow:loss = 1.3663131, step = 49600 (23.075 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32669\n",
      "INFO:tensorflow:loss = 1.4523478, step = 49700 (23.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32779\n",
      "INFO:tensorflow:loss = 1.2743156, step = 49800 (23.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32517\n",
      "INFO:tensorflow:loss = 1.178566, step = 49900 (23.120 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 50001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.08633\n",
      "INFO:tensorflow:loss = 1.2036018, step = 50000 (24.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32582\n",
      "INFO:tensorflow:loss = 1.2802459, step = 50100 (23.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33982\n",
      "INFO:tensorflow:loss = 1.2393521, step = 50200 (23.042 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33689\n",
      "INFO:tensorflow:loss = 1.2789202, step = 50300 (23.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3357\n",
      "INFO:tensorflow:loss = 1.4605901, step = 50400 (23.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33409\n",
      "INFO:tensorflow:loss = 1.1544962, step = 50500 (23.072 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31658\n",
      "INFO:tensorflow:loss = 1.323885, step = 50600 (23.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3253\n",
      "INFO:tensorflow:loss = 1.2713141, step = 50700 (23.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33315\n",
      "INFO:tensorflow:loss = 1.2400665, step = 50800 (23.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33739\n",
      "INFO:tensorflow:loss = 1.1460814, step = 50900 (23.056 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 51001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.10407\n",
      "INFO:tensorflow:loss = 1.3048966, step = 51000 (24.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30187\n",
      "INFO:tensorflow:loss = 1.2962303, step = 51100 (23.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30137\n",
      "INFO:tensorflow:loss = 1.1583534, step = 51200 (23.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30617\n",
      "INFO:tensorflow:loss = 1.3479528, step = 51300 (23.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.34049\n",
      "INFO:tensorflow:loss = 1.3061128, step = 51400 (23.039 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30769\n",
      "INFO:tensorflow:loss = 1.3749833, step = 51500 (23.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29968\n",
      "INFO:tensorflow:loss = 1.43254, step = 51600 (23.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32173\n",
      "INFO:tensorflow:loss = 1.4981885, step = 51700 (23.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29506\n",
      "INFO:tensorflow:loss = 1.301935, step = 51800 (23.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.292\n",
      "INFO:tensorflow:loss = 1.3431449, step = 51900 (23.299 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 52001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.07682\n",
      "INFO:tensorflow:loss = 1.5813439, step = 52000 (24.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29256\n",
      "INFO:tensorflow:loss = 1.301001, step = 52100 (23.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31988\n",
      "INFO:tensorflow:loss = 1.188534, step = 52200 (23.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.34669\n",
      "INFO:tensorflow:loss = 1.2871432, step = 52300 (23.006 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.343\n",
      "INFO:tensorflow:loss = 1.0312493, step = 52400 (23.026 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.34031\n",
      "INFO:tensorflow:loss = 1.3769662, step = 52500 (23.040 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3383\n",
      "INFO:tensorflow:loss = 1.1794206, step = 52600 (23.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32491\n",
      "INFO:tensorflow:loss = 1.2943287, step = 52700 (23.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32889\n",
      "INFO:tensorflow:loss = 1.5077376, step = 52800 (23.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33829\n",
      "INFO:tensorflow:loss = 1.442347, step = 52900 (23.051 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 53001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.10102\n",
      "INFO:tensorflow:loss = 1.3511986, step = 53000 (24.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33797\n",
      "INFO:tensorflow:loss = 1.060381, step = 53100 (23.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33376\n",
      "INFO:tensorflow:loss = 1.2802341, step = 53200 (23.075 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33351\n",
      "INFO:tensorflow:loss = 1.3301105, step = 53300 (23.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33145\n",
      "INFO:tensorflow:loss = 1.24151, step = 53400 (23.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32432\n",
      "INFO:tensorflow:loss = 1.4486386, step = 53500 (23.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31767\n",
      "INFO:tensorflow:loss = 1.4075274, step = 53600 (23.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33496\n",
      "INFO:tensorflow:loss = 1.3913734, step = 53700 (23.068 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33516\n",
      "INFO:tensorflow:loss = 1.3668094, step = 53800 (23.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33029\n",
      "INFO:tensorflow:loss = 1.1319818, step = 53900 (23.094 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 54001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.03605\n",
      "INFO:tensorflow:loss = 1.2331681, step = 54000 (24.776 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33815\n",
      "INFO:tensorflow:loss = 1.4149396, step = 54100 (23.051 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32701\n",
      "INFO:tensorflow:loss = 1.2187113, step = 54200 (23.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30437\n",
      "INFO:tensorflow:loss = 1.3530741, step = 54300 (23.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32168\n",
      "INFO:tensorflow:loss = 1.3931532, step = 54400 (23.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31295\n",
      "INFO:tensorflow:loss = 1.4354615, step = 54500 (23.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33593\n",
      "INFO:tensorflow:loss = 1.3938204, step = 54600 (23.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32742\n",
      "INFO:tensorflow:loss = 1.4065223, step = 54700 (23.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3292\n",
      "INFO:tensorflow:loss = 1.2245517, step = 54800 (23.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32935\n",
      "INFO:tensorflow:loss = 1.4481279, step = 54900 (23.098 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 55001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.09674\n",
      "INFO:tensorflow:loss = 1.3566988, step = 55000 (24.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33051\n",
      "INFO:tensorflow:loss = 1.2818835, step = 55100 (23.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3324\n",
      "INFO:tensorflow:loss = 1.3867985, step = 55200 (23.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32871\n",
      "INFO:tensorflow:loss = 1.2819097, step = 55300 (23.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33262\n",
      "INFO:tensorflow:loss = 1.206877, step = 55400 (23.081 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3194\n",
      "INFO:tensorflow:loss = 1.1918142, step = 55500 (23.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33296\n",
      "INFO:tensorflow:loss = 1.1553811, step = 55600 (23.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.34023\n",
      "INFO:tensorflow:loss = 1.4000878, step = 55700 (23.040 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33963\n",
      "INFO:tensorflow:loss = 1.3158846, step = 55800 (23.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33391\n",
      "INFO:tensorflow:loss = 1.2277412, step = 55900 (23.074 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 56001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.08877\n",
      "INFO:tensorflow:loss = 1.2202706, step = 56000 (24.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32109\n",
      "INFO:tensorflow:loss = 1.2707686, step = 56100 (23.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32144\n",
      "INFO:tensorflow:loss = 1.3952222, step = 56200 (23.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32435\n",
      "INFO:tensorflow:loss = 1.3197482, step = 56300 (23.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31917\n",
      "INFO:tensorflow:loss = 1.280357, step = 56400 (23.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32236\n",
      "INFO:tensorflow:loss = 1.2179501, step = 56500 (23.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30669\n",
      "INFO:tensorflow:loss = 1.2460537, step = 56600 (23.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30279\n",
      "INFO:tensorflow:loss = 1.4062827, step = 56700 (23.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30503\n",
      "INFO:tensorflow:loss = 1.217497, step = 56800 (23.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29883\n",
      "INFO:tensorflow:loss = 1.4177353, step = 56900 (23.262 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 57001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.09026\n",
      "INFO:tensorflow:loss = 1.3245068, step = 57000 (24.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32359\n",
      "INFO:tensorflow:loss = 1.3598253, step = 57100 (23.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.325\n",
      "INFO:tensorflow:loss = 1.2935355, step = 57200 (23.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32355\n",
      "INFO:tensorflow:loss = 1.2674849, step = 57300 (23.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3296\n",
      "INFO:tensorflow:loss = 1.3953912, step = 57400 (23.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32303\n",
      "INFO:tensorflow:loss = 1.573312, step = 57500 (23.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31122\n",
      "INFO:tensorflow:loss = 1.5234684, step = 57600 (23.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3239\n",
      "INFO:tensorflow:loss = 1.4305918, step = 57700 (23.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3106\n",
      "INFO:tensorflow:loss = 1.316195, step = 57800 (23.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30303\n",
      "INFO:tensorflow:loss = 1.254805, step = 57900 (23.239 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 58001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.08845\n",
      "INFO:tensorflow:loss = 1.418373, step = 58000 (24.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31606\n",
      "INFO:tensorflow:loss = 1.2340074, step = 58100 (23.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32701\n",
      "INFO:tensorflow:loss = 1.3111482, step = 58200 (23.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32375\n",
      "INFO:tensorflow:loss = 1.3995266, step = 58300 (23.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31663\n",
      "INFO:tensorflow:loss = 1.4741445, step = 58400 (23.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32293\n",
      "INFO:tensorflow:loss = 1.6599095, step = 58500 (23.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32301\n",
      "INFO:tensorflow:loss = 1.3478674, step = 58600 (23.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3274\n",
      "INFO:tensorflow:loss = 1.3325963, step = 58700 (23.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32524\n",
      "INFO:tensorflow:loss = 1.2279739, step = 58800 (23.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32856\n",
      "INFO:tensorflow:loss = 1.3224379, step = 58900 (23.103 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 59001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.08321\n",
      "INFO:tensorflow:loss = 1.3620113, step = 59000 (24.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32438\n",
      "INFO:tensorflow:loss = 1.3029747, step = 59100 (23.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32773\n",
      "INFO:tensorflow:loss = 1.6580887, step = 59200 (23.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31814\n",
      "INFO:tensorflow:loss = 1.5843682, step = 59300 (23.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29995\n",
      "INFO:tensorflow:loss = 1.1819735, step = 59400 (23.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.2972\n",
      "INFO:tensorflow:loss = 1.2181325, step = 59500 (23.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30537\n",
      "INFO:tensorflow:loss = 1.1906037, step = 59600 (23.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32413\n",
      "INFO:tensorflow:loss = 1.523378, step = 59700 (23.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32695\n",
      "INFO:tensorflow:loss = 1.1281259, step = 59800 (23.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33388\n",
      "INFO:tensorflow:loss = 1.3968419, step = 59900 (23.073 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 60001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.10015\n",
      "INFO:tensorflow:loss = 1.2491986, step = 60000 (24.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33639\n",
      "INFO:tensorflow:loss = 1.075795, step = 60100 (23.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33646\n",
      "INFO:tensorflow:loss = 1.4110253, step = 60200 (23.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33875\n",
      "INFO:tensorflow:loss = 1.277143, step = 60300 (23.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.34104\n",
      "INFO:tensorflow:loss = 1.2564368, step = 60400 (23.037 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33962\n",
      "INFO:tensorflow:loss = 1.2379031, step = 60500 (23.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33998\n",
      "INFO:tensorflow:loss = 1.2271619, step = 60600 (23.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31619\n",
      "INFO:tensorflow:loss = 1.226193, step = 60700 (23.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32388\n",
      "INFO:tensorflow:loss = 1.2882262, step = 60800 (23.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.34696\n",
      "INFO:tensorflow:loss = 1.2241447, step = 60900 (23.004 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 61001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.09571\n",
      "INFO:tensorflow:loss = 1.2816823, step = 61000 (24.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33678\n",
      "INFO:tensorflow:loss = 1.2210399, step = 61100 (23.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.34046\n",
      "INFO:tensorflow:loss = 1.287767, step = 61200 (23.040 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33655\n",
      "INFO:tensorflow:loss = 1.2931623, step = 61300 (23.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31269\n",
      "INFO:tensorflow:loss = 1.2459414, step = 61400 (23.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.28026\n",
      "INFO:tensorflow:loss = 1.2348372, step = 61500 (23.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29202\n",
      "INFO:tensorflow:loss = 1.3088505, step = 61600 (23.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.27979\n",
      "INFO:tensorflow:loss = 1.3844068, step = 61700 (23.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32784\n",
      "INFO:tensorflow:loss = 1.2383322, step = 61800 (23.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3214\n",
      "INFO:tensorflow:loss = 1.1813025, step = 61900 (23.141 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 62001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.05898\n",
      "INFO:tensorflow:loss = 1.1942902, step = 62000 (24.637 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.28413\n",
      "INFO:tensorflow:loss = 1.2455854, step = 62100 (23.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32005\n",
      "INFO:tensorflow:loss = 1.235953, step = 62200 (23.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29786\n",
      "INFO:tensorflow:loss = 1.2069287, step = 62300 (23.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32885\n",
      "INFO:tensorflow:loss = 1.1747943, step = 62400 (23.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30759\n",
      "INFO:tensorflow:loss = 1.4562455, step = 62500 (23.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29906\n",
      "INFO:tensorflow:loss = 1.2620702, step = 62600 (23.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31083\n",
      "INFO:tensorflow:loss = 1.1823616, step = 62700 (23.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29495\n",
      "INFO:tensorflow:loss = 1.1229647, step = 62800 (23.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30388\n",
      "INFO:tensorflow:loss = 1.456078, step = 62900 (23.235 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 63001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.0665\n",
      "INFO:tensorflow:loss = 1.169337, step = 63000 (24.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30318\n",
      "INFO:tensorflow:loss = 1.2701627, step = 63100 (23.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32627\n",
      "INFO:tensorflow:loss = 1.3122793, step = 63200 (23.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33498\n",
      "INFO:tensorflow:loss = 1.3384411, step = 63300 (23.068 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32838\n",
      "INFO:tensorflow:loss = 1.3457379, step = 63400 (23.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32728\n",
      "INFO:tensorflow:loss = 1.3008995, step = 63500 (23.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32766\n",
      "INFO:tensorflow:loss = 1.5030761, step = 63600 (23.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33183\n",
      "INFO:tensorflow:loss = 1.3250932, step = 63700 (23.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32753\n",
      "INFO:tensorflow:loss = 1.2500594, step = 63800 (23.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33631\n",
      "INFO:tensorflow:loss = 1.2333658, step = 63900 (23.060 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 64001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.08864\n",
      "INFO:tensorflow:loss = 1.1494098, step = 64000 (24.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33234\n",
      "INFO:tensorflow:loss = 1.4672387, step = 64100 (23.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3335\n",
      "INFO:tensorflow:loss = 1.4036905, step = 64200 (23.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33026\n",
      "INFO:tensorflow:loss = 1.1480141, step = 64300 (23.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3322\n",
      "INFO:tensorflow:loss = 1.3473129, step = 64400 (23.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33108\n",
      "INFO:tensorflow:loss = 1.2405854, step = 64500 (23.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32078\n",
      "INFO:tensorflow:loss = 1.3987825, step = 64600 (23.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.28536\n",
      "INFO:tensorflow:loss = 1.1510918, step = 64700 (23.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30757\n",
      "INFO:tensorflow:loss = 1.5036732, step = 64800 (23.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32362\n",
      "INFO:tensorflow:loss = 1.3583889, step = 64900 (23.129 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 65001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.08302\n",
      "INFO:tensorflow:loss = 1.2994659, step = 65000 (24.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32284\n",
      "INFO:tensorflow:loss = 1.1367576, step = 65100 (23.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32058\n",
      "INFO:tensorflow:loss = 1.3943563, step = 65200 (23.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32177\n",
      "INFO:tensorflow:loss = 1.4167004, step = 65300 (23.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31963\n",
      "INFO:tensorflow:loss = 1.5513389, step = 65400 (23.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31767\n",
      "INFO:tensorflow:loss = 1.1729171, step = 65500 (23.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31633\n",
      "INFO:tensorflow:loss = 1.2284355, step = 65600 (23.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32745\n",
      "INFO:tensorflow:loss = 1.4161313, step = 65700 (23.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33372\n",
      "INFO:tensorflow:loss = 1.4524257, step = 65800 (23.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3016\n",
      "INFO:tensorflow:loss = 1.1411923, step = 65900 (23.248 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 66001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.08782\n",
      "INFO:tensorflow:loss = 1.2159588, step = 66000 (24.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31407\n",
      "INFO:tensorflow:loss = 1.4290917, step = 66100 (23.180 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32778\n",
      "INFO:tensorflow:loss = 1.3243446, step = 66200 (23.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32139\n",
      "INFO:tensorflow:loss = 1.0688016, step = 66300 (23.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.28264\n",
      "INFO:tensorflow:loss = 1.5640578, step = 66400 (23.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.28673\n",
      "INFO:tensorflow:loss = 1.3447328, step = 66500 (23.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.28562\n",
      "INFO:tensorflow:loss = 1.0602834, step = 66600 (23.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29393\n",
      "INFO:tensorflow:loss = 1.059691, step = 66700 (23.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29445\n",
      "INFO:tensorflow:loss = 1.2900087, step = 66800 (23.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29614\n",
      "INFO:tensorflow:loss = 1.2909257, step = 66900 (23.276 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 67001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.07627\n",
      "INFO:tensorflow:loss = 1.4732122, step = 67000 (24.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30224\n",
      "INFO:tensorflow:loss = 1.3567147, step = 67100 (23.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.28534\n",
      "INFO:tensorflow:loss = 1.4196919, step = 67200 (23.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.28783\n",
      "INFO:tensorflow:loss = 1.2772977, step = 67300 (23.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30667\n",
      "INFO:tensorflow:loss = 1.3879735, step = 67400 (23.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31932\n",
      "INFO:tensorflow:loss = 1.1379578, step = 67500 (23.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31463\n",
      "INFO:tensorflow:loss = 1.13873, step = 67600 (23.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33292\n",
      "INFO:tensorflow:loss = 1.1925365, step = 67700 (23.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30938\n",
      "INFO:tensorflow:loss = 1.0627849, step = 67800 (23.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29503\n",
      "INFO:tensorflow:loss = 1.2777542, step = 67900 (23.282 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 68001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.08756\n",
      "INFO:tensorflow:loss = 1.3097274, step = 68000 (24.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32821\n",
      "INFO:tensorflow:loss = 1.2543663, step = 68100 (23.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3266\n",
      "INFO:tensorflow:loss = 1.2620752, step = 68200 (23.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32727\n",
      "INFO:tensorflow:loss = 1.1883645, step = 68300 (23.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31246\n",
      "INFO:tensorflow:loss = 1.3534955, step = 68400 (23.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31306\n",
      "INFO:tensorflow:loss = 1.197928, step = 68500 (23.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32182\n",
      "INFO:tensorflow:loss = 1.3019519, step = 68600 (23.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32413\n",
      "INFO:tensorflow:loss = 1.2235395, step = 68700 (23.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32347\n",
      "INFO:tensorflow:loss = 1.3342352, step = 68800 (23.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32732\n",
      "INFO:tensorflow:loss = 1.246299, step = 68900 (23.109 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 69001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.0703\n",
      "INFO:tensorflow:loss = 1.0136583, step = 69000 (24.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31822\n",
      "INFO:tensorflow:loss = 1.2507207, step = 69100 (23.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31984\n",
      "INFO:tensorflow:loss = 1.3567337, step = 69200 (23.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31328\n",
      "INFO:tensorflow:loss = 1.2116237, step = 69300 (23.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32488\n",
      "INFO:tensorflow:loss = 1.1880629, step = 69400 (23.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32777\n",
      "INFO:tensorflow:loss = 1.2277036, step = 69500 (23.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33045\n",
      "INFO:tensorflow:loss = 1.2308116, step = 69600 (23.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31373\n",
      "INFO:tensorflow:loss = 1.2656083, step = 69700 (23.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30223\n",
      "INFO:tensorflow:loss = 1.1509066, step = 69800 (23.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32225\n",
      "INFO:tensorflow:loss = 1.3209836, step = 69900 (23.136 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 70001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.08721\n",
      "INFO:tensorflow:loss = 1.3618221, step = 70000 (24.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32592\n",
      "INFO:tensorflow:loss = 1.3815122, step = 70100 (23.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31379\n",
      "INFO:tensorflow:loss = 1.3691574, step = 70200 (23.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32159\n",
      "INFO:tensorflow:loss = 1.3360834, step = 70300 (23.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31414\n",
      "INFO:tensorflow:loss = 1.2546191, step = 70400 (23.180 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31919\n",
      "INFO:tensorflow:loss = 1.3316737, step = 70500 (23.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32146\n",
      "INFO:tensorflow:loss = 1.1530665, step = 70600 (23.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32107\n",
      "INFO:tensorflow:loss = 1.2994664, step = 70700 (23.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3243\n",
      "INFO:tensorflow:loss = 1.5313241, step = 70800 (23.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32027\n",
      "INFO:tensorflow:loss = 1.2804217, step = 70900 (23.146 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 71001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.08198\n",
      "INFO:tensorflow:loss = 1.2199562, step = 71000 (24.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31743\n",
      "INFO:tensorflow:loss = 1.4535878, step = 71100 (23.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31959\n",
      "INFO:tensorflow:loss = 1.0311911, step = 71200 (23.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31871\n",
      "INFO:tensorflow:loss = 1.2612345, step = 71300 (23.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32292\n",
      "INFO:tensorflow:loss = 1.4983382, step = 71400 (23.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32127\n",
      "INFO:tensorflow:loss = 1.3473606, step = 71500 (23.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32114\n",
      "INFO:tensorflow:loss = 1.4744562, step = 71600 (23.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32485\n",
      "INFO:tensorflow:loss = 1.2915903, step = 71700 (23.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32779\n",
      "INFO:tensorflow:loss = 1.1796972, step = 71800 (23.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32454\n",
      "INFO:tensorflow:loss = 1.3353968, step = 71900 (23.124 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 72001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.07349\n",
      "INFO:tensorflow:loss = 1.2601004, step = 72000 (24.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32592\n",
      "INFO:tensorflow:loss = 1.1195643, step = 72100 (23.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32088\n",
      "INFO:tensorflow:loss = 1.2984356, step = 72200 (23.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30913\n",
      "INFO:tensorflow:loss = 1.2628388, step = 72300 (23.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3129\n",
      "INFO:tensorflow:loss = 1.5873497, step = 72400 (23.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31781\n",
      "INFO:tensorflow:loss = 1.2641242, step = 72500 (23.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32402\n",
      "INFO:tensorflow:loss = 1.5431083, step = 72600 (23.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32312\n",
      "INFO:tensorflow:loss = 1.1816263, step = 72700 (23.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32202\n",
      "INFO:tensorflow:loss = 1.1482863, step = 72800 (23.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31544\n",
      "INFO:tensorflow:loss = 1.1918985, step = 72900 (23.172 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 73001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.08306\n",
      "INFO:tensorflow:loss = 1.3118398, step = 73000 (24.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3273\n",
      "INFO:tensorflow:loss = 1.3098389, step = 73100 (23.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32658\n",
      "INFO:tensorflow:loss = 1.1677268, step = 73200 (23.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32498\n",
      "INFO:tensorflow:loss = 1.308811, step = 73300 (23.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32428\n",
      "INFO:tensorflow:loss = 1.6070634, step = 73400 (23.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32223\n",
      "INFO:tensorflow:loss = 1.1521828, step = 73500 (23.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32161\n",
      "INFO:tensorflow:loss = 1.2669342, step = 73600 (23.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32609\n",
      "INFO:tensorflow:loss = 1.3447428, step = 73700 (23.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32901\n",
      "INFO:tensorflow:loss = 1.4940801, step = 73800 (23.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32919\n",
      "INFO:tensorflow:loss = 1.2099478, step = 73900 (23.099 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 74001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.08757\n",
      "INFO:tensorflow:loss = 1.3195386, step = 74000 (24.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32709\n",
      "INFO:tensorflow:loss = 1.3039734, step = 74100 (23.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3295\n",
      "INFO:tensorflow:loss = 1.2256501, step = 74200 (23.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32477\n",
      "INFO:tensorflow:loss = 1.4023458, step = 74300 (23.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32807\n",
      "INFO:tensorflow:loss = 1.3553753, step = 74400 (23.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3275\n",
      "INFO:tensorflow:loss = 1.3239226, step = 74500 (23.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32624\n",
      "INFO:tensorflow:loss = 1.3987577, step = 74600 (23.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3244\n",
      "INFO:tensorflow:loss = 1.2696054, step = 74700 (23.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33266\n",
      "INFO:tensorflow:loss = 1.2760413, step = 74800 (23.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32291\n",
      "INFO:tensorflow:loss = 1.3700757, step = 74900 (23.133 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 75001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.07407\n",
      "INFO:tensorflow:loss = 1.457595, step = 75000 (24.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32653\n",
      "INFO:tensorflow:loss = 1.3040158, step = 75100 (23.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33135\n",
      "INFO:tensorflow:loss = 1.08436, step = 75200 (23.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32945\n",
      "INFO:tensorflow:loss = 1.3868095, step = 75300 (23.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30459\n",
      "INFO:tensorflow:loss = 1.3160437, step = 75400 (23.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3287\n",
      "INFO:tensorflow:loss = 1.3247223, step = 75500 (23.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33126\n",
      "INFO:tensorflow:loss = 1.1559993, step = 75600 (23.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33385\n",
      "INFO:tensorflow:loss = 1.3537548, step = 75700 (23.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33526\n",
      "INFO:tensorflow:loss = 1.3973835, step = 75800 (23.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33719\n",
      "INFO:tensorflow:loss = 1.588051, step = 75900 (23.057 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 76001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.08194\n",
      "INFO:tensorflow:loss = 1.3366058, step = 76000 (24.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31145\n",
      "INFO:tensorflow:loss = 1.1411941, step = 76100 (23.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.28114\n",
      "INFO:tensorflow:loss = 1.3228939, step = 76200 (23.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29804\n",
      "INFO:tensorflow:loss = 1.3248433, step = 76300 (23.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31171\n",
      "INFO:tensorflow:loss = 0.9915689, step = 76400 (23.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31475\n",
      "INFO:tensorflow:loss = 1.2173759, step = 76500 (23.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.28366\n",
      "INFO:tensorflow:loss = 1.1731348, step = 76600 (23.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.28075\n",
      "INFO:tensorflow:loss = 1.0429568, step = 76700 (23.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.27948\n",
      "INFO:tensorflow:loss = 1.3938361, step = 76800 (23.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.28634\n",
      "INFO:tensorflow:loss = 1.3234516, step = 76900 (23.330 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 77001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.06594\n",
      "INFO:tensorflow:loss = 1.3522367, step = 77000 (24.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.2788\n",
      "INFO:tensorflow:loss = 1.4586953, step = 77100 (23.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29558\n",
      "INFO:tensorflow:loss = 1.1225417, step = 77200 (23.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3063\n",
      "INFO:tensorflow:loss = 1.1341598, step = 77300 (23.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.28709\n",
      "INFO:tensorflow:loss = 1.3757501, step = 77400 (23.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.28015\n",
      "INFO:tensorflow:loss = 1.145539, step = 77500 (23.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30212\n",
      "INFO:tensorflow:loss = 1.4579078, step = 77600 (23.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33414\n",
      "INFO:tensorflow:loss = 1.2002605, step = 77700 (23.072 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.34541\n",
      "INFO:tensorflow:loss = 1.4138244, step = 77800 (23.013 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.34722\n",
      "INFO:tensorflow:loss = 1.1236567, step = 77900 (23.004 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 78001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.09809\n",
      "INFO:tensorflow:loss = 1.3081137, step = 78000 (24.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33995\n",
      "INFO:tensorflow:loss = 1.1596234, step = 78100 (23.042 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3314\n",
      "INFO:tensorflow:loss = 1.2169417, step = 78200 (23.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33078\n",
      "INFO:tensorflow:loss = 1.1449246, step = 78300 (23.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30802\n",
      "INFO:tensorflow:loss = 1.1768622, step = 78400 (23.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33357\n",
      "INFO:tensorflow:loss = 1.3838181, step = 78500 (23.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33387\n",
      "INFO:tensorflow:loss = 1.2730894, step = 78600 (23.075 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32908\n",
      "INFO:tensorflow:loss = 1.3698531, step = 78700 (23.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3251\n",
      "INFO:tensorflow:loss = 1.2501607, step = 78800 (23.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32863\n",
      "INFO:tensorflow:loss = 1.5486751, step = 78900 (23.101 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 79001 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.09384\n",
      "INFO:tensorflow:loss = 1.2782056, step = 79000 (24.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3316\n",
      "INFO:tensorflow:loss = 1.4168786, step = 79100 (23.086 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32951\n",
      "INFO:tensorflow:loss = 1.3769572, step = 79200 (23.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32816\n",
      "INFO:tensorflow:loss = 1.3697546, step = 79300 (23.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30364\n",
      "INFO:tensorflow:loss = 1.2021474, step = 79400 (23.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31573\n",
      "INFO:tensorflow:loss = 1.434259, step = 79500 (23.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30679\n",
      "INFO:tensorflow:loss = 1.3456309, step = 79600 (23.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31948\n",
      "INFO:tensorflow:loss = 1.2509165, step = 79700 (23.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31983\n",
      "INFO:tensorflow:loss = 1.2431817, step = 79800 (23.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3053\n",
      "INFO:tensorflow:loss = 1.6529301, step = 79900 (23.226 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 80000 into ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.3212209.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7f29bd55cc88>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=train_input_fn, steps=80000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###DONE TRAIN###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@\n",
      "(TensorShape([Dimension(64), Dimension(None), Dimension(None), Dimension(3)]), TensorShape([Dimension(64)]))\n",
      "@@@\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-31-06:16:15\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt-80000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-31-06:27:48\n",
      "INFO:tensorflow:Saving dict for global step 80000: accuracy = 0.5401628, global_step = 80000, loss = 1.265189\n"
     ]
    }
   ],
   "source": [
    "#performance on training dataset:\n",
    "def train_partial_input_fn():\n",
    "#     return input_fn(path_tfrecords_train_lst[7000:8500], train=False) \n",
    "    return input_fn(path_tfrecords_train_lst, train=False) \n",
    "\n",
    "train_partial_result = model.evaluate(input_fn=train_partial_input_fn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#VAL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfrec_val_batch_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfrec_val_directory = os.path.join('..','datasets','stixels','val','tfrec_batch_size_'\n",
    "                                   +str(tfrec_val_batch_size))#+'_percent_'+str(percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_tfrecords_val_lst=[]\n",
    "path_tfrecords_val = os.path.join(img_path, 'val')\n",
    "for root, dirs, files in os.walk(tfrec_val_directory):\n",
    "    for file in files:\n",
    "        if '.tfrecord' in file:\n",
    "            path_tfrecords_val_lst.append(os.path.join(tfrec_val_directory,file))\n",
    "        else:\n",
    "            print('WARNING: file ' + file + 'looks suspicious. does it belong here?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def val_input_fn():\n",
    "    return input_fn(path_tfrecords_val_lst, train=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@\n",
      "(TensorShape([Dimension(64), Dimension(None), Dimension(None), Dimension(3)]), TensorShape([Dimension(64)]))\n",
      "@@@\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-06-01-08:19:46\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt-80000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-06-01-08:57:52\n",
      "INFO:tensorflow:Saving dict for global step 80000: accuracy = 0.39537528, global_step = 80000, loss = 1.6725091\n"
     ]
    }
   ],
   "source": [
    "val_result = model.evaluate(input_fn=val_input_fn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.26630434, 'global_step': 100000, 'loss': 2.224182}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification val accuracy: 26.63%\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification val accuracy: {0:.2%}\".format(val_result[\"accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TEST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfrec_test_batch_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfrec_test_directory = os.path.join('..','datasets','stixels','test','tfrec_batch_size_'+str(tfrec_test_batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_tfrecords_test_lst=[]\n",
    "path_tfrecords_test = os.path.join(img_path, 'test')\n",
    "for root, dirs, files in os.walk(tfrec_test_directory):\n",
    "    for file in files:\n",
    "        if '.tfrecord' in file:\n",
    "            path_tfrecords_test_lst.append(os.path.join(tfrec_test_directory,file))\n",
    "        else:\n",
    "            print('WARNING: file ' + file + 'looks suspicious. does it belong here?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_input_fn():\n",
    "    return input_fn(filenames=path_tfrecords_test_lst[1000:2500], train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@\n",
      "(TensorShape([Dimension(64), Dimension(None), Dimension(None), Dimension(3)]), TensorShape([Dimension(64)]))\n",
      "@@@\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-29-04:20:07\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./ckpts_28_5_mobilenetV2_partial_midSize10_kernels_varies_midLR_withAvg2/model.ckpt-135001\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-29-04:20:13\n",
      "INFO:tensorflow:Saving dict for global step 135001: accuracy = 0.19497283, global_step = 135001, loss = 2.7235723\n"
     ]
    }
   ],
   "source": [
    "test_result = model.evaluate(input_fn=test_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification test accuracy: 11.55%\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification test accuracy: {0:.2%}\".format(test_result[\"accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PRED:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum_csv_test_path = os.path.join(img_path,'val', 'sum_csv') #TEST\n",
    "labels_test=pd.read_csv(os.path.join(sum_csv_test_path,'labels_val_'+str(percent)+'percent.csv'))\n",
    "test_names_list=list(labels_test['Name'])\n",
    "image_paths_test=[]\n",
    "for name in test_names_list:\n",
    "    image_paths_test.append(os.path.join(img_path, 'val', name+'.png')) #maybe no need to add '.png'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_images(image_paths):\n",
    "    # Load the images from disk.\n",
    "    images = [imread(path) for path in image_paths]\n",
    "    # Convert to a numpy array and return it.\n",
    "    return np.asarray(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##TODO:SHUFFLE!\n",
    "some_num=1500\n",
    "some_images = load_images(image_paths=image_paths_test[7000:7000+some_num])\n",
    "some_images_cls = np.array(labels_test['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"image\": some_images.astype(np.float32)},\n",
    "    num_epochs=1,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predictions = model.predict(input_fn=predict_input_fn)\n",
    "# predictions for val\n",
    "predictions = model.predict(input_fn=val_input_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Estimator.predict at 0x7fb123a487d8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@\n",
      "(TensorShape([Dimension(64), Dimension(None), Dimension(None), Dimension(3)]), TensorShape([Dimension(64)]))\n",
      "@@@\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt-80000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "117888"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_pred = np.array(list(predictions))\n",
    "len(cls_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117888,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    0,     5,     5,    21,    71,   313,   150,  1079,  3691,\n",
       "         6280, 11605, 13872, 16378, 17646, 19292, 18101, 19392, 17603,\n",
       "        16215, 15047, 14708, 15527, 14560, 14073, 14708, 13082, 13245,\n",
       "        12922, 10970, 11509, 10997, 10722, 10903,  9856,  9444,  9308,\n",
       "         7769,  5462,  2876,  1092,   241,    23,     0,     0,     0,\n",
       "         7815]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "        34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46]))"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram(some_images_cls, bins= [x for x in range(0, 47, 1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0,    0,    0,    0,    3,  101,   11,  109,  990, 1530, 3529,\n",
       "        4319, 5280, 5354, 6056, 5253, 6157, 5445, 4703, 4465, 4378, 4679,\n",
       "        4376, 4452, 4726, 3291, 3713, 4195, 3087, 3355, 3087, 2931, 3322,\n",
       "        2568, 2604, 2827, 2262, 1755,  610,  160,    2,    0,    0,    0,\n",
       "           0, 2203]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "        34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram(cls_pred, bins= [x for x in range(0, 47, 1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.63838133e-08, 5.23802601e-06, 2.41361181e-06, 8.22993752e-06,\n",
       "       6.88640721e-05, 6.73187096e-05, 1.12743000e-04, 2.48558167e-03,\n",
       "       2.41161394e-03, 1.98379252e-03, 1.63461361e-03, 3.52152251e-03,\n",
       "       4.75671981e-03, 8.01659003e-03, 9.75785963e-03, 8.38503707e-03,\n",
       "       5.74642140e-03, 7.23679783e-03, 7.88456481e-03, 1.14491200e-02,\n",
       "       1.59071349e-02, 1.35434372e-02, 5.99773182e-03, 4.06883238e-03,\n",
       "       6.72300300e-03, 8.37637670e-03, 1.83306281e-02, 2.76202224e-02,\n",
       "       2.98272502e-02, 2.47496460e-02, 1.82593651e-02, 4.35408838e-02,\n",
       "       2.88887601e-02, 3.89404297e-02, 9.61616039e-02, 1.31164491e-01,\n",
       "       6.05020821e-02, 3.79621610e-02, 1.50133632e-02, 7.29497289e-03,\n",
       "       4.58270835e-04, 1.19983735e-04, 5.25741832e-08, 3.36415056e-08,\n",
       "       4.82108398e-08, 3.18117941e-08, 2.91014105e-01], dtype=float32)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_pred[67]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([46, 46, 46, ..., 46, 46, 46])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(cls_pred,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0, 1500]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "        34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46]))"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram(np.argmax(cls_pred,axis=1), bins= [x for x in range(0, 47, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(cls_pred,axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(cls_pred[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_cls = tf.argmax(cls_pred, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ArgMax:0' shape=(100,) dtype=int64>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/noa_raindel/.TFgpu/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "[46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46\n",
      " 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46\n",
      " 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46\n",
      " 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46\n",
      " 46 46 46 46]\n"
     ]
    }
   ],
   "source": [
    "init_op = tf.initialize_all_variables()\n",
    "with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "        print (sess.run(y_pred_cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Contain bugs\n",
    "# def calculate_AUC(y_pred_cls, GT, num_classes):\n",
    "#     if max(y_pred_cls) < 17 and num_classes==47:\n",
    "#         print(\"Wrong number of classes! Check input the AUC func!\")\n",
    "#     if max(y_pred_cls) > 16 and num_classes==17:\n",
    "#         print(\"Wrong number of classes! Check input the AUC func!\")\n",
    "#     px_in_bin = (370-140)/(num_classes-1)\n",
    "# #     auc_acc = np.zeros(int(50/px_in_bin)+1)\n",
    "#     auc_acc = np.zeros(num_classes)\n",
    "#     for error in range(num_classes): #range(int(50/px_in_bin)+1):\n",
    "#         if error > 0:\n",
    "#             auc_acc[error] = auc_acc[error-1]\n",
    "#         for i in range(len(y_pred_cls)):\n",
    "# #             print(y_pred_cls[i]-(GT[i] - error))\n",
    "# #             print(max(GT[i] - error,0))\n",
    "#             if (GT[i] == min(y_pred_cls[i] + error,num_classes)) or (GT == max(y_pred_cls[i] - error,0)):\n",
    "# #                 print('k')\n",
    "#                 auc_acc[error] += 1\n",
    "   \n",
    "#     error_vec = [px_in_bin/2 + i*px_in_bin for i in range(num_classes)]\n",
    "#     total = len(y_pred_cls)\n",
    "# #     auc_acc /= total\n",
    "    \n",
    "#     return error_vec, auc_acc\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/noa_raindel/.TFgpu/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "# extract ground truth data\n",
    "dataset = tf.data.TFRecordDataset(filenames=path_tfrecords_val_lst)\n",
    "dataset = dataset.map(parse)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "images_batch, labels_batch = iterator.get_next()\n",
    "x = {'image': images_batch}\n",
    "y = labels_batch\n",
    "GTlabels=[]\n",
    "init_op = tf.initialize_all_variables()\n",
    "with tf.Session() as sess:\n",
    "    for i in range(len(path_tfrecords_val_lst)):\n",
    "        sess.run(init_op)\n",
    "        GTlabels.append(sess.run(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_AUC_fast(y_pred_cls, GT, num_classes):\n",
    "    if max(y_pred_cls) < 17 and num_classes==47:\n",
    "        print(\"Wrong number of classes! Check input the AUC func!\")\n",
    "    if max(y_pred_cls) > 16 and num_classes==17:\n",
    "        print(\"Wrong number of classes! Check input the AUC func!\")\n",
    "    px_in_bin = (370-140)/(num_classes-1)\n",
    "    \n",
    "    \n",
    "    diff_vec = [abs(number) for number in np.subtract(y_pred_cls,GT)]\n",
    "    error_count = np.zeros(num_classes)\n",
    "    for i in range(len(y_pred_cls)):\n",
    "        error_count[diff_vec[i]] += 1\n",
    "        \n",
    "        \n",
    "    auc_acc = np.cumsum(error_count)\n",
    "    \n",
    "    \n",
    "    error_px_vec = [px_in_bin/2 + i*px_in_bin for i in range(num_classes)]\n",
    "    total = len(y_pred_cls)\n",
    "    auc_acc /= total\n",
    "    \n",
    "    return error_px_vec, auc_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x47,y47 = calculate_AUC_fast(y_pred_cls=cls_pred, GT=GTlabels[:len(cls_pred)], num_classes=num_classes)\n",
    "x47=np.insert(x47, 0, 0)\n",
    "y47=np.insert(y47, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.    2.5   7.5  12.5  17.5  22.5  27.5  32.5  37.5  42.5  47.5  52.5\n",
      "  57.5  62.5  67.5  72.5  77.5  82.5  87.5  92.5  97.5 102.5 107.5 112.5\n",
      " 117.5 122.5 127.5 132.5 137.5 142.5 147.5 152.5 157.5 162.5 167.5 172.5\n",
      " 177.5 182.5 187.5 192.5 197.5 202.5 207.5 212.5 217.5 222.5 227.5 232.5]\n",
      "[0.         0.39537527 0.77951106 0.87417719 0.90420569 0.91986462\n",
      " 0.93039156 0.93850943 0.94547367 0.95077531 0.95529655 0.95916463\n",
      " 0.96246437 0.96511095 0.96778298 0.96999695 0.97182071 0.97340696\n",
      " 0.97528162 0.97726656 0.97881888 0.98008279 0.98140608 0.98282268\n",
      " 0.98402721 0.98509602 0.9861309  0.98711489 0.98819218 0.9891592\n",
      " 0.99039767 0.9913562  0.9923317  0.99323086 0.99397733 0.99487649\n",
      " 0.99618282 0.99765031 0.99873609 0.99956739 0.99972856 0.99986428\n",
      " 0.99995759 0.99996607 1.         1.         1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(x47)\n",
    "print(y47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fea42007cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(x47,y47,marker='*')\n",
    "plt.xlabel('Pixels')\n",
    "plt.ylabel('Fraction of results within range')\n",
    "plt.xlim(0,50)\n",
    "plt.ylim(0,1)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.5, AUC=  0.8439040266586662\n",
      "52.5, AUC=  0.85469703285766\n",
      "50,   AUC=  0.8493005297581631\n"
     ]
    }
   ],
   "source": [
    "# AUC for 47 bins\n",
    "AUC_475 = np.trapz(y=y47[:11], x=x47[:11])/x47[10] # up until 47.5 pixel error\n",
    "AUC_525 = np.trapz(y=y47[:12], x=x47[:12])/x47[11] # up until 52.5 pixel error\n",
    "AUC_50 = (AUC_475+AUC_525)/2\n",
    "print('47.5, AUC= ',AUC_475)\n",
    "print('52.5, AUC= ', AUC_525)\n",
    "print('50,   AUC= ', AUC_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# analyzing performance of 17 bins\n",
    "pred17_df = pd.read_csv('PREDS.csv')\n",
    "preds17 = list(pred17_df['preds'])\n",
    "\n",
    "GT17_df = pd.read_csv('VAL_GT.csv')\n",
    "GT17 = list(GT17_df['GT'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.       7.1875  21.5625  35.9375  50.3125  64.6875  79.0625  93.4375\n",
      " 107.8125 122.1875 136.5625 150.9375 165.3125 179.6875 194.0625 208.4375\n",
      " 222.8125 237.1875]\n",
      "[0.         0.69665276 0.92248575 0.94916361 0.96161611 0.97048894\n",
      " 0.97614685 0.98028637 0.98389149 0.98664834 0.98919313 0.99138165\n",
      " 0.99387554 0.99616585 0.99919415 0.99990669 1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "x17,y17 = calculate_AUC_fast(y_pred_cls=preds17, GT=GT17, num_classes=17)\n",
    "x17=np.insert(x17, 0, 0)\n",
    "y17=np.insert(y17, 0, 0)\n",
    "\n",
    "print(x17)\n",
    "print(y17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f725a41a828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(2)\n",
    "plt.plot(x17,y17,marker='*')\n",
    "plt.xlabel('Pixels')\n",
    "plt.ylabel('Fraction of results within range')\n",
    "plt.xlim(0,50)\n",
    "plt.ylim(0,1)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.3, AUC=  0.8214134238793236\n"
     ]
    }
   ],
   "source": [
    "# AUC for 17 bins\n",
    "AUC503 = np.trapz(y=y17[:5], x=x17[:5])/x17[4] # up until 50.3 pixel error\n",
    "print('50.3, AUC= ',AUC503)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1817488\n"
     ]
    }
   ],
   "source": [
    "# count variables in model\n",
    "# np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])\n",
    "\n",
    "total_parameters = 0\n",
    "for variable in model.get_variable_names():\n",
    "    shape = model.get_variable_value(variable).shape\n",
    "    variable_parameters = 1\n",
    "    for dim in range(len(list(shape))):\n",
    "        variable_parameters *= shape[dim]\n",
    "    total_parameters += variable_parameters\n",
    "print(total_parameters)\n",
    "\n",
    "# model.get_variable_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_im(img,cls):\n",
    "    img = resize(img, (370,img.shape[1]))\n",
    "    imgplot = plt.imshow(img)\n",
    "    img[140+cls*5:140+(cls+1)*5,:,0]=1\n",
    "    img[140+cls*5:140+(cls+1)*5,:,1:]=0\n",
    "    return img[:,:5,:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "some_num=500\n",
    "some_images = load_images(image_paths=image_paths_test[7000:7000+some_num])\n",
    "some_images_cls = np.array(labels_test['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./ckpts_30_5_mobilenetV2_47bins_03_swap_1/model.ckpt-80000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(input_fn=predict_input_fn)\n",
    "cls_pred = np.array(list(predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/noa_raindel/.TFgpu/lib/python3.5/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/noa_raindel/.TFgpu/lib/python3.5/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0ee77e2908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting our preds:\n",
    "some_images_for_plt = some_images/255.0\n",
    "img = np.ones([370, 1, 3])\n",
    "for im in range(cls_pred.shape[0]):\n",
    "    img0 = plot_im(some_images_for_plt[im,:,:,:], cls_pred[im])\n",
    "    img=np.concatenate([img,img0],axis=1)\n",
    "imgplot = plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/noa_raindel/.TFgpu/lib/python3.5/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/noa_raindel/.TFgpu/lib/python3.5/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 500 is out of bounds for axis 0 with size 500",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-95d987511a5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m370\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mim\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msome_images_cls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mimg0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplot_im\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msome_images_for_plt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msome_images_cls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# imgplot = plt.imshow(img[:,1250:1950,:])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 500 is out of bounds for axis 0 with size 500"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0ee8721780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting GT:\n",
    "some_images_for_plt = some_images[:]/255.0\n",
    "img = np.ones([370, 1, 3])\n",
    "for im in range(some_images_cls[:].shape[0]):\n",
    "    img0 = plot_im(some_images_for_plt[im,:,:,:], some_images_cls[im])\n",
    "    img=np.concatenate([img,img0],axis=1)\n",
    "# imgplot = plt.imshow(img[:,1250:1950,:])\n",
    "imgplot = plt.imshow(img[:,:,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
