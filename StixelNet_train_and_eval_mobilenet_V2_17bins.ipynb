{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########now part 2: decode and train#######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3625252946920903512\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11272650752\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 3594027441480131163\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shared/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.contrib.layers.python.layers import utils\n",
    "#from preprocess_func_new import *\n",
    "from matplotlib.image import imread\n",
    "import os\n",
    "from os.path import expanduser\n",
    "# from tensorflow.python import keras\n",
    "# from tensorflow.keras.applications.mobileNet import DepthwiseConv2D\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#tf.enable_eager_execution()\n",
    "\n",
    "#tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../datasets2/stixels'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path = os.path.join('..','datasets2','stixels')\n",
    "img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent=2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrec_batch_size=1 #for path name only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../datasets2/stixels/train/tfrec_batch_size_1_percent_2'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfrec_train_directory = os.path.join('..','datasets2','stixels','train','tfrec_batch_size_'\n",
    "                                     +str(tfrec_batch_size)+'_percent_'+str(percent))\n",
    "#### note there is a misspelling \"precent\"\n",
    "tfrec_train_directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a list of paths to train tfrecs:\n",
    "path_tfrecords_train_lst=[]\n",
    "path_tfrecords_train = os.path.join(img_path, 'train')\n",
    "for root, dirs, files in os.walk(tfrec_train_directory):\n",
    "    for file in files:\n",
    "        if '.tfrecord' in file:\n",
    "            path_tfrecords_train_lst.append(os.path.join(tfrec_train_directory,file))\n",
    "        else:\n",
    "            print('WARNING: file ' + file + 'looks suspicious. does it belong here?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "398578"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(path_tfrecords_train_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#shortening the list for experiments\n",
    "path_tfrecords_train_lst = path_tfrecords_train_lst[:128]\n",
    "##################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params\n",
    "H=370 \n",
    "W=24\n",
    "C=3\n",
    "img_shape = (H, W, C)\n",
    "num_classes = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(serialized):\n",
    "    # Define a dict with the data-names and types we expect to\n",
    "    # find in the TFRecords file.\n",
    "    # It is a bit awkward that this needs to be specified again,\n",
    "    # because it could have been written in the header of the\n",
    "    # TFRecords file instead.\n",
    "    features = \\\n",
    "        {\n",
    "            'image': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.int64)\n",
    "        }\n",
    "\n",
    "    # Parse the serialized data so we get a dict with our data.\n",
    "    parsed_example = tf.parse_single_example(serialized=serialized,\n",
    "                                             features=features)\n",
    "\n",
    "    # Get the image as raw bytes.\n",
    "    image_raw = parsed_example['image']\n",
    "\n",
    "    # Decode the raw bytes so it becomes a tensor with type.\n",
    "    #######image = tf.decode_raw(image_raw, tf.int32) ####\n",
    "    image = tf.image.decode_png(image_raw, channels=3, dtype=tf.uint8) \n",
    "    #image = tf.cast(image, tf.int32)\n",
    "\n",
    "    # The type is now uint8 but we need it to be float.\n",
    "    \n",
    "    image = tf.cast(image, tf.float32) ####\n",
    "    \n",
    "    # Get the label associated with the image.\n",
    "    label = parsed_example['label']\n",
    "    \n",
    "    \n",
    "    # The image and label are now correct TensorFlow types.\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########## a function to print tensor values\n",
    "def print_tensor(tensor):\n",
    "    dataset = tf.data.TFRecordDataset(filenames=[tensor])\n",
    "    dataset = dataset.map(parse)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    images_batch, labels_batch = iterator.get_next()\n",
    "    x = {'image': images_batch}\n",
    "    y = labels_batch\n",
    "    init_op = tf.initialize_all_variables()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "        print (sess.run(y))\n",
    "        #print (sess.run(x))\n",
    "        #return(sess.run(x))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ try to print the tensors\n",
    "for t in path_tfrecords_train_lst[:128]:\n",
    "    #print (t)\n",
    "    print_tensor(t)\n",
    "    #print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-a893ff3f9288>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m############# print shape of tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "############# print shape of tensor\n",
    "x2=tf.Session().run(x['image'])\n",
    "x2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa46a8d0e48>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa46a75c908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "####################. show the parsed stixel\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "matplotlib.pyplot.imshow(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(filenames, train, batch_size=batch_size, buffer_size=100000): \n",
    "    # Args:\n",
    "    # filenames:   Filenames for the TFRecords files.\n",
    "    # train:       Boolean whether training (True) or testing (False).\n",
    "    # batch_size:  Return batches of this size.\n",
    "    # buffer_size: Read buffers of this size. The random shuffling\n",
    "    #              is done on the buffer, so it must be big enough.\n",
    "\n",
    "    # Create a TensorFlow Dataset-object which has functionality\n",
    "    # for reading and shuffling data from TFRecords files.\n",
    "    dataset = tf.data.TFRecordDataset(filenames=filenames)\n",
    "\n",
    "    # Parse the serialized data in the TFRecords files.\n",
    "    # This returns TensorFlow tensors for the image and labels.\n",
    "    dataset = dataset.map(parse)\n",
    "    \n",
    "    if train:\n",
    "        # If training then read a buffer of the given size and\n",
    "        # randomly shuffle it.\n",
    "        ######dataset = dataset.shuffle(buffer_size=buffer_size)\n",
    "\n",
    "        # Allow infinite reading of the data.\n",
    "        num_repeat = None #-1\n",
    "    else:\n",
    "        # If testing then don't shuffle the data.\n",
    "        \n",
    "        # Only go through the data once.\n",
    "        num_repeat = 1\n",
    "\n",
    "    # Repeat the dataset the given number of times.\n",
    "    dataset = dataset.repeat(num_repeat)\n",
    "    \n",
    "    # Get a batch of data with the given size.\n",
    "    #dataset = dataset.batch(batch_size)\n",
    "    #dataset = tf.contrib.data.batch_and_drop_remainder(batch_size)\n",
    "    dataset = dataset.apply(tf.contrib.data.batch_and_drop_remainder(batch_size))\n",
    "    print('@@@')\n",
    "    print(dataset.output_shapes)  # ==> \"(16,)\" (the batch dimension is known)\n",
    "    print('@@@')\n",
    "    # Create an iterator for the dataset and the above modifications.\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "    # Get the next batch of images and labels.\n",
    "    images_batch, labels_batch = iterator.get_next()\n",
    "\n",
    "    # The input-function must return a dict wrapping the images.\n",
    "    x = {'image': images_batch}\n",
    "    y = labels_batch\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn():\n",
    "    return input_fn(filenames=path_tfrecords_train_lst, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the next four cells are a modification of https://github.com/xiaochus/MobileNetV2/blob/master/mobilenet_v2.py\n",
    "def _conv_block(inputs, filters, kernel, strides, is_training):\n",
    "    \"\"\"Convolution Block\n",
    "    This function defines a 2D convolution operation with BN and relu6.\n",
    "    # Arguments\n",
    "        inputs: Tensor, input tensor of conv layer.\n",
    "        filters: Integer, the dimensionality of the output space.\n",
    "        kernel: An integer or tuple/list of 2 integers, specifying the\n",
    "            width and height of the 2D convolution window.\n",
    "        strides: An integer or tuple/list of 2 integers,\n",
    "            specifying the strides of the convolution along the width and height.\n",
    "            Can be a single integer to specify the same value for\n",
    "            all spatial dimensions.\n",
    "    # Returns\n",
    "        Output tensor.\n",
    "    \"\"\"\n",
    "    x = tf.layers.conv2d(inputs=inputs, \n",
    "                         filters=filters, \n",
    "                         kernel_size=kernel,\n",
    "                         activation=None, \n",
    "                         strides=strides,\n",
    "                         kernel_initializer=tf.contrib.layers.xavier_initializer(seed=481),\n",
    "                         padding='same'\n",
    "                        )\n",
    "    \n",
    "    x = tf.layers.batch_normalization(inputs=x,\n",
    "                                      training=is_training\n",
    "                                     )\n",
    "    \n",
    "    x = tf.nn.relu6(features=x)\n",
    "       \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bottleneck(inputs, filters, kernel, t, s, is_training, r=False):\n",
    "    \"\"\"Bottleneck\n",
    "    This function defines a basic bottleneck structure.\n",
    "    # Arguments\n",
    "        inputs: Tensor, input tensor of conv layer.\n",
    "        filters: Integer, the dimensionality of the output space.\n",
    "        kernel: An integer or tuple/list of 2 integers, specifying the\n",
    "            width and height of the 2D convolution window.\n",
    "        t: Integer, expansion factor.\n",
    "            t is always applied to the input size.\n",
    "        s: An integer or tuple/list of 2 integers,specifying the strides\n",
    "            of the convolution along the width and height.Can be a single\n",
    "            integer to specify the same value for all spatial dimensions.\n",
    "        r: Boolean, Whether to use the residuals.\n",
    "    # Returns\n",
    "        Output tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    num_filters_in = utils.last_dimension(inputs.get_shape(), min_rank=4)\n",
    "    \n",
    "    # \"Expension layer\" + BN + activation\n",
    "    x = _conv_block(inputs=inputs, \n",
    "                    filters=num_filters_in*t, \n",
    "                    kernel=(1, 1), \n",
    "                    strides=(1, 1), \n",
    "                    is_training=is_training)\n",
    "    \n",
    "    # Depthwise convolution + BN + activation\n",
    "    x = tf.contrib.layers.separable_conv2d(inputs=x,\n",
    "                                           num_outputs=None,\n",
    "                                           kernel_size=kernel,\n",
    "                                           depth_multiplier=1,\n",
    "                                           stride=(s,s),\n",
    "                                           padding='SAME',\n",
    "                                           activation_fn=tf.nn.relu6,\n",
    "                                           weights_initializer=tf.contrib.layers.xavier_initializer(seed=481),\n",
    "                                           normalizer_fn=None\n",
    "                                          )\n",
    "     \n",
    "    x = tf.layers.batch_normalization(inputs=x, \n",
    "                                      training=is_training\n",
    "                                     )\n",
    "    \n",
    "    x = tf.nn.relu6(features=x)\n",
    "    \n",
    "    # \"Projection\" layer + BN\n",
    "    x = tf.layers.conv2d(inputs=x,\n",
    "                         filters = filters,\n",
    "                         kernel_size = (1, 1),\n",
    "                         strides=(1, 1),\n",
    "                         padding='same',\n",
    "                         kernel_initializer=tf.contrib.layers.xavier_initializer(seed=481)\n",
    "                        )\n",
    "    x = tf.layers.batch_normalization(inputs=x,\n",
    "                                      training=is_training\n",
    "                                     )\n",
    "    \n",
    "    if r:\n",
    "        x = tf.add(x, inputs)\n",
    "        \n",
    "    '''\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "    tchannel = K.int_shape(inputs)[channel_axis] * t\n",
    "    x = _conv_block(inputs, tchannel, (1, 1), (1, 1))\n",
    "    x = DepthwiseConv2D(kernel, strides=(s, s), depth_multiplier=1, padding='same')(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation(relu6)(x)\n",
    "\n",
    "    x = Conv2D(filters, (1, 1), strides=(1, 1), padding='same')(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    '''\n",
    "    \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _inverted_residual_block(inputs, filters, kernel, t, strides, n, is_training):\n",
    "    \"\"\"Inverted Residual Block\n",
    "    This function defines a sequence of 1 or more identical layers.\n",
    "    # Arguments\n",
    "        inputs: Tensor, input tensor of conv layer.\n",
    "        filters: Integer, the dimensionality of the output space.\n",
    "        kernel: An integer or tuple/list of 2 integers, specifying the\n",
    "            width and height of the 2D convolution window.\n",
    "        t: Integer, expansion factor.\n",
    "            t is always applied to the input size.\n",
    "        s: An integer or tuple/list of 2 integers,specifying the strides\n",
    "            of the convolution along the width and height.Can be a single\n",
    "            integer to specify the same value for all spatial dimensions.\n",
    "        n: Integer, layer repeat times.\n",
    "    # Returns\n",
    "        Output tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    x = _bottleneck(inputs=inputs, \n",
    "                    filters=filters, \n",
    "                    kernel=kernel, \n",
    "                    t=t, \n",
    "                    s=strides, \n",
    "                    is_training=is_training\n",
    "                   )\n",
    "        \n",
    "    for i in range(1, n):\n",
    "        x = _bottleneck(inputs=x, \n",
    "                        filters=filters, \n",
    "                        kernel=kernel, \n",
    "                        t=t, \n",
    "                        s=1, \n",
    "                        is_training=is_training, \n",
    "                        r=True\n",
    "                       )\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MobileNetV2(inputs, k, is_training):\n",
    "    \"\"\"MobileNetV2\n",
    "    This function defines a MobileNetV2 architectures.\n",
    "    # Arguments\n",
    "        inputs: A tensor of the input of shape [-1,W,H,C].\n",
    "        k: Integer, number of classes.\n",
    "        is_training: boolean indication training or prediction\n",
    "    # Returns\n",
    "        MobileNetV2 model.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    x = _conv_block(inputs=inputs, filters=32, kernel=(3, 3), strides=(2, 2), is_training=is_training)\n",
    "        \n",
    "    x = _inverted_residual_block(inputs=x, filters=16,  kernel=(7, 3), t=1, strides=1, n=1, is_training=is_training)\n",
    "    x = _inverted_residual_block(inputs=x, filters=24,  kernel=(7, 3), t=6, strides=2, n=2, is_training=is_training)\n",
    "    x = _inverted_residual_block(inputs=x, filters=32,  kernel=(7, 3), t=6, strides=2, n=3, is_training=is_training)\n",
    "    x = _inverted_residual_block(inputs=x, filters=64,  kernel=(7, 3), t=6, strides=2, n=4, is_training=is_training)\n",
    "    x = _inverted_residual_block(inputs=x, filters=96,  kernel=(7, 3), t=6, strides=1, n=3, is_training=is_training)\n",
    "#     x = _inverted_residual_block(inputs=x, filters=160, kernel=(3, 3), t=6, strides=2, n=3, is_training=is_training)\n",
    "#     x = _inverted_residual_block(inputs=x, filters=320, kernel=(3, 3), t=6, strides=1, n=1, is_training=is_training)\n",
    "    x = tf.layers.average_pooling2d(inputs=x, pool_size=(2,24), strides=(1,1))\n",
    "    # Eventually this should be replaced with:\n",
    "    x = tf.layers.flatten(x)\n",
    "\n",
    "\n",
    "    # This is the last layer so it does not use an activation function.\n",
    "    x = tf.layers.dense(inputs=x, name='layer_fc6',\n",
    "                          units=k,\n",
    "                          kernel_initializer=tf.contrib.layers.xavier_initializer()\n",
    "                          ) \n",
    "    '''\n",
    "    x = _conv_block(inputs=x, filters=1280, kernel=(1, 1), strides=(1, 1), is_training=is_training)\n",
    "    x = tf.layers.average_pooling2d(inputs=x, pool_size=(2000,2000), strides=(1,1), padding='same')\n",
    "    x = tf.reshape(x, [-1,1,1,1280])\n",
    "    #x = tf.layers.dropout(inputs=x, rate=0.3, seed=481, training=is_training)\n",
    "    x = tf.layers.conv2d(inputs=x,\n",
    "                         filters = k,\n",
    "                         kernel_size = (1, 1),\n",
    "                         padding='same',\n",
    "                         kernel_initializer=tf.contrib.layers.xavier_initializer(seed=481)\n",
    "                        )\n",
    "    '''\n",
    "    '''\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Reshape((1, 1, 1280))(x)\n",
    "    x = Dropout(0.3, name='Dropout')(x)\n",
    "    x = Conv2D(k, (1, 1), padding='same')(x)\n",
    "    x = Activation('softmax', name='softmax')(x)\n",
    "    output = Reshape((k,))(x)\n",
    "    '''\n",
    "    \n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "    # Args:\n",
    "    #\n",
    "    # features: This is the x-arg from the input_fn.\n",
    "    # labels:   This is the y-arg from the input_fn.\n",
    "    # mode:     Either TRAIN, EVAL, or PREDICT\n",
    "    # params:   User-defined hyper-parameters, e.g. learning-rate.\n",
    "    \n",
    "   \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        is_training = True\n",
    "    else:\n",
    "        is_training = False\n",
    "    \n",
    "    # Reference to the tensor named \"image\" in the input-function.    \n",
    "    x = features[\"image\"]\n",
    "    # The convolutional layers expect 4-rank tensors\n",
    "    # but x is a 2-rank tensor, so reshape it.\n",
    "    inputs = tf.reshape(x, [-1,W,H,C])\n",
    "    \n",
    "    net = MobileNetV2(inputs=inputs, k=17, is_training=is_training)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Logits output of the neural network.\n",
    "    logits = net\n",
    "\n",
    "    # Softmax output of the neural network.\n",
    "    y_pred = tf.nn.softmax(logits=logits)\n",
    "    \n",
    "    # Classification output of the neural network.\n",
    "    y_pred_cls = tf.argmax(y_pred, axis=1) \n",
    "   \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        # If the estimator is supposed to be in prediction-mode\n",
    "        # then use the predicted class-number that is output by\n",
    "        # the neural network. Optimization etc. is not needed.\n",
    "        \n",
    "        spec = tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                          predictions=y_pred_cls)\n",
    "    else:\n",
    "        # Otherwise the estimator is supposed to be in either\n",
    "        # training or evaluation-mode. Note that the loss-function\n",
    "        # is also required in Evaluation mode.\n",
    "        \n",
    "        # Define the loss-function to be optimized, by first\n",
    "        # calculating the cross-entropy between the output of\n",
    "        # the neural network and the true labels for the input data.\n",
    "        # This gives the cross-entropy for each image in the batch.\n",
    "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels,\n",
    "                                                                       logits=logits)\n",
    "\n",
    "        # Reduce the cross-entropy batch-tensor to a single number\n",
    "        # which can be used in optimization of the neural network.\n",
    "        tf.argmax(logits)\n",
    "        #loss = tf.losses.mean_squared_error(labels=labels, predictions=logits)\n",
    "        loss = tf.reduce_mean(cross_entropy)\n",
    "#######################\n",
    "        lr = 1e-4\n",
    "        step_rate = 5000\n",
    "        decay = 0.7 #if this equals 1 the lr stays the same\n",
    "\n",
    "        #global_step = tf.Variable(0, trainable=False)\n",
    "        #increment_global_step = tf.assign(global_step, global_step + 1)\n",
    "\n",
    "        learning_rate = tf.train.exponential_decay(lr, global_step=tf.train.get_or_create_global_step(), \n",
    "                                           decay_steps=step_rate, decay_rate=decay, staircase=True)\n",
    "        \n",
    "        # Define the optimizer for improving the neural network.\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "#         optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate) \n",
    "        \n",
    "        ''' original\n",
    "        # Get the TensorFlow op for doing a single optimization step.\n",
    "        train_op = optimizer.minimize(loss=loss, global_step = tf.train.get_or_create_global_step())\n",
    "        '''\n",
    "        # for learning parameters of batch normalization:\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            train_op = optimizer.minimize(loss, global_step=tf.train.get_or_create_global_step())\n",
    "        \n",
    "        \n",
    "#############################        \n",
    "\n",
    "\n",
    "        # Define the evaluation metrics,\n",
    "        # in this case the classification accuracy.\n",
    "        metrics = \\\n",
    "        {\n",
    "            \"accuracy\": tf.metrics.accuracy(labels, y_pred_cls) #TODO change acc method\n",
    "        }\n",
    "\n",
    "        # Wrap all of this in an EstimatorSpec.\n",
    "        spec = tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            loss=loss,\n",
    "            train_op=train_op,\n",
    "            eval_metric_ops=metrics)\n",
    "\n",
    "\n",
    "        tf.summary.scalar(\"accuracy\", metrics[\"accuracy\"][1]) \n",
    "        merge_summary_op = tf.summary.merge_all()\n",
    "\n",
    "\n",
    "            \n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {} #{\"learning_rate\": 1e-5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dir_and_comment(model_dir):\n",
    "    home = expanduser(\"~\")\n",
    "    log_name=os.path.join('logs/', model_dir + '.txt')\n",
    "    \n",
    "    if os.path.isdir(model_dir):\n",
    "        print('INFO: dir with name ' + model_dir + ' already exist.')\n",
    "    \n",
    "    new_comment=input('Please add a comment\\n')\n",
    "    \n",
    "    if os.path.exists(log_name):\n",
    "        append_write = 'a' # append if already exists\n",
    "    else:\n",
    "        append_write = 'w' # make a new file if not\n",
    "    \n",
    "    model_log = open(log_name,append_write)\n",
    "    model_log.write(home +' : '+ new_comment + '\\n')\n",
    "    model_log.close()\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: dir with name ./ckpts_28_5_mobilenetV2_15bins_02 already exist.\n",
      "Please add a comment\n",
      "startung eval\n",
      "INFO:tensorflow:Using config: {'_model_dir': './ckpts_28_5_mobilenetV2_15bins_02', '_tf_random_seed': None, '_save_summary_steps': 10, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f94049cd9b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model_dir = './ckpts_28_5_mobilenetV2_15bins_02' #'./ckpts_<day>_<month>_<architecture>_<main_change>'\n",
    "make_dir_and_comment(model_dir) \n",
    "# model = tf.estimator.Estimator(model_fn=model_fn,\n",
    "#                                params=params,\n",
    "#                                model_dir=model_dir)\n",
    "\n",
    "model = tf.estimator.Estimator(model_fn=model_fn,\n",
    "                               params=params,\n",
    "                               model_dir=model_dir,\n",
    "                               #config=tf.estimator.RunConfig(save_checkpoints_steps=1000, save_summary_steps=100)\n",
    "                               config=tf.estimator.RunConfig().replace(save_checkpoints_steps=1000,save_summary_steps=10)\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@\n",
      "(TensorShape([Dimension(64), Dimension(None), Dimension(None), Dimension(3)]), TensorShape([Dimension(64)]))\n",
      "@@@\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt-20000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 20001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.1122823, step = 20000\n",
      "INFO:tensorflow:global_step/sec: 3.58145\n",
      "INFO:tensorflow:loss = 1.1327447, step = 20100 (27.924 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.47519\n",
      "INFO:tensorflow:loss = 0.7908582, step = 20200 (22.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46842\n",
      "INFO:tensorflow:loss = 0.98103744, step = 20300 (22.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.49149\n",
      "INFO:tensorflow:loss = 1.0190346, step = 20400 (22.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4883\n",
      "INFO:tensorflow:loss = 0.91620517, step = 20500 (22.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.49199\n",
      "INFO:tensorflow:loss = 1.2070487, step = 20600 (22.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.48226\n",
      "INFO:tensorflow:loss = 1.0105302, step = 20700 (22.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46735\n",
      "INFO:tensorflow:loss = 1.0902083, step = 20800 (22.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46682\n",
      "INFO:tensorflow:loss = 0.9481356, step = 20900 (22.388 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 21001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.19031\n",
      "INFO:tensorflow:loss = 1.2219424, step = 21000 (23.863 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.47558\n",
      "INFO:tensorflow:loss = 0.851419, step = 21100 (22.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4898\n",
      "INFO:tensorflow:loss = 1.0360537, step = 21200 (22.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46877\n",
      "INFO:tensorflow:loss = 1.0875286, step = 21300 (22.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.47601\n",
      "INFO:tensorflow:loss = 1.0369475, step = 21400 (22.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.48122\n",
      "INFO:tensorflow:loss = 0.9812309, step = 21500 (22.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.48878\n",
      "INFO:tensorflow:loss = 1.0084653, step = 21600 (22.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4725\n",
      "INFO:tensorflow:loss = 0.93448234, step = 21700 (22.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.47368\n",
      "INFO:tensorflow:loss = 0.9861816, step = 21800 (22.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46248\n",
      "INFO:tensorflow:loss = 0.8365743, step = 21900 (22.409 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 22001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.18769\n",
      "INFO:tensorflow:loss = 1.0014775, step = 22000 (23.880 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.48376\n",
      "INFO:tensorflow:loss = 0.87981594, step = 22100 (22.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45747\n",
      "INFO:tensorflow:loss = 1.180953, step = 22200 (22.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.48804\n",
      "INFO:tensorflow:loss = 0.96280503, step = 22300 (22.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.48337\n",
      "INFO:tensorflow:loss = 1.1390052, step = 22400 (22.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46848\n",
      "INFO:tensorflow:loss = 0.89501226, step = 22500 (22.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4598\n",
      "INFO:tensorflow:loss = 1.0936847, step = 22600 (22.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.49714\n",
      "INFO:tensorflow:loss = 1.0975163, step = 22700 (22.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46857\n",
      "INFO:tensorflow:loss = 0.8674464, step = 22800 (22.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46439\n",
      "INFO:tensorflow:loss = 1.2114427, step = 22900 (22.400 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 23001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.17825\n",
      "INFO:tensorflow:loss = 1.1670494, step = 23000 (23.933 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45856\n",
      "INFO:tensorflow:loss = 0.8679682, step = 23100 (22.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44862\n",
      "INFO:tensorflow:loss = 1.1527075, step = 23200 (22.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46049\n",
      "INFO:tensorflow:loss = 0.8093431, step = 23300 (22.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.465\n",
      "INFO:tensorflow:loss = 1.252283, step = 23400 (22.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45313\n",
      "INFO:tensorflow:loss = 1.026081, step = 23500 (22.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44545\n",
      "INFO:tensorflow:loss = 0.83094823, step = 23600 (22.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46819\n",
      "INFO:tensorflow:loss = 1.0771708, step = 23700 (22.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45566\n",
      "INFO:tensorflow:loss = 1.0484369, step = 23800 (22.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46916\n",
      "INFO:tensorflow:loss = 0.9333685, step = 23900 (22.377 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.18446\n",
      "INFO:tensorflow:loss = 1.0273335, step = 24000 (23.897 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45508\n",
      "INFO:tensorflow:loss = 0.71272385, step = 24100 (22.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45676\n",
      "INFO:tensorflow:loss = 0.8526674, step = 24200 (22.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45916\n",
      "INFO:tensorflow:loss = 1.210755, step = 24300 (22.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46726\n",
      "INFO:tensorflow:loss = 1.0110896, step = 24400 (22.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.49078\n",
      "INFO:tensorflow:loss = 0.8129363, step = 24500 (22.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46258\n",
      "INFO:tensorflow:loss = 1.1705067, step = 24600 (22.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45375\n",
      "INFO:tensorflow:loss = 1.015093, step = 24700 (22.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44633\n",
      "INFO:tensorflow:loss = 0.7903836, step = 24800 (22.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44702\n",
      "INFO:tensorflow:loss = 0.9279921, step = 24900 (22.488 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 25001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.1811\n",
      "INFO:tensorflow:loss = 0.85692805, step = 25000 (23.916 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46047\n",
      "INFO:tensorflow:loss = 1.109218, step = 25100 (22.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46146\n",
      "INFO:tensorflow:loss = 0.98749316, step = 25200 (22.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.47632\n",
      "INFO:tensorflow:loss = 0.963874, step = 25300 (22.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45286\n",
      "INFO:tensorflow:loss = 0.91012, step = 25400 (22.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46566\n",
      "INFO:tensorflow:loss = 1.0961411, step = 25500 (22.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46998\n",
      "INFO:tensorflow:loss = 0.987152, step = 25600 (22.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.48982\n",
      "INFO:tensorflow:loss = 0.8610951, step = 25700 (22.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4704\n",
      "INFO:tensorflow:loss = 0.7542821, step = 25800 (22.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45642\n",
      "INFO:tensorflow:loss = 0.92407274, step = 25900 (22.439 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 26001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.17399\n",
      "INFO:tensorflow:loss = 1.0467409, step = 26000 (23.957 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45716\n",
      "INFO:tensorflow:loss = 0.79229605, step = 26100 (22.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44226\n",
      "INFO:tensorflow:loss = 1.07938, step = 26200 (22.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44795\n",
      "INFO:tensorflow:loss = 0.9956879, step = 26300 (22.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45395\n",
      "INFO:tensorflow:loss = 0.96804506, step = 26400 (22.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45002\n",
      "INFO:tensorflow:loss = 0.9780952, step = 26500 (22.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43651\n",
      "INFO:tensorflow:loss = 1.0275241, step = 26600 (22.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45508\n",
      "INFO:tensorflow:loss = 0.7151319, step = 26700 (22.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44292\n",
      "INFO:tensorflow:loss = 0.9303479, step = 26800 (22.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46724\n",
      "INFO:tensorflow:loss = 0.8293712, step = 26900 (22.386 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 27001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.17141\n",
      "INFO:tensorflow:loss = 0.7503854, step = 27000 (23.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45804\n",
      "INFO:tensorflow:loss = 1.0983076, step = 27100 (22.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45293\n",
      "INFO:tensorflow:loss = 0.7644135, step = 27200 (22.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45093\n",
      "INFO:tensorflow:loss = 0.9163619, step = 27300 (22.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45705\n",
      "INFO:tensorflow:loss = 1.1884911, step = 27400 (22.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46138\n",
      "INFO:tensorflow:loss = 1.0576289, step = 27500 (22.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4574\n",
      "INFO:tensorflow:loss = 0.73939884, step = 27600 (22.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46924\n",
      "INFO:tensorflow:loss = 0.9018538, step = 27700 (22.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44353\n",
      "INFO:tensorflow:loss = 0.87828803, step = 27800 (22.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45109\n",
      "INFO:tensorflow:loss = 0.68720746, step = 27900 (22.466 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 28001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.17135\n",
      "INFO:tensorflow:loss = 0.95058876, step = 28000 (23.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45243\n",
      "INFO:tensorflow:loss = 0.9481327, step = 28100 (22.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4406\n",
      "INFO:tensorflow:loss = 1.2384036, step = 28200 (22.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43906\n",
      "INFO:tensorflow:loss = 1.0346768, step = 28300 (22.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43917\n",
      "INFO:tensorflow:loss = 0.7715124, step = 28400 (22.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46057\n",
      "INFO:tensorflow:loss = 1.1848674, step = 28500 (22.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4662\n",
      "INFO:tensorflow:loss = 0.6554383, step = 28600 (22.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46907\n",
      "INFO:tensorflow:loss = 1.0084487, step = 28700 (22.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43875\n",
      "INFO:tensorflow:loss = 0.78287935, step = 28800 (22.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.445\n",
      "INFO:tensorflow:loss = 0.8899065, step = 28900 (22.497 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 29001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.17089\n",
      "INFO:tensorflow:loss = 1.1099256, step = 29000 (23.976 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45808\n",
      "INFO:tensorflow:loss = 0.980633, step = 29100 (22.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44196\n",
      "INFO:tensorflow:loss = 0.9433454, step = 29200 (22.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43781\n",
      "INFO:tensorflow:loss = 0.844918, step = 29300 (22.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43106\n",
      "INFO:tensorflow:loss = 0.7485026, step = 29400 (22.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46127\n",
      "INFO:tensorflow:loss = 0.74297947, step = 29500 (22.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44422\n",
      "INFO:tensorflow:loss = 1.1733409, step = 29600 (22.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45049\n",
      "INFO:tensorflow:loss = 0.7933879, step = 29700 (22.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44469\n",
      "INFO:tensorflow:loss = 0.8397529, step = 29800 (22.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43318\n",
      "INFO:tensorflow:loss = 1.0985591, step = 29900 (22.558 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 30001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.17754\n",
      "INFO:tensorflow:loss = 0.9859747, step = 30000 (23.937 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45586\n",
      "INFO:tensorflow:loss = 1.0600163, step = 30100 (22.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45863\n",
      "INFO:tensorflow:loss = 1.1121397, step = 30200 (22.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44597\n",
      "INFO:tensorflow:loss = 0.88182694, step = 30300 (22.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43881\n",
      "INFO:tensorflow:loss = 0.9200196, step = 30400 (22.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45715\n",
      "INFO:tensorflow:loss = 0.8756435, step = 30500 (22.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45449\n",
      "INFO:tensorflow:loss = 1.2313585, step = 30600 (22.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45322\n",
      "INFO:tensorflow:loss = 1.0093534, step = 30700 (22.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45852\n",
      "INFO:tensorflow:loss = 0.7607957, step = 30800 (22.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44138\n",
      "INFO:tensorflow:loss = 0.7579308, step = 30900 (22.516 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 31001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.17852\n",
      "INFO:tensorflow:loss = 0.7943061, step = 31000 (23.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45204\n",
      "INFO:tensorflow:loss = 1.0988584, step = 31100 (22.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43952\n",
      "INFO:tensorflow:loss = 0.8484846, step = 31200 (22.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44911\n",
      "INFO:tensorflow:loss = 0.8656286, step = 31300 (22.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44359\n",
      "INFO:tensorflow:loss = 1.1643428, step = 31400 (22.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44803\n",
      "INFO:tensorflow:loss = 0.94241124, step = 31500 (22.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46119\n",
      "INFO:tensorflow:loss = 0.77884763, step = 31600 (22.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45176\n",
      "INFO:tensorflow:loss = 0.75197816, step = 31700 (22.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45175\n",
      "INFO:tensorflow:loss = 0.96391135, step = 31800 (22.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46526\n",
      "INFO:tensorflow:loss = 0.92261076, step = 31900 (22.396 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 32001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.15707\n",
      "INFO:tensorflow:loss = 0.9971956, step = 32000 (24.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44321\n",
      "INFO:tensorflow:loss = 0.98454165, step = 32100 (22.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45424\n",
      "INFO:tensorflow:loss = 1.0205147, step = 32200 (22.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46827\n",
      "INFO:tensorflow:loss = 0.97309387, step = 32300 (22.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46245\n",
      "INFO:tensorflow:loss = 0.96277654, step = 32400 (22.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45657\n",
      "INFO:tensorflow:loss = 0.9649561, step = 32500 (22.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45174\n",
      "INFO:tensorflow:loss = 0.9756557, step = 32600 (22.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44831\n",
      "INFO:tensorflow:loss = 1.2681718, step = 32700 (22.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45471\n",
      "INFO:tensorflow:loss = 0.93210375, step = 32800 (22.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45539\n",
      "INFO:tensorflow:loss = 0.85677505, step = 32900 (22.446 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 33001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.193\n",
      "INFO:tensorflow:loss = 0.82615, step = 33000 (23.849 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46531\n",
      "INFO:tensorflow:loss = 1.0428598, step = 33100 (22.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45767\n",
      "INFO:tensorflow:loss = 0.94866836, step = 33200 (22.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45548\n",
      "INFO:tensorflow:loss = 0.7237112, step = 33300 (22.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46844\n",
      "INFO:tensorflow:loss = 0.8534636, step = 33400 (22.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45774\n",
      "INFO:tensorflow:loss = 0.8605068, step = 33500 (22.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45491\n",
      "INFO:tensorflow:loss = 0.96458393, step = 33600 (22.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46051\n",
      "INFO:tensorflow:loss = 1.2225854, step = 33700 (22.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46795\n",
      "INFO:tensorflow:loss = 1.1300002, step = 33800 (22.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.47993\n",
      "INFO:tensorflow:loss = 0.99585307, step = 33900 (22.321 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 34001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.20359\n",
      "INFO:tensorflow:loss = 0.82218593, step = 34000 (23.790 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.47629\n",
      "INFO:tensorflow:loss = 0.8281988, step = 34100 (22.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46085\n",
      "INFO:tensorflow:loss = 0.89690995, step = 34200 (22.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46861\n",
      "INFO:tensorflow:loss = 0.8530439, step = 34300 (22.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.1580826, step = 34400 (22.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4382\n",
      "INFO:tensorflow:loss = 0.8056741, step = 34500 (22.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45357\n",
      "INFO:tensorflow:loss = 0.866772, step = 34600 (22.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43326\n",
      "INFO:tensorflow:loss = 1.1325123, step = 34700 (22.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44208\n",
      "INFO:tensorflow:loss = 1.1312525, step = 34800 (22.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45266\n",
      "INFO:tensorflow:loss = 1.0041242, step = 34900 (22.456 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 35001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.17139\n",
      "INFO:tensorflow:loss = 0.5886617, step = 35000 (23.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44269\n",
      "INFO:tensorflow:loss = 0.9411204, step = 35100 (22.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45597\n",
      "INFO:tensorflow:loss = 0.95252115, step = 35200 (22.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45572\n",
      "INFO:tensorflow:loss = 1.1980301, step = 35300 (22.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45009\n",
      "INFO:tensorflow:loss = 0.9074885, step = 35400 (22.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46487\n",
      "INFO:tensorflow:loss = 1.1178162, step = 35500 (22.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.47161\n",
      "INFO:tensorflow:loss = 0.89396906, step = 35600 (22.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46325\n",
      "INFO:tensorflow:loss = 1.1770928, step = 35700 (22.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45822\n",
      "INFO:tensorflow:loss = 1.1715095, step = 35800 (22.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45224\n",
      "INFO:tensorflow:loss = 0.8679443, step = 35900 (22.460 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 36001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.15537\n",
      "INFO:tensorflow:loss = 1.0190496, step = 36000 (24.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45325\n",
      "INFO:tensorflow:loss = 1.0230191, step = 36100 (22.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46139\n",
      "INFO:tensorflow:loss = 0.97737265, step = 36200 (22.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46474\n",
      "INFO:tensorflow:loss = 0.8653116, step = 36300 (22.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44539\n",
      "INFO:tensorflow:loss = 0.85829335, step = 36400 (22.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44676\n",
      "INFO:tensorflow:loss = 0.93027747, step = 36500 (22.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46394\n",
      "INFO:tensorflow:loss = 1.072459, step = 36600 (22.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.47882\n",
      "INFO:tensorflow:loss = 0.841807, step = 36700 (22.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46908\n",
      "INFO:tensorflow:loss = 0.84512115, step = 36800 (22.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43829\n",
      "INFO:tensorflow:loss = 0.9271846, step = 36900 (22.531 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 37001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.15896\n",
      "INFO:tensorflow:loss = 0.77591395, step = 37000 (24.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.47006\n",
      "INFO:tensorflow:loss = 1.0983629, step = 37100 (22.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4557\n",
      "INFO:tensorflow:loss = 0.84178233, step = 37200 (22.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44187\n",
      "INFO:tensorflow:loss = 1.0025065, step = 37300 (22.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43538\n",
      "INFO:tensorflow:loss = 1.0544555, step = 37400 (22.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45795\n",
      "INFO:tensorflow:loss = 0.7386534, step = 37500 (22.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46938\n",
      "INFO:tensorflow:loss = 0.8987118, step = 37600 (22.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44391\n",
      "INFO:tensorflow:loss = 1.1507611, step = 37700 (22.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44446\n",
      "INFO:tensorflow:loss = 1.0660604, step = 37800 (22.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4363\n",
      "INFO:tensorflow:loss = 0.8784265, step = 37900 (22.541 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 38001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.16219\n",
      "INFO:tensorflow:loss = 1.086132, step = 38000 (24.026 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45277\n",
      "INFO:tensorflow:loss = 0.88988507, step = 38100 (22.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45792\n",
      "INFO:tensorflow:loss = 1.0538197, step = 38200 (22.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43581\n",
      "INFO:tensorflow:loss = 0.7163536, step = 38300 (22.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44881\n",
      "INFO:tensorflow:loss = 0.8921639, step = 38400 (22.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.48736\n",
      "INFO:tensorflow:loss = 1.046316, step = 38500 (22.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45945\n",
      "INFO:tensorflow:loss = 0.8065502, step = 38600 (22.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43858\n",
      "INFO:tensorflow:loss = 1.059223, step = 38700 (22.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45278\n",
      "INFO:tensorflow:loss = 1.0275034, step = 38800 (22.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44046\n",
      "INFO:tensorflow:loss = 0.83390677, step = 38900 (22.520 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 39001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.18837\n",
      "INFO:tensorflow:loss = 0.89919555, step = 39000 (23.876 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.49204\n",
      "INFO:tensorflow:loss = 0.8697072, step = 39100 (22.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45246\n",
      "INFO:tensorflow:loss = 0.87742424, step = 39200 (22.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46145\n",
      "INFO:tensorflow:loss = 1.0000684, step = 39300 (22.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46504\n",
      "INFO:tensorflow:loss = 0.93212444, step = 39400 (22.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45572\n",
      "INFO:tensorflow:loss = 0.7796408, step = 39500 (22.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46734\n",
      "INFO:tensorflow:loss = 1.0905018, step = 39600 (22.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4694\n",
      "INFO:tensorflow:loss = 0.8910495, step = 39700 (22.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43647\n",
      "INFO:tensorflow:loss = 0.91604316, step = 39800 (22.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45137\n",
      "INFO:tensorflow:loss = 0.9171789, step = 39900 (22.464 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.16569\n",
      "INFO:tensorflow:loss = 0.88661957, step = 40000 (24.006 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46062\n",
      "INFO:tensorflow:loss = 0.8083959, step = 40100 (22.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43787\n",
      "INFO:tensorflow:loss = 0.8053323, step = 40200 (22.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43435\n",
      "INFO:tensorflow:loss = 0.75396186, step = 40300 (22.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.47208\n",
      "INFO:tensorflow:loss = 0.9019702, step = 40400 (22.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45389\n",
      "INFO:tensorflow:loss = 1.188343, step = 40500 (22.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4587\n",
      "INFO:tensorflow:loss = 0.8304097, step = 40600 (22.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4722\n",
      "INFO:tensorflow:loss = 0.9550996, step = 40700 (22.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45638\n",
      "INFO:tensorflow:loss = 0.8999881, step = 40800 (22.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4512\n",
      "INFO:tensorflow:loss = 1.1466305, step = 40900 (22.466 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 41001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.1595\n",
      "INFO:tensorflow:loss = 0.6752765, step = 41000 (24.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43733\n",
      "INFO:tensorflow:loss = 0.8922981, step = 41100 (22.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44934\n",
      "INFO:tensorflow:loss = 0.9552846, step = 41200 (22.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4458\n",
      "INFO:tensorflow:loss = 0.87649345, step = 41300 (22.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45825\n",
      "INFO:tensorflow:loss = 0.805976, step = 41400 (22.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44676\n",
      "INFO:tensorflow:loss = 1.1353865, step = 41500 (22.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44783\n",
      "INFO:tensorflow:loss = 0.91421837, step = 41600 (22.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4498\n",
      "INFO:tensorflow:loss = 0.8811542, step = 41700 (22.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44974\n",
      "INFO:tensorflow:loss = 0.6857252, step = 41800 (22.475 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.45051\n",
      "INFO:tensorflow:loss = 1.0318415, step = 41900 (22.467 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 42001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.17499\n",
      "INFO:tensorflow:loss = 0.6986098, step = 42000 (23.953 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.47344\n",
      "INFO:tensorflow:loss = 1.0568323, step = 42100 (22.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4469\n",
      "INFO:tensorflow:loss = 1.0153636, step = 42200 (22.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46098\n",
      "INFO:tensorflow:loss = 1.0500965, step = 42300 (22.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45232\n",
      "INFO:tensorflow:loss = 0.9487232, step = 42400 (22.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43483\n",
      "INFO:tensorflow:loss = 0.7565691, step = 42500 (22.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4556\n",
      "INFO:tensorflow:loss = 0.9651077, step = 42600 (22.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44624\n",
      "INFO:tensorflow:loss = 1.1946346, step = 42700 (22.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.47483\n",
      "INFO:tensorflow:loss = 1.0131514, step = 42800 (22.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45417\n",
      "INFO:tensorflow:loss = 0.55741465, step = 42900 (22.450 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 43001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.16756\n",
      "INFO:tensorflow:loss = 1.3049881, step = 43000 (23.994 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44042\n",
      "INFO:tensorflow:loss = 1.034551, step = 43100 (22.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4363\n",
      "INFO:tensorflow:loss = 0.8930213, step = 43200 (22.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.47774\n",
      "INFO:tensorflow:loss = 0.9709408, step = 43300 (22.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46567\n",
      "INFO:tensorflow:loss = 0.8501571, step = 43400 (22.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44539\n",
      "INFO:tensorflow:loss = 0.7465322, step = 43500 (22.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45225\n",
      "INFO:tensorflow:loss = 0.7501533, step = 43600 (22.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43507\n",
      "INFO:tensorflow:loss = 0.8096243, step = 43700 (22.547 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4589\n",
      "INFO:tensorflow:loss = 0.92936605, step = 43800 (22.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45493\n",
      "INFO:tensorflow:loss = 0.8191647, step = 43900 (22.446 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 44001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.16745\n",
      "INFO:tensorflow:loss = 0.7086998, step = 44000 (23.996 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43024\n",
      "INFO:tensorflow:loss = 0.85600626, step = 44100 (22.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43333\n",
      "INFO:tensorflow:loss = 0.91982496, step = 44200 (22.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44495\n",
      "INFO:tensorflow:loss = 0.9091252, step = 44300 (22.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44942\n",
      "INFO:tensorflow:loss = 0.74262637, step = 44400 (22.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4485\n",
      "INFO:tensorflow:loss = 0.86216193, step = 44500 (22.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43936\n",
      "INFO:tensorflow:loss = 1.0064445, step = 44600 (22.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45065\n",
      "INFO:tensorflow:loss = 0.9219016, step = 44700 (22.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43553\n",
      "INFO:tensorflow:loss = 0.72221714, step = 44800 (22.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45893\n",
      "INFO:tensorflow:loss = 0.8438124, step = 44900 (22.428 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 45001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.17598\n",
      "INFO:tensorflow:loss = 0.81882155, step = 45000 (23.945 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45337\n",
      "INFO:tensorflow:loss = 0.80739164, step = 45100 (22.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45929\n",
      "INFO:tensorflow:loss = 0.90686697, step = 45200 (22.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45326\n",
      "INFO:tensorflow:loss = 0.84154844, step = 45300 (22.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.47507\n",
      "INFO:tensorflow:loss = 0.83212703, step = 45400 (22.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45828\n",
      "INFO:tensorflow:loss = 1.1061974, step = 45500 (22.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45186\n",
      "INFO:tensorflow:loss = 0.82353514, step = 45600 (22.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44078\n",
      "INFO:tensorflow:loss = 0.82553506, step = 45700 (22.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45005\n",
      "INFO:tensorflow:loss = 0.965852, step = 45800 (22.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45969\n",
      "INFO:tensorflow:loss = 0.9571879, step = 45900 (22.423 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 46001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.17632\n",
      "INFO:tensorflow:loss = 0.7091965, step = 46000 (23.943 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45448\n",
      "INFO:tensorflow:loss = 1.1711253, step = 46100 (22.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44489\n",
      "INFO:tensorflow:loss = 0.87691057, step = 46200 (22.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45192\n",
      "INFO:tensorflow:loss = 1.0404136, step = 46300 (22.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43251\n",
      "INFO:tensorflow:loss = 0.8040345, step = 46400 (22.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4694\n",
      "INFO:tensorflow:loss = 0.89145386, step = 46500 (22.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44972\n",
      "INFO:tensorflow:loss = 0.9046764, step = 46600 (22.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45698\n",
      "INFO:tensorflow:loss = 0.9771661, step = 46700 (22.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45035\n",
      "INFO:tensorflow:loss = 1.0662525, step = 46800 (22.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44041\n",
      "INFO:tensorflow:loss = 0.6283442, step = 46900 (22.520 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 47001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.17594\n",
      "INFO:tensorflow:loss = 0.84622574, step = 47000 (23.947 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44178\n",
      "INFO:tensorflow:loss = 0.7813474, step = 47100 (22.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45611\n",
      "INFO:tensorflow:loss = 0.9712398, step = 47200 (22.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.48181\n",
      "INFO:tensorflow:loss = 0.6963718, step = 47300 (22.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45881\n",
      "INFO:tensorflow:loss = 1.3147273, step = 47400 (22.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44034\n",
      "INFO:tensorflow:loss = 0.9974319, step = 47500 (22.520 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43851\n",
      "INFO:tensorflow:loss = 0.73194367, step = 47600 (22.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44505\n",
      "INFO:tensorflow:loss = 0.9455147, step = 47700 (22.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4505\n",
      "INFO:tensorflow:loss = 0.8672325, step = 47800 (22.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4443\n",
      "INFO:tensorflow:loss = 1.0052876, step = 47900 (22.500 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 48001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.10729\n",
      "INFO:tensorflow:loss = 0.8946546, step = 48000 (24.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44846\n",
      "INFO:tensorflow:loss = 0.92530704, step = 48100 (22.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44223\n",
      "INFO:tensorflow:loss = 0.733407, step = 48200 (22.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44304\n",
      "INFO:tensorflow:loss = 0.93692017, step = 48300 (22.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44123\n",
      "INFO:tensorflow:loss = 0.8093762, step = 48400 (22.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43326\n",
      "INFO:tensorflow:loss = 0.89598435, step = 48500 (22.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44267\n",
      "INFO:tensorflow:loss = 0.8796973, step = 48600 (22.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4416\n",
      "INFO:tensorflow:loss = 0.900427, step = 48700 (22.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44967\n",
      "INFO:tensorflow:loss = 1.2963573, step = 48800 (22.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44202\n",
      "INFO:tensorflow:loss = 0.77640325, step = 48900 (22.514 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 49001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.16187\n",
      "INFO:tensorflow:loss = 1.0167112, step = 49000 (24.026 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44172\n",
      "INFO:tensorflow:loss = 0.91941917, step = 49100 (22.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.99516106, step = 49200 (22.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45163\n",
      "INFO:tensorflow:loss = 0.8835308, step = 49300 (22.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46272\n",
      "INFO:tensorflow:loss = 0.8901174, step = 49400 (22.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44206\n",
      "INFO:tensorflow:loss = 0.973549, step = 49500 (22.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46344\n",
      "INFO:tensorflow:loss = 0.80327344, step = 49600 (22.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43024\n",
      "INFO:tensorflow:loss = 0.8822094, step = 49700 (22.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44039\n",
      "INFO:tensorflow:loss = 1.2640985, step = 49800 (22.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43269\n",
      "INFO:tensorflow:loss = 0.9773588, step = 49900 (22.561 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 50001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.13349\n",
      "INFO:tensorflow:loss = 0.76837105, step = 50000 (24.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.47357\n",
      "INFO:tensorflow:loss = 1.1231616, step = 50100 (22.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45051\n",
      "INFO:tensorflow:loss = 0.849636, step = 50200 (22.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43958\n",
      "INFO:tensorflow:loss = 0.8839898, step = 50300 (22.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46111\n",
      "INFO:tensorflow:loss = 0.8599496, step = 50400 (22.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44209\n",
      "INFO:tensorflow:loss = 0.9750687, step = 50500 (22.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44226\n",
      "INFO:tensorflow:loss = 1.1251721, step = 50600 (22.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44105\n",
      "INFO:tensorflow:loss = 0.7746195, step = 50700 (22.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46809\n",
      "INFO:tensorflow:loss = 0.69282424, step = 50800 (22.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43835\n",
      "INFO:tensorflow:loss = 1.1317542, step = 50900 (22.531 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 51001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.16661\n",
      "INFO:tensorflow:loss = 0.9959644, step = 51000 (24.000 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45891\n",
      "INFO:tensorflow:loss = 0.89964414, step = 51100 (22.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43956\n",
      "INFO:tensorflow:loss = 0.7744059, step = 51200 (22.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44386\n",
      "INFO:tensorflow:loss = 0.9248799, step = 51300 (22.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44624\n",
      "INFO:tensorflow:loss = 0.6135112, step = 51400 (22.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44641\n",
      "INFO:tensorflow:loss = 0.95003474, step = 51500 (22.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46035\n",
      "INFO:tensorflow:loss = 0.8737747, step = 51600 (22.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45545\n",
      "INFO:tensorflow:loss = 0.8304824, step = 51700 (22.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44595\n",
      "INFO:tensorflow:loss = 0.9598905, step = 51800 (22.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4514\n",
      "INFO:tensorflow:loss = 0.7820147, step = 51900 (22.466 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 52001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.17857\n",
      "INFO:tensorflow:loss = 0.8647333, step = 52000 (23.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44436\n",
      "INFO:tensorflow:loss = 0.98002845, step = 52100 (22.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45154\n",
      "INFO:tensorflow:loss = 0.8863721, step = 52200 (22.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43628\n",
      "INFO:tensorflow:loss = 1.0245621, step = 52300 (22.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43463\n",
      "INFO:tensorflow:loss = 0.7876165, step = 52400 (22.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46806\n",
      "INFO:tensorflow:loss = 0.884753, step = 52500 (22.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46828\n",
      "INFO:tensorflow:loss = 0.850054, step = 52600 (22.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46346\n",
      "INFO:tensorflow:loss = 0.90640354, step = 52700 (22.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45828\n",
      "INFO:tensorflow:loss = 0.718502, step = 52800 (22.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46453\n",
      "INFO:tensorflow:loss = 0.60567844, step = 52900 (22.398 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 53001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.21303\n",
      "INFO:tensorflow:loss = 0.91435283, step = 53000 (23.736 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.50325\n",
      "INFO:tensorflow:loss = 0.8930119, step = 53100 (22.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.49949\n",
      "INFO:tensorflow:loss = 1.0547719, step = 53200 (22.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.50892\n",
      "INFO:tensorflow:loss = 1.001468, step = 53300 (22.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.50217\n",
      "INFO:tensorflow:loss = 1.2044768, step = 53400 (22.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.49194\n",
      "INFO:tensorflow:loss = 1.1009985, step = 53500 (22.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51255\n",
      "INFO:tensorflow:loss = 0.951163, step = 53600 (22.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.50101\n",
      "INFO:tensorflow:loss = 1.0502546, step = 53700 (22.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.49874\n",
      "INFO:tensorflow:loss = 0.9698415, step = 53800 (22.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.5002\n",
      "INFO:tensorflow:loss = 1.0202934, step = 53900 (22.220 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 54001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.25113\n",
      "INFO:tensorflow:loss = 0.94102955, step = 54000 (23.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.52311\n",
      "INFO:tensorflow:loss = 1.1067388, step = 54100 (22.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51424\n",
      "INFO:tensorflow:loss = 0.90609634, step = 54200 (22.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.52159\n",
      "INFO:tensorflow:loss = 0.9770253, step = 54300 (22.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51078\n",
      "INFO:tensorflow:loss = 0.61067903, step = 54400 (22.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.50075\n",
      "INFO:tensorflow:loss = 0.8189775, step = 54500 (22.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51218\n",
      "INFO:tensorflow:loss = 0.9556768, step = 54600 (22.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51049\n",
      "INFO:tensorflow:loss = 0.9513856, step = 54700 (22.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.52226\n",
      "INFO:tensorflow:loss = 0.8074651, step = 54800 (22.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51162\n",
      "INFO:tensorflow:loss = 0.781788, step = 54900 (22.165 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 55001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.2374\n",
      "INFO:tensorflow:loss = 0.9859733, step = 55000 (23.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51963\n",
      "INFO:tensorflow:loss = 0.963376, step = 55100 (22.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.50778\n",
      "INFO:tensorflow:loss = 0.9708942, step = 55200 (22.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.50564\n",
      "INFO:tensorflow:loss = 0.6690655, step = 55300 (22.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.49374\n",
      "INFO:tensorflow:loss = 0.89567184, step = 55400 (22.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.50943\n",
      "INFO:tensorflow:loss = 1.2471809, step = 55500 (22.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51221\n",
      "INFO:tensorflow:loss = 1.0401006, step = 55600 (22.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51249\n",
      "INFO:tensorflow:loss = 0.66892403, step = 55700 (22.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.50618\n",
      "INFO:tensorflow:loss = 0.83924663, step = 55800 (22.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51813\n",
      "INFO:tensorflow:loss = 1.0724983, step = 55900 (22.133 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 56001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.24606\n",
      "INFO:tensorflow:loss = 1.0286272, step = 56000 (23.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.50562\n",
      "INFO:tensorflow:loss = 1.0689442, step = 56100 (22.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.50533\n",
      "INFO:tensorflow:loss = 0.9467501, step = 56200 (22.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.52151\n",
      "INFO:tensorflow:loss = 0.88218033, step = 56300 (22.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51625\n",
      "INFO:tensorflow:loss = 0.7969649, step = 56400 (22.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.5153\n",
      "INFO:tensorflow:loss = 0.84828985, step = 56500 (22.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.5253\n",
      "INFO:tensorflow:loss = 1.0039666, step = 56600 (22.096 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.5035\n",
      "INFO:tensorflow:loss = 0.76004076, step = 56700 (22.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.52281\n",
      "INFO:tensorflow:loss = 1.0328228, step = 56800 (22.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51686\n",
      "INFO:tensorflow:loss = 0.61193347, step = 56900 (22.140 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 57001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.24549\n",
      "INFO:tensorflow:loss = 0.9931462, step = 57000 (23.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.50145\n",
      "INFO:tensorflow:loss = 0.81999874, step = 57100 (22.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51229\n",
      "INFO:tensorflow:loss = 0.7797808, step = 57200 (22.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51201\n",
      "INFO:tensorflow:loss = 0.93874776, step = 57300 (22.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51338\n",
      "INFO:tensorflow:loss = 0.7742004, step = 57400 (22.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.50126\n",
      "INFO:tensorflow:loss = 0.8039547, step = 57500 (22.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.50151\n",
      "INFO:tensorflow:loss = 0.9959496, step = 57600 (22.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.49285\n",
      "INFO:tensorflow:loss = 0.70719403, step = 57700 (22.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.49647\n",
      "INFO:tensorflow:loss = 0.97966695, step = 57800 (22.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51017\n",
      "INFO:tensorflow:loss = 1.0580606, step = 57900 (22.173 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 58001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.23582\n",
      "INFO:tensorflow:loss = 0.8616618, step = 58000 (23.607 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51237\n",
      "INFO:tensorflow:loss = 0.7803706, step = 58100 (22.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51157\n",
      "INFO:tensorflow:loss = 0.9170836, step = 58200 (22.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51843\n",
      "INFO:tensorflow:loss = 0.91829133, step = 58300 (22.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.52121\n",
      "INFO:tensorflow:loss = 0.75425315, step = 58400 (22.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51287\n",
      "INFO:tensorflow:loss = 1.0938815, step = 58500 (22.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.50926\n",
      "INFO:tensorflow:loss = 0.71984684, step = 58600 (22.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.5217\n",
      "INFO:tensorflow:loss = 0.9652749, step = 58700 (22.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.5119\n",
      "INFO:tensorflow:loss = 1.0947416, step = 58800 (22.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51425\n",
      "INFO:tensorflow:loss = 0.7041639, step = 58900 (22.153 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 59001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.24332\n",
      "INFO:tensorflow:loss = 0.97005296, step = 59000 (23.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51225\n",
      "INFO:tensorflow:loss = 0.9766811, step = 59100 (22.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51201\n",
      "INFO:tensorflow:loss = 0.7285948, step = 59200 (22.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51974\n",
      "INFO:tensorflow:loss = 0.90103877, step = 59300 (22.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51538\n",
      "INFO:tensorflow:loss = 0.7785678, step = 59400 (22.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.52129\n",
      "INFO:tensorflow:loss = 0.6839968, step = 59500 (22.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51126\n",
      "INFO:tensorflow:loss = 0.7765528, step = 59600 (22.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.52336\n",
      "INFO:tensorflow:loss = 0.6445444, step = 59700 (22.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51673\n",
      "INFO:tensorflow:loss = 0.8594686, step = 59800 (22.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51613\n",
      "INFO:tensorflow:loss = 0.80730045, step = 59900 (22.144 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 60001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.24126\n",
      "INFO:tensorflow:loss = 0.99748015, step = 60000 (23.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51063\n",
      "INFO:tensorflow:loss = 0.83886564, step = 60100 (22.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51795\n",
      "INFO:tensorflow:loss = 0.9083395, step = 60200 (22.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.52079\n",
      "INFO:tensorflow:loss = 0.9341545, step = 60300 (22.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51396\n",
      "INFO:tensorflow:loss = 0.6373491, step = 60400 (22.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51116\n",
      "INFO:tensorflow:loss = 0.7965228, step = 60500 (22.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51914\n",
      "INFO:tensorflow:loss = 0.80287457, step = 60600 (22.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51322\n",
      "INFO:tensorflow:loss = 0.9586309, step = 60700 (22.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.50821\n",
      "INFO:tensorflow:loss = 0.7890116, step = 60800 (22.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.5255\n",
      "INFO:tensorflow:loss = 0.8319769, step = 60900 (22.098 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 61001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.25462\n",
      "INFO:tensorflow:loss = 0.947431, step = 61000 (23.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51383\n",
      "INFO:tensorflow:loss = 0.99514437, step = 61100 (22.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.50732\n",
      "INFO:tensorflow:loss = 0.87346935, step = 61200 (22.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.50891\n",
      "INFO:tensorflow:loss = 0.88873136, step = 61300 (22.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51788\n",
      "INFO:tensorflow:loss = 0.5930865, step = 61400 (22.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51357\n",
      "INFO:tensorflow:loss = 0.75349545, step = 61500 (22.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51191\n",
      "INFO:tensorflow:loss = 0.9136021, step = 61600 (22.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51528\n",
      "INFO:tensorflow:loss = 0.97002673, step = 61700 (22.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.52617\n",
      "INFO:tensorflow:loss = 0.9247378, step = 61800 (22.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51773\n",
      "INFO:tensorflow:loss = 0.7482701, step = 61900 (22.135 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 62001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.23643\n",
      "INFO:tensorflow:loss = 1.094276, step = 62000 (23.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.5192\n",
      "INFO:tensorflow:loss = 1.0270147, step = 62100 (22.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51026\n",
      "INFO:tensorflow:loss = 0.77333796, step = 62200 (22.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51204\n",
      "INFO:tensorflow:loss = 0.99299, step = 62300 (22.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51523\n",
      "INFO:tensorflow:loss = 0.84108984, step = 62400 (22.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51484\n",
      "INFO:tensorflow:loss = 1.1029861, step = 62500 (22.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51538\n",
      "INFO:tensorflow:loss = 0.7277589, step = 62600 (22.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51374\n",
      "INFO:tensorflow:loss = 0.9758463, step = 62700 (22.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.50922\n",
      "INFO:tensorflow:loss = 1.0470643, step = 62800 (22.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51494\n",
      "INFO:tensorflow:loss = 0.959838, step = 62900 (22.148 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 63001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.23807\n",
      "INFO:tensorflow:loss = 0.89353234, step = 63000 (23.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51295\n",
      "INFO:tensorflow:loss = 0.73117745, step = 63100 (22.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51902\n",
      "INFO:tensorflow:loss = 0.8125182, step = 63200 (22.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.50929\n",
      "INFO:tensorflow:loss = 0.9580334, step = 63300 (22.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.52336\n",
      "INFO:tensorflow:loss = 0.9372043, step = 63400 (22.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51188\n",
      "INFO:tensorflow:loss = 0.7649386, step = 63500 (22.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51527\n",
      "INFO:tensorflow:loss = 0.9823126, step = 63600 (22.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51606\n",
      "INFO:tensorflow:loss = 1.2638845, step = 63700 (22.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.52195\n",
      "INFO:tensorflow:loss = 0.7558064, step = 63800 (22.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51397\n",
      "INFO:tensorflow:loss = 0.7832918, step = 63900 (22.154 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 64001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.24024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.8514335, step = 64000 (23.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.50153\n",
      "INFO:tensorflow:loss = 0.8962941, step = 64100 (22.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.49873\n",
      "INFO:tensorflow:loss = 1.0709634, step = 64200 (22.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.49116\n",
      "INFO:tensorflow:loss = 0.9650222, step = 64300 (22.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.48383\n",
      "INFO:tensorflow:loss = 0.88516104, step = 64400 (22.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.49803\n",
      "INFO:tensorflow:loss = 0.9250408, step = 64500 (22.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.48437\n",
      "INFO:tensorflow:loss = 0.87893534, step = 64600 (22.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.49276\n",
      "INFO:tensorflow:loss = 1.0233209, step = 64700 (22.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.49396\n",
      "INFO:tensorflow:loss = 0.941723, step = 64800 (22.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.49663\n",
      "INFO:tensorflow:loss = 0.7049805, step = 64900 (22.241 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 65001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.23511\n",
      "INFO:tensorflow:loss = 0.92718196, step = 65000 (23.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.49145\n",
      "INFO:tensorflow:loss = 0.88534564, step = 65100 (22.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.48735\n",
      "INFO:tensorflow:loss = 0.83121777, step = 65200 (22.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.49487\n",
      "INFO:tensorflow:loss = 0.79050785, step = 65300 (22.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.49338\n",
      "INFO:tensorflow:loss = 0.8849957, step = 65400 (22.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.49554\n",
      "INFO:tensorflow:loss = 0.8514253, step = 65500 (22.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.49556\n",
      "INFO:tensorflow:loss = 0.73472947, step = 65600 (22.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.50013\n",
      "INFO:tensorflow:loss = 0.71326584, step = 65700 (22.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51714\n",
      "INFO:tensorflow:loss = 0.7638701, step = 65800 (22.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51725\n",
      "INFO:tensorflow:loss = 0.8330347, step = 65900 (22.138 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 66001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.24817\n",
      "INFO:tensorflow:loss = 0.95702326, step = 66000 (23.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51529\n",
      "INFO:tensorflow:loss = 0.93386436, step = 66100 (22.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51253\n",
      "INFO:tensorflow:loss = 1.0723722, step = 66200 (22.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51625\n",
      "INFO:tensorflow:loss = 0.93193734, step = 66300 (22.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.5144\n",
      "INFO:tensorflow:loss = 1.0088375, step = 66400 (22.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.5111\n",
      "INFO:tensorflow:loss = 0.93828475, step = 66500 (22.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51729\n",
      "INFO:tensorflow:loss = 0.97750497, step = 66600 (22.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51832\n",
      "INFO:tensorflow:loss = 0.76018757, step = 66700 (22.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.50923\n",
      "INFO:tensorflow:loss = 0.87312406, step = 66800 (22.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51529\n",
      "INFO:tensorflow:loss = 0.92124414, step = 66900 (22.147 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 67001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.24751\n",
      "INFO:tensorflow:loss = 0.86552525, step = 67000 (23.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51201\n",
      "INFO:tensorflow:loss = 0.84317213, step = 67100 (22.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51108\n",
      "INFO:tensorflow:loss = 0.8738729, step = 67200 (22.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51844\n",
      "INFO:tensorflow:loss = 0.93183875, step = 67300 (22.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.52116\n",
      "INFO:tensorflow:loss = 0.768114, step = 67400 (22.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51226\n",
      "INFO:tensorflow:loss = 0.8370687, step = 67500 (22.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51628\n",
      "INFO:tensorflow:loss = 0.86980915, step = 67600 (22.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51468\n",
      "INFO:tensorflow:loss = 0.93067867, step = 67700 (22.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51002\n",
      "INFO:tensorflow:loss = 1.1831454, step = 67800 (22.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51399\n",
      "INFO:tensorflow:loss = 0.7650237, step = 67900 (22.154 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 68001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.24178\n",
      "INFO:tensorflow:loss = 0.84735626, step = 68000 (23.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.50469\n",
      "INFO:tensorflow:loss = 1.110385, step = 68100 (22.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.50912\n",
      "INFO:tensorflow:loss = 0.8222897, step = 68200 (22.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.50976\n",
      "INFO:tensorflow:loss = 1.0948563, step = 68300 (22.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.50403\n",
      "INFO:tensorflow:loss = 0.78314984, step = 68400 (22.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51715\n",
      "INFO:tensorflow:loss = 0.97029626, step = 68500 (22.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.52005\n",
      "INFO:tensorflow:loss = 0.84240794, step = 68600 (22.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51708\n",
      "INFO:tensorflow:loss = 0.82382554, step = 68700 (22.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51084\n",
      "INFO:tensorflow:loss = 0.85769784, step = 68800 (22.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.50111\n",
      "INFO:tensorflow:loss = 0.8647044, step = 68900 (22.216 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 69001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.23665\n",
      "INFO:tensorflow:loss = 0.9379074, step = 69000 (23.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.5087\n",
      "INFO:tensorflow:loss = 0.93963605, step = 69100 (22.180 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.50525\n",
      "INFO:tensorflow:loss = 0.95503867, step = 69200 (22.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51104\n",
      "INFO:tensorflow:loss = 1.043088, step = 69300 (22.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.506\n",
      "INFO:tensorflow:loss = 0.9219941, step = 69400 (22.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.5154\n",
      "INFO:tensorflow:loss = 0.9258803, step = 69500 (22.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.52627\n",
      "INFO:tensorflow:loss = 1.0610716, step = 69600 (22.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51981\n",
      "INFO:tensorflow:loss = 1.1293699, step = 69700 (22.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.52202\n",
      "INFO:tensorflow:loss = 0.76381695, step = 69800 (22.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.50537\n",
      "INFO:tensorflow:loss = 0.96643305, step = 69900 (22.196 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 70001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.23837\n",
      "INFO:tensorflow:loss = 0.8235913, step = 70000 (23.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51909\n",
      "INFO:tensorflow:loss = 0.8758944, step = 70100 (22.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51269\n",
      "INFO:tensorflow:loss = 0.7771226, step = 70200 (22.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.47454\n",
      "INFO:tensorflow:loss = 0.769576, step = 70300 (22.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44512\n",
      "INFO:tensorflow:loss = 1.0169959, step = 70400 (22.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45929\n",
      "INFO:tensorflow:loss = 0.80631644, step = 70500 (22.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44578\n",
      "INFO:tensorflow:loss = 1.0003815, step = 70600 (22.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46303\n",
      "INFO:tensorflow:loss = 0.8849044, step = 70700 (22.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45361\n",
      "INFO:tensorflow:loss = 0.798689, step = 70800 (22.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44691\n",
      "INFO:tensorflow:loss = 0.9099299, step = 70900 (22.487 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 71001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.1767\n",
      "INFO:tensorflow:loss = 0.880198, step = 71000 (23.944 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45403\n",
      "INFO:tensorflow:loss = 0.7568224, step = 71100 (22.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4486\n",
      "INFO:tensorflow:loss = 0.9270918, step = 71200 (22.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44603\n",
      "INFO:tensorflow:loss = 1.0846063, step = 71300 (22.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44695\n",
      "INFO:tensorflow:loss = 1.0811176, step = 71400 (22.489 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.47496\n",
      "INFO:tensorflow:loss = 0.9170051, step = 71500 (22.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.47819\n",
      "INFO:tensorflow:loss = 0.85783136, step = 71600 (22.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.48509\n",
      "INFO:tensorflow:loss = 0.88008577, step = 71700 (22.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.49309\n",
      "INFO:tensorflow:loss = 1.1118143, step = 71800 (22.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.50048\n",
      "INFO:tensorflow:loss = 0.9375118, step = 71900 (22.220 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 72001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.20688\n",
      "INFO:tensorflow:loss = 1.0222898, step = 72000 (23.771 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.49929\n",
      "INFO:tensorflow:loss = 0.9413647, step = 72100 (22.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4729\n",
      "INFO:tensorflow:loss = 0.9645352, step = 72200 (22.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45497\n",
      "INFO:tensorflow:loss = 0.6562095, step = 72300 (22.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.48047\n",
      "INFO:tensorflow:loss = 0.7930465, step = 72400 (22.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.49117\n",
      "INFO:tensorflow:loss = 1.2020402, step = 72500 (22.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.48863\n",
      "INFO:tensorflow:loss = 0.70247483, step = 72600 (22.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.48159\n",
      "INFO:tensorflow:loss = 0.97879076, step = 72700 (22.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.47005\n",
      "INFO:tensorflow:loss = 1.0586711, step = 72800 (22.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46246\n",
      "INFO:tensorflow:loss = 1.041788, step = 72900 (22.410 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 73001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.1857\n",
      "INFO:tensorflow:loss = 1.0788387, step = 73000 (23.890 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.49617\n",
      "INFO:tensorflow:loss = 0.76386213, step = 73100 (22.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46916\n",
      "INFO:tensorflow:loss = 0.80272096, step = 73200 (22.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45536\n",
      "INFO:tensorflow:loss = 0.8597143, step = 73300 (22.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43994\n",
      "INFO:tensorflow:loss = 0.8212573, step = 73400 (22.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46862\n",
      "INFO:tensorflow:loss = 1.0141159, step = 73500 (22.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.48364\n",
      "INFO:tensorflow:loss = 1.1847367, step = 73600 (22.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.47173\n",
      "INFO:tensorflow:loss = 0.9738308, step = 73700 (22.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.49271\n",
      "INFO:tensorflow:loss = 0.89382106, step = 73800 (22.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.48247\n",
      "INFO:tensorflow:loss = 0.8921733, step = 73900 (22.309 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 74001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.19042\n",
      "INFO:tensorflow:loss = 0.8610162, step = 74000 (23.865 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.49888\n",
      "INFO:tensorflow:loss = 1.0871096, step = 74100 (22.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46495\n",
      "INFO:tensorflow:loss = 0.8155587, step = 74200 (22.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44862\n",
      "INFO:tensorflow:loss = 0.9360622, step = 74300 (22.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46574\n",
      "INFO:tensorflow:loss = 0.9847743, step = 74400 (22.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.48457\n",
      "INFO:tensorflow:loss = 1.0379556, step = 74500 (22.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46611\n",
      "INFO:tensorflow:loss = 1.0351728, step = 74600 (22.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.48321\n",
      "INFO:tensorflow:loss = 0.92151827, step = 74700 (22.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46493\n",
      "INFO:tensorflow:loss = 0.9241201, step = 74800 (22.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44669\n",
      "INFO:tensorflow:loss = 0.8125322, step = 74900 (22.489 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 75001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.18508\n",
      "INFO:tensorflow:loss = 0.9739287, step = 75000 (23.894 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45987\n",
      "INFO:tensorflow:loss = 0.8382926, step = 75100 (22.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46404\n",
      "INFO:tensorflow:loss = 0.8328428, step = 75200 (22.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.48183\n",
      "INFO:tensorflow:loss = 0.8727816, step = 75300 (22.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.48255\n",
      "INFO:tensorflow:loss = 0.68197966, step = 75400 (22.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.47483\n",
      "INFO:tensorflow:loss = 0.7936009, step = 75500 (22.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4668\n",
      "INFO:tensorflow:loss = 0.8958986, step = 75600 (22.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.47927\n",
      "INFO:tensorflow:loss = 1.0872433, step = 75700 (22.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46595\n",
      "INFO:tensorflow:loss = 0.92865926, step = 75800 (22.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.47492\n",
      "INFO:tensorflow:loss = 0.8496424, step = 75900 (22.348 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 76001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.16255\n",
      "INFO:tensorflow:loss = 0.715607, step = 76000 (24.023 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44198\n",
      "INFO:tensorflow:loss = 0.8135815, step = 76100 (22.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4432\n",
      "INFO:tensorflow:loss = 1.0305692, step = 76200 (22.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44752\n",
      "INFO:tensorflow:loss = 0.99603283, step = 76300 (22.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44501\n",
      "INFO:tensorflow:loss = 0.6927992, step = 76400 (22.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45427\n",
      "INFO:tensorflow:loss = 0.80954534, step = 76500 (22.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43938\n",
      "INFO:tensorflow:loss = 0.62495816, step = 76600 (22.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45992\n",
      "INFO:tensorflow:loss = 1.0422962, step = 76700 (22.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46706\n",
      "INFO:tensorflow:loss = 0.9507395, step = 76800 (22.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46794\n",
      "INFO:tensorflow:loss = 0.8326562, step = 76900 (22.381 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 77001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.16039\n",
      "INFO:tensorflow:loss = 0.9561361, step = 77000 (24.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45116\n",
      "INFO:tensorflow:loss = 1.0838842, step = 77100 (22.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45359\n",
      "INFO:tensorflow:loss = 0.7733777, step = 77200 (22.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45111\n",
      "INFO:tensorflow:loss = 1.03299, step = 77300 (22.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44932\n",
      "INFO:tensorflow:loss = 0.9219548, step = 77400 (22.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44499\n",
      "INFO:tensorflow:loss = 1.2109332, step = 77500 (22.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43846\n",
      "INFO:tensorflow:loss = 0.9944477, step = 77600 (22.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4473\n",
      "INFO:tensorflow:loss = 0.96673745, step = 77700 (22.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44336\n",
      "INFO:tensorflow:loss = 0.9367045, step = 77800 (22.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46073\n",
      "INFO:tensorflow:loss = 0.7261096, step = 77900 (22.416 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 78001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.17412\n",
      "INFO:tensorflow:loss = 0.6894459, step = 78000 (23.957 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44853\n",
      "INFO:tensorflow:loss = 0.9086761, step = 78100 (22.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44032\n",
      "INFO:tensorflow:loss = 0.87019426, step = 78200 (22.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43538\n",
      "INFO:tensorflow:loss = 0.7020566, step = 78300 (22.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.42973\n",
      "INFO:tensorflow:loss = 1.2099977, step = 78400 (22.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44723\n",
      "INFO:tensorflow:loss = 1.1796817, step = 78500 (22.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.42719\n",
      "INFO:tensorflow:loss = 1.0169672, step = 78600 (22.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.4328\n",
      "INFO:tensorflow:loss = 1.0495653, step = 78700 (22.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43393\n",
      "INFO:tensorflow:loss = 0.7776854, step = 78800 (22.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.77884686, step = 78900 (22.573 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 79001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.16471\n",
      "INFO:tensorflow:loss = 0.869418, step = 79000 (24.010 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45211\n",
      "INFO:tensorflow:loss = 0.76541805, step = 79100 (22.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44265\n",
      "INFO:tensorflow:loss = 0.96237177, step = 79200 (22.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46436\n",
      "INFO:tensorflow:loss = 0.81282604, step = 79300 (22.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45696\n",
      "INFO:tensorflow:loss = 0.79503584, step = 79400 (22.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45138\n",
      "INFO:tensorflow:loss = 0.785702, step = 79500 (22.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43685\n",
      "INFO:tensorflow:loss = 0.72553384, step = 79600 (22.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43417\n",
      "INFO:tensorflow:loss = 1.0326282, step = 79700 (22.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43297\n",
      "INFO:tensorflow:loss = 0.8842576, step = 79800 (22.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43727\n",
      "INFO:tensorflow:loss = 0.9222629, step = 79900 (22.537 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 80001 into ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 4.14185\n",
      "INFO:tensorflow:loss = 0.87907666, step = 80000 (24.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.40394\n",
      "INFO:tensorflow:loss = 0.7864628, step = 80100 (22.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43281\n",
      "INFO:tensorflow:loss = 1.0168089, step = 80200 (22.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.41949\n",
      "INFO:tensorflow:loss = 0.90646803, step = 80300 (22.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43984\n",
      "INFO:tensorflow:loss = 0.87230814, step = 80400 (22.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.42682\n",
      "INFO:tensorflow:loss = 0.9702604, step = 80500 (22.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.42865\n",
      "INFO:tensorflow:loss = 0.7332376, step = 80600 (22.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.40761\n",
      "INFO:tensorflow:loss = 0.7801678, step = 80700 (22.691 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.40616\n",
      "INFO:tensorflow:loss = 0.9174027, step = 80800 (22.695 sec)\n"
     ]
    }
   ],
   "source": [
    "model.train(input_fn=train_input_fn, steps=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###DONE TRAIN###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@\n",
      "(TensorShape([Dimension(64), Dimension(None), Dimension(None), Dimension(3)]), TensorShape([Dimension(64)]))\n",
      "@@@\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-29-06:21:39\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./ckpts_28_5_mobilenetV2_15bins_02/model.ckpt-81001\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "#performance on training dataset:\n",
    "def train_partial_input_fn():\n",
    "#     return input_fn(path_tfrecords_train_lst[7000:8500], train=False) \n",
    "    return input_fn(path_tfrecords_train_lst, train=False) \n",
    "\n",
    "train_partial_result = model.evaluate(input_fn=train_partial_input_fn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#VAL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrec_val_batch_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrec_val_directory = os.path.join('..','datasets','stixels','val','tfrec_batch_size_'+str(tfrec_val_batch_size))#+'_percent_'+str(percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_tfrecords_val_lst=[]\n",
    "path_tfrecords_val = os.path.join(img_path, 'val')\n",
    "for root, dirs, files in os.walk(tfrec_val_directory):\n",
    "    for file in files:\n",
    "        if '.tfrecord' in file:\n",
    "            path_tfrecords_val_lst.append(os.path.join(tfrec_val_directory,file))\n",
    "        else:\n",
    "            print('WARNING: file ' + file + 'looks suspicious. does it belong here?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_input_fn():\n",
    "    return input_fn(path_tfrecords_val_lst[4000:5500], train=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_result = model.evaluate(input_fn=val_input_fn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.26630434, 'global_step': 100000, 'loss': 2.224182}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification val accuracy: 26.63%\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification val accuracy: {0:.2%}\".format(val_result[\"accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TEST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfrec_test_batch_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfrec_test_directory = os.path.join('..','datasets','stixels','test','tfrec_batch_size_'+str(tfrec_test_batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_tfrecords_test_lst=[]\n",
    "path_tfrecords_test = os.path.join(img_path, 'test')\n",
    "for root, dirs, files in os.walk(tfrec_test_directory):\n",
    "    for file in files:\n",
    "        if '.tfrecord' in file:\n",
    "            path_tfrecords_test_lst.append(os.path.join(tfrec_test_directory,file))\n",
    "        else:\n",
    "            print('WARNING: file ' + file + 'looks suspicious. does it belong here?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_input_fn():\n",
    "    return input_fn(filenames=path_tfrecords_test_lst[1000:2500], train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@\n",
      "(TensorShape([Dimension(64), Dimension(None), Dimension(None), Dimension(3)]), TensorShape([Dimension(64)]))\n",
      "@@@\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-28-15:58:19\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./ckpts_28_5_mobilenetV2_partial_midSize10_kernels_varies_midLR/model.ckpt-20000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-28-15:58:25\n",
      "INFO:tensorflow:Saving dict for global step 20000: accuracy = 0.18953805, global_step = 20000, loss = 2.6755853\n"
     ]
    }
   ],
   "source": [
    "test_result = model.evaluate(input_fn=test_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification test accuracy: 11.55%\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification test accuracy: {0:.2%}\".format(test_result[\"accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PRED:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum_csv_test_path = os.path.join(img_path,'train', 'sum_csv') #TEST\n",
    "labels_test=pd.read_csv(os.path.join(sum_csv_test_path,'labels_train_'+str(percent)+'percent.csv'))\n",
    "test_names_list=list(labels_test['Name'])\n",
    "image_paths_test=[]\n",
    "for name in test_names_list:\n",
    "    image_paths_test.append(os.path.join(img_path, 'train', name+'.png')) #maybe no need to add '.png'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_images(image_paths):\n",
    "    # Load the images from disk.\n",
    "    images = [imread(path) for path in image_paths]\n",
    "    # Convert to a numpy array and return it.\n",
    "    return np.asarray(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##TODO:SHUFFLE!\n",
    "some_num=1500\n",
    "some_images = load_images(image_paths=image_paths_test[7000:7000+some_num])\n",
    "some_images_cls = np.array(labels_test['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"image\": some_images.astype(np.float32)},\n",
    "    num_epochs=1,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(input_fn=predict_input_fn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Estimator.predict at 0x7fb884129fc0>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./ckpts_28_5_mobilenetV2_partial_midSize10_kernels_varies_midLR/model.ckpt-20000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([46, 46, 46, ..., 46, 46, 46])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_pred = np.array(list(predictions))\n",
    "cls_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500,)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    0,     5,     5,    21,    71,   313,   150,  1079,  3691,\n",
       "         6280, 11605, 13872, 16378, 17646, 19292, 18101, 19392, 17603,\n",
       "        16215, 15047, 14708, 15527, 14560, 14073, 14708, 13082, 13245,\n",
       "        12922, 10970, 11509, 10997, 10722, 10903,  9856,  9444,  9308,\n",
       "         7769,  5462,  2876,  1092,   241,    23,     0,     0,     0,\n",
       "         7815]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "        34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46]))"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram(some_images_cls, bins= [x for x in range(0, 47, 1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0, 1500]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "        34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46]))"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram(cls_pred, bins= [x for x in range(0, 47, 1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.63838133e-08, 5.23802601e-06, 2.41361181e-06, 8.22993752e-06,\n",
       "       6.88640721e-05, 6.73187096e-05, 1.12743000e-04, 2.48558167e-03,\n",
       "       2.41161394e-03, 1.98379252e-03, 1.63461361e-03, 3.52152251e-03,\n",
       "       4.75671981e-03, 8.01659003e-03, 9.75785963e-03, 8.38503707e-03,\n",
       "       5.74642140e-03, 7.23679783e-03, 7.88456481e-03, 1.14491200e-02,\n",
       "       1.59071349e-02, 1.35434372e-02, 5.99773182e-03, 4.06883238e-03,\n",
       "       6.72300300e-03, 8.37637670e-03, 1.83306281e-02, 2.76202224e-02,\n",
       "       2.98272502e-02, 2.47496460e-02, 1.82593651e-02, 4.35408838e-02,\n",
       "       2.88887601e-02, 3.89404297e-02, 9.61616039e-02, 1.31164491e-01,\n",
       "       6.05020821e-02, 3.79621610e-02, 1.50133632e-02, 7.29497289e-03,\n",
       "       4.58270835e-04, 1.19983735e-04, 5.25741832e-08, 3.36415056e-08,\n",
       "       4.82108398e-08, 3.18117941e-08, 2.91014105e-01], dtype=float32)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_pred[67]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([46, 46, 46, ..., 46, 46, 46])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(cls_pred,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0, 1500]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "        34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46]))"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram(np.argmax(cls_pred,axis=1), bins= [x for x in range(0, 47, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(cls_pred,axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(cls_pred[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_cls = tf.argmax(cls_pred, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ArgMax:0' shape=(100,) dtype=int64>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/noa_raindel/.TFgpu/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "[46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46\n",
      " 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46\n",
      " 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46\n",
      " 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46\n",
      " 46 46 46 46]\n"
     ]
    }
   ],
   "source": [
    "init_op = tf.initialize_all_variables()\n",
    "with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "        print (sess.run(y_pred_cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
