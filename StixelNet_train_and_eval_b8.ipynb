{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########now part 2: decode and train#######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "#from preprocess_func_new import *\n",
    "from matplotlib.image import imread\n",
    "import os\n",
    "from os.path import expanduser\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=8\n",
    "val_batch_size=batch_size\n",
    "test_batch_size=batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../datasets/stixels'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path = os.path.join('..','datasets','stixels')\n",
    "img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train\n",
    "tfrec_train_directory = os.path.join('..','datasets','stixels','train','tfrec_batch_size_'+str(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train\n",
    "path_tfrecords_train_lst=[]\n",
    "path_tfrecords_train = os.path.join(img_path, 'train')\n",
    "for root, dirs, files in os.walk(tfrec_train_directory):\n",
    "    for file in files:\n",
    "        if '.tfrecord' in file:\n",
    "            path_tfrecords_train_lst.append(os.path.join(tfrec_train_directory,file))\n",
    "        else:\n",
    "            print('WARNING: file ' + file + 'looks suspicious. does it belong here?')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "H=370 \n",
    "W=24\n",
    "C=3\n",
    "img_shape = (H, W, C)\n",
    "num_classes = 47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(serialized):\n",
    "    # Define a dict with the data-names and types we expect to\n",
    "    # find in the TFRecords file.\n",
    "    # It is a bit awkward that this needs to be specified again,\n",
    "    # because it could have been written in the header of the\n",
    "    # TFRecords file instead.\n",
    "    features = \\\n",
    "        {\n",
    "            'image': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.int64)\n",
    "        }\n",
    "\n",
    "    # Parse the serialized data so we get a dict with our data.\n",
    "    parsed_example = tf.parse_single_example(serialized=serialized,\n",
    "                                             features=features)\n",
    "\n",
    "    # Get the image as raw bytes.\n",
    "    image_raw = parsed_example['image']\n",
    "\n",
    "    # Decode the raw bytes so it becomes a tensor with type.\n",
    "    #######image = tf.decode_raw(image_raw, tf.int32) ####\n",
    "    image = tf.image.decode_png(image_raw, channels=3, dtype=tf.uint16)\n",
    "    #image = tf.cast(image, tf.int32)\n",
    "\n",
    "    # The type is now uint8 but we need it to be float.\n",
    "    \n",
    "    image = tf.cast(image, tf.float32) ####\n",
    "    \n",
    "    # Get the label associated with the image.\n",
    "    label = parsed_example['label']\n",
    "\n",
    "    # The image and label are now correct TensorFlow types.\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_fn(filenames, train, batch_size=batch_size, buffer_size=40000): #2048\n",
    "    # Args:\n",
    "    # filenames:   Filenames for the TFRecords files.\n",
    "    # train:       Boolean whether training (True) or testing (False).\n",
    "    # batch_size:  Return batches of this size.\n",
    "    # buffer_size: Read buffers of this size. The random shuffling\n",
    "    #              is done on the buffer, so it must be big enough.\n",
    "\n",
    "    # Create a TensorFlow Dataset-object which has functionality\n",
    "    # for reading and shuffling data from TFRecords files.\n",
    "    dataset = tf.data.TFRecordDataset(filenames=filenames)\n",
    "\n",
    "    # Parse the serialized data in the TFRecords files.\n",
    "    # This returns TensorFlow tensors for the image and labels.\n",
    "    dataset = dataset.map(parse)\n",
    "\n",
    "    if train:\n",
    "        # If training then read a buffer of the given size and\n",
    "        # randomly shuffle it.\n",
    "        dataset = dataset.shuffle(buffer_size=buffer_size)\n",
    "\n",
    "        # Allow infinite reading of the data.\n",
    "        num_repeat = None\n",
    "    else:\n",
    "        # If testing then don't shuffle the data.\n",
    "        \n",
    "        # Only go through the data once.\n",
    "        num_repeat = 1\n",
    "\n",
    "    # Repeat the dataset the given number of times.\n",
    "    dataset = dataset.repeat(num_repeat)\n",
    "    \n",
    "    # Get a batch of data with the given size.\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    # Create an iterator for the dataset and the above modifications.\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "    # Get the next batch of images and labels.\n",
    "    images_batch, labels_batch = iterator.get_next()\n",
    "\n",
    "    # The input-function must return a dict wrapping the images.\n",
    "    x = {'image': images_batch}\n",
    "    y = labels_batch\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_input_fn():\n",
    "    return input_fn(filenames=path_tfrecords_train_lst, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode ,params):\n",
    "    # Args:\n",
    "    #\n",
    "    # features: This is the x-arg from the input_fn.\n",
    "    # labels:   This is the y-arg from the input_fn.\n",
    "    # mode:     Either TRAIN, EVAL, or PREDICT\n",
    "    # params:   User-defined hyper-parameters, e.g. learning-rate.\n",
    "    \n",
    "    # Reference to the tensor named \"image\" in the input-function.\n",
    "    x = features[\"image\"]\n",
    "    # The convolutional layers expect 4-rank tensors\n",
    "    # but x is a 2-rank tensor, so reshape it.\n",
    "    net = tf.reshape(x, [-1,W,H,C])\n",
    "    # First convolutional layer.\n",
    "    net = tf.layers.conv2d(inputs=net, name='layer_conv1',\n",
    "                           filters=64, kernel_size=(11,5),\n",
    "                           padding='same', activation=tf.nn.relu)\n",
    "    net = tf.layers.max_pooling2d(inputs=net, pool_size=(8,4), strides=1)\n",
    "    #net = tf.nn.lrn(input=net, depth_radius=4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm1')\n",
    "    # Second convolutional layer.\n",
    "    net = tf.layers.conv2d(inputs=net, name='layer_conv2',\n",
    "                           filters=200, kernel_size=(5,3),\n",
    "                           padding='same', activation=tf.nn.relu) #200\n",
    "    #net = tf.nn.lrn(input=net, depth_radius=4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm1')\n",
    "    net = tf.layers.max_pooling2d(inputs=net, pool_size=(4,3), strides=1)    \n",
    "\n",
    "    # Flatten to a 2-rank tensor.\n",
    "    #net = tf.contrib.layers.flatten(net)\n",
    "    # Eventually this should be replaced with:\n",
    "    net = tf.layers.flatten(net)\n",
    "\n",
    "    # First fully-connected / dense layer.\n",
    "    # This uses the ReLU activation function.\n",
    "    net = tf.layers.dense(inputs=net, name='layer_fc1',\n",
    "                          units=512, activation=tf.nn.relu)     #1024\n",
    "    \n",
    "    # Second fully-connected / dense layer\n",
    "    net = tf.layers.dense(inputs=net, name='layer_fc2',\n",
    "                          units=512, activation=tf.nn.relu)   #2048\n",
    "    \n",
    "   \n",
    "    # This is the last layer so it does not use an activation function.\n",
    "    net = tf.layers.dense(inputs=net, name='layer_fc3',\n",
    "                          units=47)\n",
    "\n",
    "    # Logits output of the neural network.\n",
    "    logits = net\n",
    "\n",
    "    # Softmax output of the neural network.\n",
    "    y_pred = tf.nn.softmax(logits=logits)\n",
    "    \n",
    "    # Classification output of the neural network.\n",
    "    y_pred_cls = tf.argmax(y_pred, axis=1)\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        # If the estimator is supposed to be in prediction-mode\n",
    "        # then use the predicted class-number that is output by\n",
    "        # the neural network. Optimization etc. is not needed.\n",
    "        spec = tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                          predictions=y_pred_cls)\n",
    "    else:\n",
    "        # Otherwise the estimator is supposed to be in either\n",
    "        # training or evaluation-mode. Note that the loss-function\n",
    "        # is also required in Evaluation mode.\n",
    "        \n",
    "        # Define the loss-function to be optimized, by first\n",
    "        # calculating the cross-entropy between the output of\n",
    "        # the neural network and the true labels for the input data.\n",
    "        # This gives the cross-entropy for each image in the batch.\n",
    "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels,\n",
    "                                                                       logits=logits)\n",
    "\n",
    "        # Reduce the cross-entropy batch-tensor to a single number\n",
    "        # which can be used in optimization of the neural network.\n",
    "        loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "        \n",
    "\n",
    "        '''\n",
    "        another example for lr decay\n",
    "        starter_learning_rate = 0.01\n",
    "        learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step=10000,\n",
    "                                                   decay_steps=10000, decay_rate=0.5, staircase=True)\n",
    "        # Passing global_step to minimize() will increment it at each step.\n",
    "        learning_step = (tf.train.GradientDescentOptimizer(learning_rate)\n",
    "                         .minimize(...my loss..., global_step=global_step)\n",
    "        '''\n",
    "                         \n",
    "        '''\n",
    "        lr = 0.01\n",
    "        step_rate = 10000\n",
    "        decay = 0.5\n",
    "\n",
    "        global_step = tf.Variable(0, trainable=False)\n",
    "#         increment_global_step = tf.assign(global_step, global_step + 1)\n",
    "        learning_rate = tf.train.exponential_decay(lr, global_step, step_rate, decay, staircase=True)\n",
    "\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate) #epsilon=0.01 in example\n",
    "        train_op = optimizer.minimize(loss=loss, global_step=global_step)\n",
    "        \n",
    "        '''                            \n",
    "        lr = 0.01\n",
    "        step_rate = 1000\n",
    "        decay = 0.5\n",
    "        # global_step_var = tf.Variable(0, trainable=False)\n",
    "        # increment_global_step = tf.assign(global_step, global_step + 1)\n",
    "\n",
    "        learning_rate = tf.train.exponential_decay(lr, global_step=tf.train.get_or_create_global_step(), \n",
    "                                           decay_steps=step_rate, decay_rate=decay, staircase=True)\n",
    "        \n",
    "        #ORIGINAL:                 \n",
    "        # Define the optimizer for improving the neural network.\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)#params[\"learning_rate\"])\n",
    "                \n",
    "        # Get the TensorFlow op for doing a single optimization step.\n",
    "        train_op = optimizer.minimize(loss=loss, global_step = tf.train.get_or_create_global_step())\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Define the evaluation metrics,\n",
    "        # in this case the classification accuracy.\n",
    "        metrics = \\\n",
    "        {\n",
    "            \"accuracy\": tf.metrics.accuracy(labels, y_pred_cls)\n",
    "        }\n",
    "\n",
    "        # Wrap all of this in an EstimatorSpec.\n",
    "        spec = tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            loss=loss,\n",
    "            train_op=train_op,\n",
    "            eval_metric_ops=metrics)\n",
    "        \n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "params = {\"learning_rate\": 1e-4}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_dir_and_comment(model_dir):\n",
    "    home = expanduser(\"~\")\n",
    "    log_name=os.path.join('logs/', model_dir + '.txt')\n",
    "    \n",
    "    if os.path.isdir(model_dir):\n",
    "        print('INFO: dir with name ' + model_dir + ' already exist.')\n",
    "    \n",
    "    new_comment=input('Please add a comment\\n')\n",
    "    \n",
    "    if os.path.exists(log_name):\n",
    "        append_write = 'a' # append if already exists\n",
    "    else:\n",
    "        append_write = 'w' # make a new file if not\n",
    "    \n",
    "    model_log = open(log_name,append_write)\n",
    "    model_log.write(home +' : '+ new_comment + '\\n')\n",
    "    model_log.close()\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please add a comment\n",
      "checking b8 with LR decay\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_worker_replicas': 1, '_keep_checkpoint_every_n_hours': 10000, '_is_chief': True, '_service': None, '_save_checkpoints_steps': None, '_task_id': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_task_type': 'worker', '_evaluation_master': '', '_model_dir': './ckpts_21_5_lenet_fc_512_512_b8_decayLR_1000', '_keep_checkpoint_max': 5, '_num_ps_replicas': 0, '_log_step_count_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f24dbe099b0>, '_global_id_in_cluster': 0, '_session_config': None, '_master': ''}\n"
     ]
    }
   ],
   "source": [
    "model_dir = './ckpts_21_5_lenet_fc_512_512_b8_decayLR_1000' #'./ckpts_<day>_<month>_<architecture>_<main_change>'\n",
    "make_dir_and_comment(model_dir) \n",
    "model = tf.estimator.Estimator(model_fn=model_fn,\n",
    "                               params=params,\n",
    "                               model_dir=model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./ckpts_21_5_lenet_fc_512_512_b8_decayLR_1000/model.ckpt.\n",
      "INFO:tensorflow:step = 0, loss = 9862.116\n",
      "INFO:tensorflow:global_step/sec: 2.65804\n",
      "INFO:tensorflow:step = 100, loss = 3.413661 (37.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.839\n",
      "INFO:tensorflow:step = 200, loss = 3.4336715 (35.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83256\n",
      "INFO:tensorflow:step = 300, loss = 3.5464396 (35.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83849\n",
      "INFO:tensorflow:step = 400, loss = 3.8409648 (35.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85649\n",
      "INFO:tensorflow:step = 500, loss = 3.5927527 (35.008 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83738\n",
      "INFO:tensorflow:step = 600, loss = 3.9153426 (35.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83328\n",
      "INFO:tensorflow:step = 700, loss = 3.291963 (35.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85453\n",
      "INFO:tensorflow:step = 800, loss = 3.659095 (35.032 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83743\n",
      "INFO:tensorflow:step = 900, loss = 3.2507477 (35.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8502\n",
      "INFO:tensorflow:step = 1000, loss = 3.4833379 (35.085 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84654\n",
      "INFO:tensorflow:step = 1100, loss = 3.3895736 (35.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84634\n",
      "INFO:tensorflow:step = 1200, loss = 3.6372266 (35.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84514\n",
      "INFO:tensorflow:step = 1300, loss = 3.36155 (35.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85251\n",
      "INFO:tensorflow:step = 1400, loss = 3.2276027 (35.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8218\n",
      "INFO:tensorflow:step = 1500, loss = 3.3504324 (35.438 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1593 into ./ckpts_21_5_lenet_fc_512_512_b8_decayLR_1000/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.40068\n",
      "INFO:tensorflow:step = 1600, loss = 3.3352208 (71.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.71326\n",
      "INFO:tensorflow:step = 1700, loss = 3.4914021 (36.856 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84592\n",
      "INFO:tensorflow:step = 1800, loss = 3.3761892 (35.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8547\n",
      "INFO:tensorflow:step = 1900, loss = 3.5532405 (35.030 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84836\n",
      "INFO:tensorflow:step = 2000, loss = 3.3400373 (35.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84174\n",
      "INFO:tensorflow:step = 2100, loss = 3.3393512 (35.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84905\n",
      "INFO:tensorflow:step = 2200, loss = 3.3122542 (35.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85753\n",
      "INFO:tensorflow:step = 2300, loss = 3.2742941 (34.995 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85338\n",
      "INFO:tensorflow:step = 2400, loss = 3.23981 (35.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84401\n",
      "INFO:tensorflow:step = 2500, loss = 3.3697622 (35.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85225\n",
      "INFO:tensorflow:step = 2600, loss = 3.603806 (35.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84168\n",
      "INFO:tensorflow:step = 2700, loss = 3.2675333 (35.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82654\n",
      "INFO:tensorflow:step = 2800, loss = 3.4895108 (35.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84123\n",
      "INFO:tensorflow:step = 2900, loss = 3.4191437 (35.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84596\n",
      "INFO:tensorflow:step = 3000, loss = 3.4077318 (35.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84761\n",
      "INFO:tensorflow:step = 3100, loss = 3.2908957 (35.117 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3193 into ./ckpts_21_5_lenet_fc_512_512_b8_decayLR_1000/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.40129\n",
      "INFO:tensorflow:step = 3200, loss = 3.405519 (71.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.71074\n",
      "INFO:tensorflow:step = 3300, loss = 3.7370107 (36.890 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85674\n",
      "INFO:tensorflow:step = 3400, loss = 3.503134 (35.005 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83878\n",
      "INFO:tensorflow:step = 3500, loss = 3.9516993 (35.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84968\n",
      "INFO:tensorflow:step = 3600, loss = 3.1236315 (35.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85042\n",
      "INFO:tensorflow:step = 3700, loss = 3.3687124 (35.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84456\n",
      "INFO:tensorflow:step = 3800, loss = 3.3922026 (35.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85466\n",
      "INFO:tensorflow:step = 3900, loss = 3.386405 (35.030 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86963\n",
      "INFO:tensorflow:step = 4000, loss = 3.4605145 (34.848 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85739\n",
      "INFO:tensorflow:step = 4100, loss = 3.4472241 (34.997 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86115\n",
      "INFO:tensorflow:step = 4200, loss = 3.3730488 (34.951 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86219\n",
      "INFO:tensorflow:step = 4300, loss = 3.4316561 (34.938 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85806\n",
      "INFO:tensorflow:step = 4400, loss = 3.451493 (34.989 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85537\n",
      "INFO:tensorflow:step = 4500, loss = 4.0080137 (35.022 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86515\n",
      "INFO:tensorflow:step = 4600, loss = 3.2917426 (34.902 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86214\n",
      "INFO:tensorflow:step = 4700, loss = 3.3057594 (34.939 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4798 into ./ckpts_21_5_lenet_fc_512_512_b8_decayLR_1000/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.39997\n",
      "INFO:tensorflow:step = 4800, loss = 3.332365 (71.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.72182\n",
      "INFO:tensorflow:step = 4900, loss = 3.5876398 (36.740 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8522\n",
      "INFO:tensorflow:step = 5000, loss = 3.4145727 (35.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8508\n",
      "INFO:tensorflow:step = 5100, loss = 3.4154754 (35.078 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85671\n",
      "INFO:tensorflow:step = 5200, loss = 3.2634387 (35.005 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83544\n",
      "INFO:tensorflow:step = 5300, loss = 3.4209738 (35.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86702\n",
      "INFO:tensorflow:step = 5400, loss = 3.4064894 (34.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.87139\n",
      "INFO:tensorflow:step = 5500, loss = 3.8748121 (34.827 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85277\n",
      "INFO:tensorflow:step = 5600, loss = 3.4290771 (35.054 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86422\n",
      "INFO:tensorflow:step = 5700, loss = 3.4014647 (34.914 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86753\n",
      "INFO:tensorflow:step = 5800, loss = 3.863694 (34.872 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86671\n",
      "INFO:tensorflow:step = 5900, loss = 3.45464 (34.883 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85004\n",
      "INFO:tensorflow:step = 6000, loss = 3.7522545 (35.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85528\n",
      "INFO:tensorflow:step = 6100, loss = 3.6131392 (35.023 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86475\n",
      "INFO:tensorflow:step = 6200, loss = 3.4807127 (34.907 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86256\n",
      "INFO:tensorflow:step = 6300, loss = 3.5146852 (34.934 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85625\n",
      "INFO:tensorflow:step = 6400, loss = 3.3347642 (35.011 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6404 into ./ckpts_21_5_lenet_fc_512_512_b8_decayLR_1000/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.36932\n",
      "INFO:tensorflow:step = 6500, loss = 3.5569851 (73.029 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84657\n",
      "INFO:tensorflow:step = 6600, loss = 3.2322838 (35.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86731\n",
      "INFO:tensorflow:step = 6700, loss = 3.3041158 (34.876 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86464\n",
      "INFO:tensorflow:step = 6800, loss = 3.5246258 (34.908 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86075\n",
      "INFO:tensorflow:step = 6900, loss = 3.253139 (34.956 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86568\n",
      "INFO:tensorflow:step = 7000, loss = 3.2693374 (34.895 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.87235\n",
      "INFO:tensorflow:step = 7100, loss = 3.40658 (34.815 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85649\n",
      "INFO:tensorflow:step = 7200, loss = 3.5318608 (35.008 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.87009\n",
      "INFO:tensorflow:step = 7300, loss = 3.317709 (34.842 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86316\n",
      "INFO:tensorflow:step = 7400, loss = 3.4356608 (34.927 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86682\n",
      "INFO:tensorflow:step = 7500, loss = 3.7568254 (34.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85508\n",
      "INFO:tensorflow:step = 7600, loss = 3.4159389 (35.025 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86912\n",
      "INFO:tensorflow:step = 7700, loss = 3.4704816 (34.854 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86308\n",
      "INFO:tensorflow:step = 7800, loss = 3.5907097 (34.927 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86289\n",
      "INFO:tensorflow:step = 7900, loss = 3.379438 (34.930 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86714\n",
      "INFO:tensorflow:step = 8000, loss = 3.3715482 (34.878 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8014 into ./ckpts_21_5_lenet_fc_512_512_b8_decayLR_1000/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.38172\n",
      "INFO:tensorflow:step = 8100, loss = 3.3665402 (72.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86236\n",
      "INFO:tensorflow:step = 8200, loss = 3.4652376 (34.948 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85616\n",
      "INFO:tensorflow:step = 8300, loss = 3.8135962 (35.000 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.87484\n",
      "INFO:tensorflow:step = 8400, loss = 3.2983136 (34.784 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86331\n",
      "INFO:tensorflow:step = 8500, loss = 3.3522696 (34.925 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86491\n",
      "INFO:tensorflow:step = 8600, loss = 3.3995104 (34.906 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8654\n",
      "INFO:tensorflow:step = 8700, loss = 3.3090978 (34.899 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86041\n",
      "INFO:tensorflow:step = 8800, loss = 3.4839833 (34.960 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85698\n",
      "INFO:tensorflow:step = 8900, loss = 3.3213305 (35.002 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86793\n",
      "INFO:tensorflow:step = 9000, loss = 3.3252673 (34.868 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8685\n",
      "INFO:tensorflow:step = 9100, loss = 3.5136151 (34.861 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85287\n",
      "INFO:tensorflow:step = 9200, loss = 3.6309729 (35.053 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.84895\n",
      "INFO:tensorflow:step = 9300, loss = 3.5888162 (35.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86325\n",
      "INFO:tensorflow:step = 9400, loss = 3.5712485 (34.925 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86268\n",
      "INFO:tensorflow:step = 9500, loss = 3.416055 (34.932 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8715\n",
      "INFO:tensorflow:step = 9600, loss = 3.4051623 (34.825 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9625 into ./ckpts_21_5_lenet_fc_512_512_b8_decayLR_1000/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.36512\n",
      "INFO:tensorflow:step = 9700, loss = 3.3231962 (73.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.86219\n",
      "INFO:tensorflow:step = 9800, loss = 3.3216186 (34.938 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85166\n",
      "INFO:tensorflow:step = 9900, loss = 3.6155949 (35.068 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into ./ckpts_21_5_lenet_fc_512_512_b8_decayLR_1000/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 3.2788622.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7f24dbe09da0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=train_input_fn, steps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#####DONE TRAIN######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# VAL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#val\n",
    "path_tfrecords_val_lst=[]\n",
    "path_tfrecords_val = os.path.join(img_path, 'val')\n",
    "for root, dirs, files in os.walk(tfrec_val_directory):\n",
    "    for file in files:\n",
    "        if '.tfrecord' in file:\n",
    "            path_tfrecords_val_lst.append(os.path.join(tfrec_val_directory,file))\n",
    "        else:\n",
    "            print('WARNING: file ' + file + 'looks suspicious. does it belong here?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#val\n",
    "tfrec_val_directory = os.path.join('..','datasets','stixels','val','tfrec_batch_size_'+str(val_batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def val_input_fn():\n",
    "    return input_fn(filenames=path_tfrecords_val_lst, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-21-15:00:41\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./ckpts_21_5_lenet_fc_512_512_b8_decayLR_1000/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "val_result = model.evaluate(input_fn=val_input_fn) ##need to reduce batch size for val and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Classification val accuracy: {0:.2%}\".format(val_result[\"accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###test###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#only for showing pics with predictions later\n",
    "\n",
    "sum_csv_test_path = os.path.join(img_path,'test', 'sum_csv')\n",
    "labels_test=pd.read_csv(os.path.join(sum_csv_test_path,'labels_test.csv'))\n",
    "test_names_list=list(labels_test['Name'])\n",
    "image_paths_test=[]\n",
    "for name in test_names_list:\n",
    "    image_paths_test.append(os.path.join(img_path, 'test', name+'.png')) #maybe no need to add '.png'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_input_fn():\n",
    "    return input_fn(filenames=path_tfrecords_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_result = model.evaluate(input_fn=test_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Classification test accuracy: {0:.2%}\".format(test_result[\"accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###pred###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for pred later only\n",
    "def load_images(image_paths):\n",
    "    # Load the images from disk.\n",
    "    images = [imread(path) for path in image_paths]\n",
    "    # Convert to a numpy array and return it.\n",
    "    return np.asarray(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for pred later only ##TODO:SHUFFLE!\n",
    "\n",
    "##TODO:SHUFFLE!\n",
    "\n",
    "some_num=5000\n",
    "some_images = load_images(image_paths=image_paths_test[20000:20000+some_num])\n",
    "some_images_cls = np.array(labels_test['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46 46 46 ... 46 46 46]\n"
     ]
    }
   ],
   "source": [
    "print(some_images_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check if this works TODO\n",
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"image\": some_images.astype(np.float32)},\n",
    "    num_epochs=1,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(input_fn=predict_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./ckpts_21_5_lenet_fc_512_512_b8_decayLR_1000/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([16, 16, 16, ..., 16, 16, 16])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_pred = np.array(list(predictions))\n",
    "cls_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0, 5000,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0]),\n",
       " array([15.5       , 15.5212766 , 15.54255319, 15.56382979, 15.58510638,\n",
       "        15.60638298, 15.62765957, 15.64893617, 15.67021277, 15.69148936,\n",
       "        15.71276596, 15.73404255, 15.75531915, 15.77659574, 15.79787234,\n",
       "        15.81914894, 15.84042553, 15.86170213, 15.88297872, 15.90425532,\n",
       "        15.92553191, 15.94680851, 15.96808511, 15.9893617 , 16.0106383 ,\n",
       "        16.03191489, 16.05319149, 16.07446809, 16.09574468, 16.11702128,\n",
       "        16.13829787, 16.15957447, 16.18085106, 16.20212766, 16.22340426,\n",
       "        16.24468085, 16.26595745, 16.28723404, 16.30851064, 16.32978723,\n",
       "        16.35106383, 16.37234043, 16.39361702, 16.41489362, 16.43617021,\n",
       "        16.45744681, 16.4787234 , 16.5       ]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram(cls_pred, bins=47)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
