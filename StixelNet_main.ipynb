{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 14963715693831411681\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11273646900\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 519497705873386678\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "from preprocess_func_new import *\n",
    "from matplotlib.image import imread\n",
    "import random\n",
    "import sys\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../datasets/stixels'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path = os.path.join('..','datasets','stixels')\n",
    "img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#merging all TEST csv files, keeping only 10 precent of \"no obstical\"\n",
    "labels_test=pd.DataFrame(columns = ['Name','Label', 'Use_stixel'])\n",
    "files = [x[2] for x in os.walk(os.path.join(img_path,'test'))]\n",
    "    if '.csv' in file and 'labels_test.csv' not in file:\n",
    "        tmp=pd.read_csv(os.path.join(img_path,'test',file))\n",
    "        if(tmp.isnull().values.any()):\n",
    "            print('Nan in ',file)\n",
    "        labels_test = pd.concat([labels_test,tmp])\n",
    "labels_test=labels_test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_test.to_csv( os.path.join(img_path,'test','labels_test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_no_obstacles_stixels(labels_df, percent = 10):\n",
    "    random.seed(481)\n",
    "    num_stx_with_obst = len(labels_df.index[labels_df['Label'] != 46].tolist())    \n",
    "    no_obst_train_idx = labels_df.index[labels_df['Label'] == 46].tolist()\n",
    "    use_idx = random.sample(no_obst_train_idx, int(num_stx_with_obst*percent/100))\n",
    "    for idx in use_idx:\n",
    "        labels_df.at[idx, 'Use_stixel'] = 1\n",
    "    return labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#merging all VAL csv files, keeping only 10 precent of \"no obstical\"\n",
    "labels_val=pd.DataFrame(columns = ['Name','Label', 'Use_stixel'])\n",
    "files = [x[2] for x in os.walk(os.path.join(img_path,'val'))]\n",
    "for file in files:\n",
    "    if '.csv' in file and 'labels_val.csv' not in file:\n",
    "        tmp=pd.read_csv(os.path.join(img_path,'val',file))\n",
    "        if(tmp.isnull().values.any()):\n",
    "            print('Nan in ',file)\n",
    "        labels_val = pd.concat([labels_val,tmp])\n",
    "labels_val=labels_val.reset_index()\n",
    "labels_val=add_no_obstacles_stixels(labels_df=labels_val, percent = 10)\n",
    "labels_val = labels_val[labels_val['Use_stixel'] == 1]\n",
    "labels_val=labels_val.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_val.to_csv( os.path.join(img_path,'val','labels_val.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#labels_train=pd.DataFrame(columns = ['Name','Label', 'Use_stixel'])\n",
    "labels_train = []\n",
    "for root, dirs, files in os.walk(os.path.join(img_path,'train')):\n",
    "    for file in files:\n",
    "        if '.csv' in file and not 'labels_train' in file:\n",
    "            tmp=pd.read_csv(os.path.join(img_path,'train',file))\n",
    "            if(tmp.isnull().values.any()):\n",
    "                print('Nan in ',file)\n",
    "            if len(labels_train)==0:\n",
    "                labels_train = tmp\n",
    "            else:\n",
    "                \n",
    "                labels_train = labels_train.append(tmp, ignore_index=True)\n",
    "                \n",
    "                \n",
    "            #labels_train = pd.concat([labels_train,tmp])\n",
    "            \n",
    "            \n",
    "# print(labels_train.head())\n",
    "# print(labels_train.tail())\n",
    "\n",
    "#labels_train=labels_train.reset_index()\n",
    "labels_train = add_no_obstacles_stixels(labels_df=labels_train, percent = 10)\n",
    "labels_train = labels_train[labels_train['Use_stixel'] == 1]\n",
    "labels_train = labels_train.reset_index(drop=True)\n",
    "# print(labels_train.head())\n",
    "# print(labels_train.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_train.to_csv( os.path.join(img_path,'train','labels_train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idxs=list(range(len(labels_train)))\n",
    "random.seed(481)\n",
    "random.shuffle(idxs) \n",
    "\n",
    "batches_idx = [idxs[x:x+batch_size] for x in range(0, len(idxs), batch_size)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Label</th>\n",
       "      <th>Use_stixel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011_09_26_drive_0057_frame_0000000261_stixel_009</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011_09_26_drive_0057_frame_0000000261_stixel_012</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011_09_26_drive_0057_frame_0000000261_stixel_016</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011_09_26_drive_0057_frame_0000000261_stixel_018</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011_09_26_drive_0057_frame_0000000261_stixel_019</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name  Label  Use_stixel\n",
       "0  2011_09_26_drive_0057_frame_0000000261_stixel_009     46           1\n",
       "1  2011_09_26_drive_0057_frame_0000000261_stixel_012     46           1\n",
       "2  2011_09_26_drive_0057_frame_0000000261_stixel_016     46           1\n",
       "3  2011_09_26_drive_0057_frame_0000000261_stixel_018     14           1\n",
       "4  2011_09_26_drive_0057_frame_0000000261_stixel_019     14           1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_progress(count, total):\n",
    "    # Percentage completion.\n",
    "    pct_complete = float(count) / total\n",
    "\n",
    "    # Status-message.\n",
    "    # Note the \\r which means the line should overwrite itself.\n",
    "    msg = \"\\r- Progress: {0:.1%}\".format(pct_complete)\n",
    "\n",
    "    # Print it.\n",
    "    sys.stdout.write(msg)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wrap_int64(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wrap_bytes(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert(image_paths, labels, out_path):\n",
    "    # Args:\n",
    "    # image_paths   List of file-paths for the images.\n",
    "    # labels        Class-labels for the images.\n",
    "    # out_path      File-path for the TFRecords output file.\n",
    "    print('')\n",
    "    print(\"Converting: \" + out_path)\n",
    "    \n",
    "    # Number of images. Used when printing the progress.\n",
    "    num_images = len(image_paths)\n",
    "    \n",
    "    # Open a TFRecordWriter for the output-file.\n",
    "    with tf.python_io.TFRecordWriter(out_path) as writer:\n",
    "        \n",
    "        # Iterate over all the image-paths and class-labels.\n",
    "        for i, (path, label) in enumerate(zip(image_paths, labels)):\n",
    "            # Print the percentage-progress.\n",
    "            #######print_progress(count=i, total=num_images-1)\n",
    "            \n",
    "            with open(path, 'rb') as f:\n",
    "                img_raw = f.read()\n",
    "           \n",
    "            # Create a dict with the data we want to save in the\n",
    "            # TFRecords file. You can add more relevant data here.\n",
    "            data = \\\n",
    "                {\n",
    "                    'image': wrap_bytes(img_raw),\n",
    "                    'label': wrap_int64(label)\n",
    "                } \n",
    "\n",
    "            # Wrap the data as TensorFlow Features.\n",
    "            feature = tf.train.Features(feature=data)\n",
    "\n",
    "            # Wrap again as a TensorFlow Example.\n",
    "            example = tf.train.Example(features=feature)\n",
    "\n",
    "            # Serialize the data.\n",
    "            serialized = example.SerializeToString()\n",
    "            \n",
    "            # Write the serialized data to the TFRecords file.\n",
    "            writer.write(serialized)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting: ../datasets/stixels/train/train_small041828.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small102036.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small059315.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small102240.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small002208.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small040090.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small159439.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small223090.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small008027.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small077125.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small040683.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small048786.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small039893.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small047063.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small137883.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small215764.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small211968.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small133086.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small058831.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small001487.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small179694.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small021135.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small209683.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small097867.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small031632.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small092849.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small171878.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small046999.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small004068.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small199653.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small151511.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small071034.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small184013.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small179271.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small055097.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small061749.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small084571.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small043658.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small077855.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small117971.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small104548.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small125553.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small222184.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small227392.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small067021.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small177785.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small005641.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small053264.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small076344.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small032253.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small036915.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small029714.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small157456.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small082008.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small131064.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small193399.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small127195.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small034871.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small070740.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small075372.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small109693.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small010590.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small002278.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small164015.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small227898.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small183408.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small004151.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small182043.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small058055.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small013772.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small153804.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small044507.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small037774.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small022178.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small073486.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small190950.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small072459.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small003449.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small011229.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small180225.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small205647.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small075547.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small025588.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small030955.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small020716.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small195691.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small109160.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small111621.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small092420.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small001950.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small184906.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small041539.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small039006.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small108909.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small007686.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small050919.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small214396.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small010641.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small166943.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small204320.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small201179.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small126462.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small219536.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small136810.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small018850.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small150913.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small184331.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small200408.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small172055.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small060188.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small053052.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small022537.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small178972.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small158195.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small219443.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small141970.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small155668.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small127632.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small193158.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small045926.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small066813.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small029567.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small112808.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small064222.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small026419.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small174861.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small102257.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small195609.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small182690.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small033768.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small097546.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small090577.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small167601.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small005527.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small035431.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small038123.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small190020.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small146972.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small140091.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small222688.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small214367.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small130802.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small206309.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small061846.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small115037.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small229847.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small035748.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small210905.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small034784.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small078627.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small106456.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small163808.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small225022.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small161943.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small208982.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small003502.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small204100.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small075083.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small163648.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small041972.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small127367.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small064595.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small085290.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small055810.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small170484.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small130995.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small105449.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small184182.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small110262.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small137675.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small074069.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small220821.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small209845.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small033208.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small081467.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small143149.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small158518.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small014340.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small186148.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small021405.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small076828.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small032947.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small163048.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small080671.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small110472.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small108576.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small085714.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small016059.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small056911.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small078127.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small214896.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small030398.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small125409.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small007490.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small200721.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small158220.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small089500.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small080618.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small110661.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small044867.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small021111.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small206089.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small201819.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small176247.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small109538.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small139838.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small079467.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small110483.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small041122.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small071500.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small109304.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small155650.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small018154.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small143376.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small101818.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small230466.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small092714.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small090401.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small027757.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small081490.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small144834.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small029267.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small064593.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small078879.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small034257.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small122707.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small228036.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small165556.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small000362.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small192546.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small012503.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small128446.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small078396.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small010072.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small089268.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small123792.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small160498.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small090386.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small011256.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small012119.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small139931.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small042051.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small134374.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small094922.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small157729.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small144229.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small079341.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small050307.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small230461.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small171946.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small129560.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small196730.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small156507.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small039167.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small081912.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small048459.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small084995.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small101318.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small042481.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small171652.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small070272.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small207697.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small036924.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small197807.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small227609.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small131998.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small176742.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small001684.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small052872.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small034546.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small042455.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small194772.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small111553.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small037826.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small212423.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small050548.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small178185.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small142878.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small127343.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small185631.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small059776.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small101735.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small205057.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small061870.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small041640.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small049955.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small060220.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small093236.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small001335.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small085774.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small085879.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small142227.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small151706.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small211175.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small007411.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small207756.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small047010.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small199994.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small104858.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small132453.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small031672.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small205563.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small110609.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small151474.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small035083.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small202856.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small229115.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small225910.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small041673.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small088170.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small033518.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small227738.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small102994.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small083371.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small160662.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small160886.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small142201.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small032783.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small046239.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small137761.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small054070.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small032573.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small098224.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small049338.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small220151.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small172681.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small208248.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small134012.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small177948.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small110976.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small213614.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small032164.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small023059.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small049809.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small202530.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small085243.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small222701.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small123976.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small008745.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small182330.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small174315.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small142310.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small181589.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small035848.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small225332.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small147157.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small133354.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small030813.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small172612.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small171562.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small047312.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small195297.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small001141.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small005986.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small084014.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small165279.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small188063.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small157177.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small082464.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small095700.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small103961.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small205046.tfrecords\n",
      "\n",
      "Converting: ../datasets/stixels/train/train_small132144.tfrecords\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-36046b339852>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     convert(image_paths=batch_image_paths_train,\n\u001b[0;32m     10\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         out_path=batch_path_tfrecords_train)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-3db07cdf4218>\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(image_paths, labels, out_path)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m                 \u001b[0mimg_raw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;31m# Create a dict with the data we want to save in the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for batch in batches_idx:\n",
    "    batch_labels=labels_train.loc[batch]\n",
    "    batch_names_list=list(batch_labels['Name'])\n",
    "    batch_labels=np.array(batch_labels['Label'])\n",
    "    batch_image_paths_train=[]\n",
    "    for name in batch_names_list:\n",
    "        batch_image_paths_train.append(os.path.join(img_path, 'train', str(name)+'.png')) \n",
    "    batch_path_tfrecords_train = os.path.join(img_path, 'train', \"train\"+str(batch[0]).zfill(6)+\".tfrecords\") \n",
    "    convert(image_paths=batch_image_paths_train,\n",
    "        labels=batch_labels,\n",
    "        out_path=batch_path_tfrecords_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#VAL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_names_list=list(labels_val['Name'])\n",
    "val_labels=np.array(labels_val['Label'])\n",
    "image_paths_val=[]\n",
    "for name in val_names_list:\n",
    "    image_paths_val.append(os.path.join(img_path, 'val', name+'.png')) \n",
    "path_tfrecords_val = os.path.join(img_path, 'val', \"val.tfrecords\")\n",
    "convert(image_paths=image_paths_val,\n",
    "        labels=val_labels,\n",
    "        out_path=path_tfrecords_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TEST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_names_list=list(labels_test['Name'])\n",
    "test_labels=np.array(labels_test['Label'])\n",
    "image_paths_test=[]\n",
    "for name in test_names_list:\n",
    "    image_paths_test.append(os.path.join(img_path, 'test', name+'.png')) #maybe no need to add '.png'\n",
    "path_tfrecords_test = os.path.join(img_path, 'test', \"test.tfrecords\")\n",
    "convert(image_paths=image_paths_test,\n",
    "        labels=test_labels,\n",
    "        out_path=path_tfrecords_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########now part 2: decode and train#######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "#from preprocess_func_new import *\n",
    "from matplotlib.image import imread\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_path = os.path.join('..','datasets','stixels')\n",
    "img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#only for showing pics with predictions later\n",
    "import os\n",
    "labels_test=pd.read_csv(os.path.join(img_path,'test','labels_test.csv'))\n",
    "test_names_list=list(labels_test['Name'])\n",
    "image_paths_test=[]\n",
    "for name in test_names_list:\n",
    "    image_paths_test.append(os.path.join(img_path, 'test', name+'.png')) #maybe no need to add '.png'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_tfrecords_train_lst=[]\n",
    "path_tfrecords_train = os.path.join(img_path, 'train')\n",
    "# files = [x[2] for x in os.walk(path_tfrecords_train)]\n",
    "for root, dirs, files in os.walk(path_tfrecords_train):\n",
    "    for file in files:\n",
    "        if '.tfrecord' in file:\n",
    "            path_tfrecords_train_lst.append(os.path.join(path_tfrecords_train,file))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149469"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(path_tfrecords_train_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "H=370 \n",
    "W=24\n",
    "C=3\n",
    "img_shape = (H, W, C)\n",
    "num_classes = 47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(serialized):\n",
    "    # Define a dict with the data-names and types we expect to\n",
    "    # find in the TFRecords file.\n",
    "    # It is a bit awkward that this needs to be specified again,\n",
    "    # because it could have been written in the header of the\n",
    "    # TFRecords file instead.\n",
    "    features = \\\n",
    "        {\n",
    "            'image': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.int64)\n",
    "        }\n",
    "\n",
    "    # Parse the serialized data so we get a dict with our data.\n",
    "    parsed_example = tf.parse_single_example(serialized=serialized,\n",
    "                                             features=features)\n",
    "\n",
    "    # Get the image as raw bytes.\n",
    "    image_raw = parsed_example['image']\n",
    "\n",
    "    # Decode the raw bytes so it becomes a tensor with type.\n",
    "    #######image = tf.decode_raw(image_raw, tf.int32) ####\n",
    "    image = tf.image.decode_png(image_raw, channels=3, dtype=tf.uint16)\n",
    "    #image = tf.cast(image, tf.int32)\n",
    "\n",
    "    # The type is now uint8 but we need it to be float.\n",
    "    \n",
    "    image = tf.cast(image, tf.float32) ####\n",
    "    \n",
    "    # Get the label associated with the image.\n",
    "    label = parsed_example['label']\n",
    "\n",
    "    # The image and label are now correct TensorFlow types.\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_fn(filenames, train, batch_size=batch_size, buffer_size=40000): #2048\n",
    "    # Args:\n",
    "    # filenames:   Filenames for the TFRecords files.\n",
    "    # train:       Boolean whether training (True) or testing (False).\n",
    "    # batch_size:  Return batches of this size.\n",
    "    # buffer_size: Read buffers of this size. The random shuffling\n",
    "    #              is done on the buffer, so it must be big enough.\n",
    "\n",
    "    # Create a TensorFlow Dataset-object which has functionality\n",
    "    # for reading and shuffling data from TFRecords files.\n",
    "    dataset = tf.data.TFRecordDataset(filenames=filenames)\n",
    "\n",
    "    # Parse the serialized data in the TFRecords files.\n",
    "    # This returns TensorFlow tensors for the image and labels.\n",
    "    dataset = dataset.map(parse)\n",
    "\n",
    "    if train:\n",
    "        # If training then read a buffer of the given size and\n",
    "        # randomly shuffle it.\n",
    "        dataset = dataset.shuffle(buffer_size=buffer_size)\n",
    "\n",
    "        # Allow infinite reading of the data.\n",
    "        num_repeat = None\n",
    "    else:\n",
    "        # If testing then don't shuffle the data.\n",
    "        \n",
    "        # Only go through the data once.\n",
    "        num_repeat = 1\n",
    "\n",
    "    # Repeat the dataset the given number of times.\n",
    "    dataset = dataset.repeat(num_repeat)\n",
    "    \n",
    "    # Get a batch of data with the given size.\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    # Create an iterator for the dataset and the above modifications.\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "    # Get the next batch of images and labels.\n",
    "    images_batch, labels_batch = iterator.get_next()\n",
    "\n",
    "    # The input-function must return a dict wrapping the images.\n",
    "    x = {'image': images_batch}\n",
    "    y = labels_batch\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_input_fn():\n",
    "    return input_fn(filenames=path_tfrecords_train_lst, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def val_input_fn():\n",
    "    return input_fn(filenames=path_tfrecords_val, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_input_fn():\n",
    "    return input_fn(filenames=path_tfrecords_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for pred later only\n",
    "def load_images(image_paths):\n",
    "    # Load the images from disk.\n",
    "    images = [imread(path) for path in image_paths]\n",
    "    # Convert to a numpy array and return it.\n",
    "    return np.asarray(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for pred later only\n",
    "some_num=10\n",
    "some_images = load_images(image_paths=image_paths_test[0:some_num])\n",
    "some_images_cls = np.array(labels_test['Label'])\n",
    "print(some_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"image\": some_images.astype(np.float32)},\n",
    "    num_epochs=1,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "    # Args:\n",
    "    #\n",
    "    # features: This is the x-arg from the input_fn.\n",
    "    # labels:   This is the y-arg from the input_fn.\n",
    "    # mode:     Either TRAIN, EVAL, or PREDICT\n",
    "    # params:   User-defined hyper-parameters, e.g. learning-rate.\n",
    "    \n",
    "    # Reference to the tensor named \"image\" in the input-function.\n",
    "    x = features[\"image\"]\n",
    "    # The convolutional layers expect 4-rank tensors\n",
    "    # but x is a 2-rank tensor, so reshape it.\n",
    "    net = tf.reshape(x, [-1,W,H,C])\n",
    "    # First convolutional layer.\n",
    "    net = tf.layers.conv2d(inputs=net, name='layer_conv1',\n",
    "                           filters=64, kernel_size=(11,5),\n",
    "                           padding='same', activation=tf.nn.relu)\n",
    "    net = tf.layers.max_pooling2d(inputs=net, pool_size=(8,4), strides=1)\n",
    "    #net = tf.nn.lrn(input=net, depth_radius=4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm1')\n",
    "    # Second convolutional layer.\n",
    "    net = tf.layers.conv2d(inputs=net, name='layer_conv2',\n",
    "                           filters=200, kernel_size=(5,3),\n",
    "                           padding='same', activation=tf.nn.relu) #200\n",
    "    #net = tf.nn.lrn(input=net, depth_radius=4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm1')\n",
    "    net = tf.layers.max_pooling2d(inputs=net, pool_size=(4,3), strides=1)    \n",
    "\n",
    "    # Flatten to a 2-rank tensor.\n",
    "    #net = tf.contrib.layers.flatten(net)\n",
    "    # Eventually this should be replaced with:\n",
    "    net = tf.layers.flatten(net)\n",
    "\n",
    "    # First fully-connected / dense layer.\n",
    "    # This uses the ReLU activation function.\n",
    "    net = tf.layers.dense(inputs=net, name='layer_fc1',\n",
    "                          units=256, activation=tf.nn.relu)     #1024\n",
    "    \n",
    "    # Second fully-connected / dense layer\n",
    "    net = tf.layers.dense(inputs=net, name='layer_fc2',\n",
    "                          units=256, activation=tf.nn.relu)   #2048\n",
    "    \n",
    "   \n",
    "    # This is the last layer so it does not use an activation function.\n",
    "    net = tf.layers.dense(inputs=net, name='layer_fc3',\n",
    "                          units=47)\n",
    "\n",
    "    # Logits output of the neural network.\n",
    "    logits = net\n",
    "\n",
    "    # Softmax output of the neural network.\n",
    "    y_pred = tf.nn.softmax(logits=logits)\n",
    "    \n",
    "    # Classification output of the neural network.\n",
    "    y_pred_cls = tf.argmax(y_pred, axis=1)\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        # If the estimator is supposed to be in prediction-mode\n",
    "        # then use the predicted class-number that is output by\n",
    "        # the neural network. Optimization etc. is not needed.\n",
    "        spec = tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                          predictions=y_pred_cls)\n",
    "    else:\n",
    "        # Otherwise the estimator is supposed to be in either\n",
    "        # training or evaluation-mode. Note that the loss-function\n",
    "        # is also required in Evaluation mode.\n",
    "        \n",
    "        # Define the loss-function to be optimized, by first\n",
    "        # calculating the cross-entropy between the output of\n",
    "        # the neural network and the true labels for the input data.\n",
    "        # This gives the cross-entropy for each image in the batch.\n",
    "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels,\n",
    "                                                                       logits=logits)\n",
    "\n",
    "        # Reduce the cross-entropy batch-tensor to a single number\n",
    "        # which can be used in optimization of the neural network.\n",
    "        loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "        # Define the optimizer for improving the neural network.\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=params[\"learning_rate\"])\n",
    "\n",
    "        # Get the TensorFlow op for doing a single optimization step.\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss, global_step=tf.train.get_global_step())\n",
    "\n",
    "        # Define the evaluation metrics,\n",
    "        # in this case the classification accuracy.\n",
    "        metrics = \\\n",
    "        {\n",
    "            \"accuracy\": tf.metrics.accuracy(labels, y_pred_cls)\n",
    "        }\n",
    "\n",
    "        # Wrap all of this in an EstimatorSpec.\n",
    "        spec = tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            loss=loss,\n",
    "            train_op=train_op,\n",
    "            eval_metric_ops=metrics)\n",
    "        \n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\"learning_rate\": 1e-4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_service': None, '_save_checkpoints_secs': 600, '_global_id_in_cluster': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_model_dir': './checkpoints_tutorial14-5-3/', '_keep_checkpoint_max': 5, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7ff0f1f5c0>, '_session_config': None, '_save_checkpoints_steps': None, '_is_chief': True, '_task_type': 'worker', '_save_summary_steps': 100, '_num_worker_replicas': 1, '_task_id': 0, '_tf_random_seed': None, '_num_ps_replicas': 0, '_master': '', '_keep_checkpoint_every_n_hours': 10000}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.Estimator(model_fn=model_fn,\n",
    "                               params=params,\n",
    "                               model_dir=\"./checkpoints_tutorial14-5-3/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./checkpoints_tutorial14-5-3/model.ckpt.\n",
      "INFO:tensorflow:step = 0, loss = 9411.85\n",
      "INFO:tensorflow:global_step/sec: 1.64644\n",
      "INFO:tensorflow:step = 100, loss = 22.463623 (60.739 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.90365\n",
      "INFO:tensorflow:step = 200, loss = 5.0379333 (52.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.90795\n",
      "INFO:tensorflow:step = 300, loss = 5.178285 (52.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.8811\n",
      "INFO:tensorflow:step = 400, loss = 16.637085 (53.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.88292\n",
      "INFO:tensorflow:step = 500, loss = 3.8187747 (53.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.90552\n",
      "INFO:tensorflow:step = 600, loss = 3.7938745 (52.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.87358\n",
      "INFO:tensorflow:step = 700, loss = 3.7825432 (53.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.91773\n",
      "INFO:tensorflow:step = 800, loss = 3.7801394 (52.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.87706\n",
      "INFO:tensorflow:step = 900, loss = 3.7508736 (53.275 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into ./checkpoints_tutorial14-5-3/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4.043049.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7f7ff0f1f4e0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=train_input_fn, steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#####DONE TRAIN######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# VAL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_tfrecords_val=os.path.join(img_path,'val','val.tfrecords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_result = model.evaluate(input_fn=val_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Classification val accuracy: {0:.2%}\".format(val_result[\"accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###test###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_tfrecords_test=os.path.join(img_path,'test','test.tfrecords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_result = model.evaluate(input_fn=test_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Classification test accuracy: {0:.2%}\".format(test_result[\"accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###pred###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(input_fn=predict_input_fn) ###FIX THIS!!!! TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cls_pred = np.array(list(predictions))\n",
    "cls_pred #FIX THIS!!!!!! TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
