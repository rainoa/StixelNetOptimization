{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "from preprocess_func import *\n",
    "%matplotlib inline\n",
    "\n",
    "#tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(108, 244, 370, 24, 3)\n",
      "(3229, 370, 24, 3)\n",
      "(3229,)\n",
      "saved\n"
     ]
    }
   ],
   "source": [
    "ds = preprocess_filtering_data(date='2011_09_26', out_name='train_2', serieses=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pd.read_table(\"StixelsGroundTruth.txt\", names=[\"series_date\",\"series_id\",\"frame_id\",\"x\",\"y\",\"Train/Test\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[[0.03529412, 0.03921569, 0.03921569],\n",
      "        [0.03529412, 0.03529412, 0.03529412],\n",
      "        [0.03137255, 0.03137255, 0.03529412],\n",
      "        ...,\n",
      "        [0.02745098, 0.03529412, 0.05882353],\n",
      "        [0.03529412, 0.04313726, 0.0627451 ],\n",
      "        [0.03529412, 0.04313726, 0.09411765]],\n",
      "\n",
      "       [[0.02745098, 0.03921569, 0.03921569],\n",
      "        [0.02745098, 0.03529412, 0.03137255],\n",
      "        [0.02745098, 0.03137255, 0.02745098],\n",
      "        ...,\n",
      "        [0.02745098, 0.03137255, 0.05490196],\n",
      "        [0.03137255, 0.04313726, 0.05882353],\n",
      "        [0.03137255, 0.05098039, 0.09019608]],\n",
      "\n",
      "       [[0.02745098, 0.04313726, 0.03529412],\n",
      "        [0.02745098, 0.03529412, 0.03529412],\n",
      "        [0.02745098, 0.03137255, 0.03529412],\n",
      "        ...,\n",
      "        [0.02745098, 0.03529412, 0.03921569],\n",
      "        [0.03137255, 0.03529412, 0.03921569],\n",
      "        [0.03137255, 0.03921569, 0.04705882]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.5411765 , 0.52156866, 0.5058824 ],\n",
      "        [0.5294118 , 0.49411765, 0.41568628],\n",
      "        [0.50980395, 0.47058824, 0.40784314],\n",
      "        ...,\n",
      "        [0.52156866, 0.45882353, 0.4627451 ],\n",
      "        [0.52156866, 0.4862745 , 0.4627451 ],\n",
      "        [0.50980395, 0.49803922, 0.5254902 ]],\n",
      "\n",
      "       [[0.44705883, 0.5137255 , 0.49411765],\n",
      "        [0.4509804 , 0.4627451 , 0.42745098],\n",
      "        [0.49803922, 0.4627451 , 0.43137255],\n",
      "        ...,\n",
      "        [0.4862745 , 0.50980395, 0.5058824 ],\n",
      "        [0.5019608 , 0.49019608, 0.50980395],\n",
      "        [0.5019608 , 0.5058824 , 0.5058824 ]],\n",
      "\n",
      "       [[0.48235294, 0.5019608 , 0.4862745 ],\n",
      "        [0.49411765, 0.4862745 , 0.4392157 ],\n",
      "        [0.5137255 , 0.5058824 , 0.44313726],\n",
      "        ...,\n",
      "        [0.5882353 , 0.5529412 , 0.5137255 ],\n",
      "        [0.54901963, 0.52156866, 0.5137255 ],\n",
      "        [0.5529412 , 0.5019608 , 0.5058824 ]]], dtype=float32), 29)\n"
     ]
    }
   ],
   "source": [
    "iter = ds.make_one_shot_iterator()\n",
    "el = iter.get_next()\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(el)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2222\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-489854edf4b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'2011_09_26'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpreprocess_filtering_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserieses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdir_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'/home/shahar_zuler/ProjectNexar'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/shahar_zuler/ProjectNexar/preprocessing/preprocess_func_v02.py\u001b[0m in \u001b[0;36mpreprocess_filtering_data\u001b[1;34m(date, serieses, state, dir_path)\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;31m# path_GT = 'C:/Users/User/Dropbox/CS231n_project/BMVC15_StixelDataset/' #path for auto ground truth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[0mGT_file_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'stixelsGroundTruth'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m     \u001b[0mground_truth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGT_file_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"series_date\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"series_id\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"frame_id\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"x\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Train_Test\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#making GT pd.df\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mseries\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mserieses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/shahar_zuler/assignment1/.envGPU/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    710\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/shahar_zuler/assignment1/.envGPU/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 455\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    456\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/shahar_zuler/assignment1/.envGPU/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1067\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'skipfooter not supported for iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1069\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1070\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1071\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'as_recarray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/shahar_zuler/assignment1/.envGPU/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1837\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1838\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1839\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1840\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1841\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m/home/shahar_zuler/assignment1/.envGPU/lib/python3.5/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_integer_dtype\u001b[1;34m(arr_or_dtype)\u001b[0m\n\u001b[0;32m    775\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mis_integer_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m     \"\"\"\n\u001b[0;32m    779\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprovided\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0man\u001b[0m \u001b[0minteger\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "date='2011_09_26'\n",
    "preprocess_filtering_data(date=date, serieses = [1, 2, 9], dir_path='/home/shahar_zuler/ProjectNexar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO:\n",
    "- split to train and validation in a smarter way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2503, 370, 24, 3)\n",
      "Train data shape:  (2000, 370, 24, 3)\n",
      "Train labels shape:  (2000,)\n",
      "Validation data shape:  (500, 370, 24, 3)\n",
      "Validation labels shape:  (500,)\n",
      "Test data shape:  (2503, 370, 24, 3)\n",
      "Test labels shape:  (2503,)\n"
     ]
    }
   ],
   "source": [
    "def get_data(num_training=2000, num_validation=500, num_test=10000, date='2011_09_26'):\n",
    "    # Load the raw KITTI data\n",
    "    \n",
    "    #X_train, y_train =preprocess_filtering_data(date=date, serieses = [1,2], dir_path='/home/shahar_zuler/ProjectNexar')\n",
    "    #X_test, y_test = preprocess_data(date=date, state = 'Test', dir_path='/home/shahar_zuler/ProjectNexar')\n",
    "    X_train = np.load('X_train.npy')\n",
    "    y_train = np.load('y_train.npy')\n",
    "    print (X_train.shape)\n",
    "    X_test = X_train\n",
    "    y_test = y_train\n",
    "    \n",
    "    # Subsample the data\n",
    "    mask = range(num_training, num_training + num_validation)\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = range(num_training)\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "#     mask = range(num_test)\n",
    "#     X_test = X_test[mask]\n",
    "#     y_test = y_test[mask]\n",
    "\n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis=0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 42.,  53.,   0.,  97.,   0., 187.,   0., 182.,   0., 188.,   0.,\n",
       "        143.,   0.,  30.,   0.,   0.,  40.,   0., 157.,   0.,  68.,   0.,\n",
       "         98.,   0.,   8.,   0.,  13.,   0.,  71.,   0.,  54.,  30.,   0.,\n",
       "        111.,   0.,  60.,   0.,  67.,   0.,  37.,   0.,  15.,   0.,  88.,\n",
       "          0., 121.,  40.]),\n",
       " array([11.        , 11.53191489, 12.06382979, 12.59574468, 13.12765957,\n",
       "        13.65957447, 14.19148936, 14.72340426, 15.25531915, 15.78723404,\n",
       "        16.31914894, 16.85106383, 17.38297872, 17.91489362, 18.44680851,\n",
       "        18.9787234 , 19.5106383 , 20.04255319, 20.57446809, 21.10638298,\n",
       "        21.63829787, 22.17021277, 22.70212766, 23.23404255, 23.76595745,\n",
       "        24.29787234, 24.82978723, 25.36170213, 25.89361702, 26.42553191,\n",
       "        26.95744681, 27.4893617 , 28.0212766 , 28.55319149, 29.08510638,\n",
       "        29.61702128, 30.14893617, 30.68085106, 31.21276596, 31.74468085,\n",
       "        32.27659574, 32.80851064, 33.34042553, 33.87234043, 34.40425532,\n",
       "        34.93617021, 35.46808511, 36.        ]),\n",
       " <a list of 47 Patch objects>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd740353048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train, bins = 47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clear old variables\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# define our input (e.g. the data that changes every batch)\n",
    "# The first dim is None, and gets sets automatically based on batch size fed in\n",
    "X = tf.placeholder(tf.float32, [None, 370, 24, 3])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "# define model\n",
    "def stixel_model(X,y,is_training):\n",
    "    conv1 = tf.layers.conv2d(inputs=X, filters=64, kernel_size=[11, 5], \n",
    "                             padding=\"same\", use_bias=True, activation=tf.nn.relu)\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[8, 4], strides=(8, 4))\n",
    "    conv2 = tf.layers.conv2d(inputs=pool1, filters=200, kernel_size=[5, 3], \n",
    "                             padding=\"same\", use_bias=True, activation=tf.nn.relu)\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[4, 3], strides=(4,3))\n",
    "#     pool2_flat = tf.reshape(pool2, [-1, 1 * 11* 200])\n",
    "    pool2_flat = tf.layers.flatten(inputs=pool2)\n",
    "    dense3 = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "    dropout3 = tf.layers.dropout(inputs=dense3, rate=0.5, training=is_training)\n",
    "    dense4 = tf.layers.dense(inputs=dropout3, units=2048, activation=tf.nn.relu)\n",
    "    dropout4 = tf.layers.dropout(inputs=dense4, rate=0.5, training=is_training)\n",
    "    y_out = tf.layers.dense(inputs=dropout4, units=47)\n",
    "    return y_out\n",
    "\n",
    "y_out = stixel_model(X,y,is_training)\n",
    "\n",
    "\n",
    "#predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    " #     \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "  #    \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# total_loss = tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf.one_hot(indices=y, depth=50, axis=-1), logits=y_out)\n",
    "total_loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.one_hot(indices=y, depth=47, axis=-1), logits=y_out)\n",
    "#tf.summary.histogram('total_loss',total_loss) ####################\n",
    "mean_loss = tf.reduce_mean(total_loss)\n",
    "\n",
    "\n",
    "print(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# optimizer = tf.train.RMSPropOptimizer(learning_rate=1e-2, momentum=0.9) \n",
    "# tf.train.MomentumOptimizer(learning_rate=1e-2, momentum=0.9)\n",
    "\n",
    "'''# decay every 10000 steps with a base of 0.5:\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "starter_learning_rate = 1e-2\n",
    "learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "                                           decay_steps=10000, decay_rate=0.5, staircase=True)\n",
    "\n",
    "# Passing global_step to minimize() will increment it at each step.\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=1e-2, momentum=0.9, decay=0)\n",
    "train_step = optimizer.minimize(mean_loss, global_step=global_step)'''\n",
    "# define our optimizer\n",
    "optimizer = tf.train.AdamOptimizer(5e-4) # select optimizer and set learning rate #### 5e-4\n",
    "train_step = optimizer.minimize(mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# batch normalization in tensorflow requires this extra dependency\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(extra_update_ops):\n",
    "    train_step = optimizer.minimize(mean_loss)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def run_model(session, predict, loss_val, Xd, yd,\n",
    "              epochs=1, batch_size=128, print_every=50,\n",
    "              training=None, plot_losses=False):\n",
    "    \n",
    "    train_writer = tf.summary.FileWriter( './logs/2/train ', sess.graph) #TB\n",
    "    # have tensorflow compute accuracy\n",
    "    the_prediction = tf.argmax(predict,axis=1)\n",
    "    correct_prediction = tf.equal(tf.argmax(predict,axis=1),y)\n",
    "#     correct_prediction = correct = tf.equal(tf.argmax(tf.nn.sigmoid(predict),axis=1),y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.histogram('accuracy',accuracy) #TB\n",
    "    tf.summary.scalar('accuracy',accuracy)\n",
    "    tf.summary.scalar('mean_loss',mean_loss)\n",
    "\n",
    "    # shuffle indicies\n",
    "    train_indicies = np.arange(Xd.shape[0])\n",
    "    np.random.shuffle(train_indicies)\n",
    "\n",
    "    training_now = training is not None\n",
    "\n",
    "    variables = ['_', mean_loss,correct_prediction, the_prediction ,accuracy] #TB\n",
    "\n",
    "    # setting up variables we want to compute (and optimizing)\n",
    "    # if we have a training function, add that to things we compute    \n",
    "    if training_now:\n",
    "        variables[-1] = training\n",
    "    \n",
    "    # counter \n",
    "    iter_cnt = 0\n",
    "    for e in range(epochs):\n",
    "        # keep track of losses and accuracy\n",
    "        correct = 0\n",
    "        losses = []\n",
    "        # make sure we iterate over the dataset once\n",
    "        for i in range(int(math.ceil(Xd.shape[0]/batch_size))):\n",
    "            # generate indicies for the batch\n",
    "            start_idx = (i*batch_size)%Xd.shape[0]\n",
    "            idx = train_indicies[start_idx:start_idx+batch_size]\n",
    "            \n",
    "            # create a feed dictionary for this batch\n",
    "            feed_dict = {X: Xd[idx,:],\n",
    "                         y: yd[idx],\n",
    "                         is_training: training_now}\n",
    "            # get batch size\n",
    "            actual_batch_size = yd[idx].shape[0]\n",
    "            \n",
    "            merge = tf.summary.merge_all() #TB\n",
    "            variables[0] = merge #TB\n",
    "            \n",
    "            # have tensorflow compute loss and correct predictions\n",
    "            # and (if given) perform a training step\n",
    "  \n",
    "            summary, loss, corr,pred, _ = session.run(variables,feed_dict=feed_dict) #TB\n",
    "            print('pred: ', pred)\n",
    "            train_writer.add_summary(summary, iter_cnt) #TB\n",
    "    \n",
    "            # aggregate performance stats\n",
    "            losses.append(loss*actual_batch_size)\n",
    "            correct += np.sum(corr)\n",
    "            \n",
    "            # print every now and then\n",
    "            if training_now and (iter_cnt % print_every) == 0:\n",
    "                print(\"Epoch {0}: Iteration {1}: with minibatch training loss = {2:.3g} and accuracy of {3:.2g}\"\\\n",
    "                      .format(e, iter_cnt,loss,np.sum(corr)/actual_batch_size))\n",
    "            iter_cnt += 1\n",
    "        total_correct = correct/Xd.shape[0]\n",
    "        total_loss = np.sum(losses)/Xd.shape[0]\n",
    "        print(\"Epoch {2} Overall loss = {0:.3g} and accuracy of {1:.3g}\"\\\n",
    "              .format(total_loss,total_correct,e+1))\n",
    "        if plot_losses:\n",
    "            plt.plot(losses)\n",
    "            plt.grid(True)\n",
    "            plt.title('Epoch {} Loss'.format(e+1))\n",
    "            plt.xlabel('minibatch number')\n",
    "            plt.ylabel('minibatch loss')\n",
    "            plt.show()\n",
    "    \n",
    "    return total_loss,total_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "pred:  [20  4  4 41 30  1 29  6 46 42  4 46 11 29 42 42  0  0 22 29 40 38 15 29\n",
      " 23 39 31 18  4 42 41 29 12 20  0 27 21  4 21 42 46 11 41 25 30 29 36 38\n",
      " 18 21 32 39 37  6 41 44 13 38 11 22 41 11  8 27 36 44  3 12 13 21 24 32\n",
      " 28  1 13 39  3 20 41 22 42 29 41 10 14 22 27 23  3 29 44 15 38 11 25 15\n",
      " 41 36  4 29 31 46 29 37 32 13 21 45 28 25 42 21 20 13 44 40 23  4  1 36\n",
      "  0 17 42 33 13 22 23  3]\n",
      "Epoch 0: Iteration 0: with minibatch training loss = 0.691 and accuracy of 0.0078\n",
      "pred:  [11 14 41  4 25 29 41 21 29 13 26 42 18 31 42 41 13  7  7  2 15 21 11 27\n",
      " 26 15  6 16  7  1 15 11 22 41 11 21  7 40 25 40 45 13 15  8 21 23  6  1\n",
      " 45 41 40 21 21 41 31 20 33 20 29 21 20 11  7  7 11 11 29  1 21 15 45 38\n",
      " 20  0 21 20 39 11 23  7 29 15 20 40 44 10  3  7 26  3 13  7 15 20 21 25\n",
      " 15 18 15 20 21  7  4 22 17 41 44 11 33  7 20 11 39  8 11  7 38 20 23 15\n",
      " 21  7 45 26 15 18 44 21]\n",
      "pred:  [25 18 39 29 41 18  0  7 45 41 18 20 13 29  9 39 40 40 14 26 13 39  8 32\n",
      " 20 18 18 39  1  7  1 15 20 18 21  7 23 25  7 18 16  7 41  0 21 22 21 18\n",
      " 16 42 18  0 13 15 13 21 20 22 20 40 33 40 44 42 18  1 18 31 26  0 29 13\n",
      "  7 26  1  0 18 10 40 40 18 18  7 44 45 44 42 15 20 26 13 22 23 29  8  7\n",
      " 22  9 21 18 10 20 44 18 17 21 18 20 38 13 18  7 18 29 41 41 21 17 11  7\n",
      " 44 22 11 41 31 39 21 44]\n",
      "pred:  [ 1 21 39  1 13 42 44 40 39  7 42 21 15 45 41 15  7  7  7  7 15  7 18 29\n",
      " 45 22  8 29 41  7 13  1 22 45  1 18  1 44 42 25 21 13  1 40  7 44  1 32\n",
      "  7 21 26 15 41 16 13  1 21 22  2 13 45 41 23 13 18 21 14 36 29 26 18  9\n",
      " 45 15  7 26 20 15 22 20 29 13 42 20 42  1 11 42  7 22 26 45 17 18 18 22\n",
      "  9 22 29 17 29 13 20 31 22 26 31 26 15 18 26 18 41 15 32 14 14 21 22 21\n",
      "  0 17 20 18 31  7 22 44]\n",
      "pred:  [14 25 20 17 42 21 18 45 11 44 18 22 42  1 20 22 46 41 21 45 29 45 21  7\n",
      " 20  1 12  1 21 39 23 20 21 45 31 15 26 21  7 31 15  1 29 18 15 39 29 45\n",
      " 21 31 29 36 31 39 16 13 18 18 16 40 27 29 21 18 18 15 21 42 41 42 26 21\n",
      "  7 41 18 29 26 23  1 21 15 42 26 21 21 22 26 18 14 42  1  1 18 18 18 29\n",
      " 29 21 17 18 20 45 21 29 41 42 20 29 26 36 29 18 17 15 21 21 45 15 15 21\n",
      " 22 15 13 31 21 21  1 45]\n",
      "pred:  [21 21 29 44 41 32 15 23 27 17 29 44 18 14 29 21  1 29 15 32 21 31 14 13\n",
      " 39  1 31 13 34 20 39 45 29 26 36 21 31 45 17 31 18 26 41 29 16 29 21 29\n",
      "  1  9 29 29 14 29 29 29 14 31 17 22 13 29 29 26  9 29 22 23 36 20 31 14\n",
      " 29 21 21 14 21 15 15 21 10 21 10 31 17 21 21 17 21 29  1  9 22 31 21 17\n",
      " 22 21 20 11 41 36  1 39 17 29 29 16 13 29 18 13 34 44 22 26 44 29 15 22\n",
      " 44 41 14 40 21 26 29 18]\n",
      "Epoch 0: Iteration 5: with minibatch training loss = 0.18 and accuracy of 0.047\n",
      "pred:  [22 25 13 17 21 35 14 34 13 29 26 31 14 17 29 17 21 21 17 29 14 21 13 17\n",
      " 15 17 17 31 23 17 21 29 31 17 21 17 14 21 31 17 17 21 16 21 16 21 14 16\n",
      " 14 31 17  1 15 26 17 17 17 29 18 25 15 17 26 17 17 17 29 17 31 35 21 17\n",
      " 17 14 14 26 17 14 16 14 39 17 29  1 26 21 29 16 14 31 29 16 17 16 31 21\n",
      " 16 15 29 13 29 29 23 14 29 31 21 15 17 16 23 14 21 15 14 17 14 15 17 22\n",
      " 21 29 26 14 26 15 17 29]\n",
      "pred:  [14 17 17 31 15 21 29 14 21 14 29 26 17 16 16 21 17 21 16 14 17 14 31 29\n",
      " 17 31 29 14 16 21 16 21 29 14 21 14 21 29 17 16 29 16 26 21 16 29 21 14\n",
      " 21 21 17 16 26 17 21 21 29 13 23 14 17 16 14 29 29 16 16 14 21 14 17 14\n",
      " 16 14 14 14 34 16 21 17 16 17 16 16 14 21 14 21 16 14 17 16 17 15 14 29\n",
      " 34 29 14 29 14 15 16 29 29 14 14 17 21 16 14 29 17 16 21 14 14 29 17 21\n",
      " 21 14 17 14 17 21 29 14]\n",
      "pred:  [21 17 14 14 21 14 14 16 23 15 21 17 16 14 15 17 26 14 35 21 17 21 15 21\n",
      " 29 17 21 15 16 21 21 21 21 21 26 21 14 16 16 14 16 15 21 16 29 17 14 17\n",
      " 14 31 34 14 15 17 16 17 14 16 15 17 17 16 15 23 15 29 21 21 14 21 29 14\n",
      " 29 14 17 21 21 16 14 17 14 21 14 17 21 14 21 14 14 14 17 15 21 17 15 16\n",
      " 29 14 16 31 21 17 17 14 17 14 17 17 16 21 21 23 17 17 14 14 29 14 21 16\n",
      " 16 17 17 17 16 21 17 21]\n",
      "pred:  [16 16 16 15 29 21 14 16 16 15 16 14 17 14 16 16 15 16 34 16 14 14 15 14\n",
      " 14 21 34 16 16 21 16 15 15 14 29 14 14 14 15 14 16 14 15 16 29 17 14 14\n",
      " 16 15 14 17 13 14 17 21 29 14 14 21 16 21 16 14 14 21 17 17 16 21 14 34\n",
      " 17 14 21 17 14 16 17 15 16 21 15 21 16 21 21 14 16 15 14 14 14 14 17 23\n",
      " 21 15 21 14 21 14 14 14 14 17 16 14 15 21 16 16 15 15 26 15 21 16 14 15\n",
      " 14 15 14 15 16 21 29 16]\n",
      "pred:  [29 16 23 29 16 14 14 15 31 15 16 23 21 14 15 29 15 15 17 15 22 14 15 15\n",
      " 16 15 17 29 15 21 16 29 34 15 15 14 29 14 29 14 15 21 15 29 16 34 15 16\n",
      " 15 16 14 21 29 29 15 14 16 15 16 17 23 21 29 29 15 15 21 35 21 16 16 16\n",
      " 15 29 15 16 17 15 21 29 29 26 29 16 15 23 23 16 23 15 16 14 14 15 35 15\n",
      " 35 15 35 14 16 17 16 16 21 15 16 23 14 15 35 16 14 21 15 15 15 15 22 15\n",
      " 35 17 14 16 17 16 21 29]\n",
      "Epoch 0: Iteration 10: with minibatch training loss = 0.149 and accuracy of 0.11\n",
      "pred:  [35 21 23 21 15 35 15 34 16 15 15 16 34 29 23 16 29 17 26 23 16 15 15 34\n",
      " 35 15 23 29 29 29 13 15 29 17 14 34 29 31 17 35 15 23 26 29 35 21 34 34\n",
      " 16 16 31 23 35 29 29 29 16 35 15 23 21 35 29 23 16 15 35 13 34 15 15 16\n",
      " 29 21 34 26 29 34 21 14 34 31 21 15 34 15 15 14 34 15 16 34 35 35 17 30\n",
      " 26 35 29 31 35 31 23 17 26 15 13 15 15 26 23 15 29 15 34 13 15 15 22 15\n",
      " 14 15 35 13 29 16 23 15]\n",
      "pred:  [15 29 13 23 30 13 26 23 29 15 30 35 16 35 29 31 26 14 14 15 35 23 34 34\n",
      " 15 34 31 14 29 13 34 31 29 35 35 34 26 35 15 31 15 30 29 16 34 13 15 15\n",
      " 16 14 13 23 16 23 29 31 35 34 30 15 30 14 31 35 13 15 16 35 35 13 35 35\n",
      " 15 16 29 31 15 29 31 15 30 31 35 15 15 35 30 29 13 13 35 35 34 29 15 35\n",
      " 35 30 30 15 14 31 35 17 23 23 35 21 35 31 13 35 34 35 30 15 34 30 30 34\n",
      " 23 31 31 23 22 31 35 15]\n",
      "pred:  [30 31 21 35 14 21 13 17 30 30 17 26 30 13 26 13 34 30 30 11 23 34 12 13\n",
      " 34 26 22 30 30 26 15 30 29 16 35 32 30 22 26 15 15 15 26 35 13 30 34 20\n",
      " 35 34 30 13 34 17 31 26 23 35 26 35 35 13 34 29 13 35 26 35 13 30 15 35\n",
      " 32 35 35 35 26 35 26 35 35 35 22 13 30 35 35 29 23 26 13 13 35 13 35 31\n",
      " 35 35 13 35 35 13 34 22 30 15 23 35 31 15 35 31 16 26 13 23 17 14 31 14\n",
      " 22 31 30 22 35 13 15 35]\n",
      "pred:  [26 13 22 12 26 32 22 35 31 30 31 20 13 15 26 30 14 15 34 12 30 35 11 30\n",
      " 26 31 30 21 31 30 12 13 34 34 13 30 26 34 15 35 30 30 35 26 35 14 26 12\n",
      " 36 11 23 30 13 13 35 26 35 30 22 12 35 29 15 16 26 30 30 30 34 34 30 26\n",
      " 30 30 23 30 17 30 30 13 34 30 34 22 26 30 26 34 31 12 17 21 30 35 13 15\n",
      " 31 35 30 35 30 30 34 13 14 23 35 13 30 31 30 12 30 34 30 17 13 34 13 35\n",
      " 22 35 34 17 22 22 31 31]\n",
      "pred:  [13 23 32 17 34 30 27 34 26 30 13 27 13 30 31 35 12 13 12 22 31 15 30 35\n",
      " 16 34 14 35 14 30 20 13 12 22 13 36 13 13 32 12 30 26 12 34 17 15 13 30\n",
      " 34 16 30 17 26 30 30 27 13 30 22 13 35 30 36 16 12 30 17 12 17 13 14 12\n",
      " 27 12 30 15 30 26 22 13]\n",
      "Epoch 0: Iteration 15: with minibatch training loss = 0.109 and accuracy of 0.025\n",
      "Epoch 1 Overall loss = 0.228 and accuracy of 0.05\n",
      "pred:  [22 20 29 12 30 13 20 27 12 21 13 30 30 22 17 31 22 12 20 27 21 11 30 26\n",
      " 23 23 30 32 36 22 36 21 13 13 27 21 27 36 32 36 36 22 22 12 29 27 30 35\n",
      " 20 32 13 34 27 30 11 13 17 20 16 12 36 15 13 27 36 13 12 36 23 13 15 30\n",
      " 26 28 27 30 15 32 28 21 13 12 12 31 14 13 14 21 12 30 31 27 15 21 21 35\n",
      " 27 13 12 16 27 27 20 16 13 12 12 22 30 30 12 36 26 26 21 27 20 15 27 17\n",
      " 36 28 16 12 12 22 31 14]\n",
      "pred:  [28 13 17 17 36 27 21 36 16 22 35 34 32 36 32 27 36 16 30 36 27 22 27 15\n",
      " 30 16 11 36 20 17 14 27 28 20 27 12 36 20 14 11 27 17 32 17 27 36 31 27\n",
      " 34 21 31 22 27 30 30 20 17 34 22 36 30 28 32 12 34 27 20 27 36 32 36 14\n",
      " 36 28 13 20 13 36 35 16 16 30 27 21 11 27 14 30 14 20 21 12 21 17 14 17\n",
      " 20 13 20 21 27 14 20 26 36 15 32 21 27 30 32 15 34 30 14 20 35 21 32 30\n",
      " 22 31 20 26 36 21 20 27]\n",
      "pred:  [14 32 28 20 20 17 35 36 22 11 36 27 12 17 21 16 28 12 21 12 20 27 12 15\n",
      " 36 14 35 20 36 12 14 27 27 14 30 27 27 15 21 36 14 17 12 12 27 20 16 17\n",
      " 17 21 36 21 21 17 12 21 36 11 16 27 16 11 21 21 15 27 36 14 12 27 21 21\n",
      " 30 13 27 21 32 22 14 12 15 35 32 13 12 21 27 14 12 36 22 27 13 20 16 21\n",
      " 14 21 11 21 36 16 12 15 27 27 21 16 27 26 16 15 21 17 16 20 32 12 27 14\n",
      " 16 21 22 15 36 22 27 16]\n",
      "pred:  [21 27 12 27 27 16 16 36 17 21 14 21 36 14 27 23 17 26 21 21 14 20 20 22\n",
      " 32 17 14 32 21 27 31 20 14 11 16 21 21 16 13 21 11 20 14 21 21 14 14 17\n",
      " 21 27 21 20 12 12 27 27 35 17 16 27 16 36 27 14 15 20 21 15 32 15 27 12\n",
      " 21 21 22 16 32 20 15 16 28 23 27 27 16 18 14 22 22 21 34 22 28 36 17 12\n",
      " 21 18 14 21 27 17 32 16 21 27 22 14 14 11 21 12 27 27 20 36 16 32 16 14\n",
      " 12 15 23 27 27 21 21 14]\n",
      "pred:  [17 20 12 23 14 16 21 16 17 27 21 14 16 28 27 15 27 17 28 36 16 21 36 21\n",
      " 27 20 21 12 14 14 27 29 12 21 20 17 28 32 12 21 17 27 27 32 16 27 27 27\n",
      " 20 14 28 21 27 16 14 16 17 17 14 34 16 14 17 15 21 12 21 27 14 12 14 23\n",
      " 36 36 36 17 20 21 21 27 21 17 27 36 27 23 17 36 21 21 20 21 12 11 21 15\n",
      " 28 27 13 17 21 27 31 20 27 27 27 14 27 17 21 14 36 21 14 21 20 21 21 36\n",
      " 21 15 27 13 17 15 17 20]\n",
      "Epoch 1: Iteration 20: with minibatch training loss = 0.0971 and accuracy of 0.078\n",
      "pred:  [16 27 21 14 21 36 21 12 21 15 20 21 17 27 21 17 15 27 21 21 20 21 14 14\n",
      " 15 16 27 18 21 36 21 14 15 21 21 17 21 14 21 15 16 15 21 15 21 21 36 16\n",
      " 27 22 23 21 14 16 21 17 16 17 21 21 14 14 14 25 21 21 16 14 28 14 14 16\n",
      " 15 15 12 14 36 27 14 14 17 21 15 27 20 14 15 15 21 27 14 14 15 21 36 27\n",
      " 14 20 27 32 27 16 27 21 21 14 14 21 27 17 22 21 14 27 21 27 21 15 16 21\n",
      " 16 17 15 21 27 15 14 14]\n",
      "pred:  [21 15 14 15 16 21 14 14 15 27 14 21 21 27 21 21 15 15 27 21 20 21 14 14\n",
      " 15 14 20 11 17 16 14 21 23 17 14 21 21 16 20 34 27 14 14 21 16 14 16 21\n",
      " 14 21 12 21 17 17 14 21 16 21 27 21 15 16 22 21 27 23 21 21 17 16 12 14\n",
      " 16 22 17 21 16 21 15 14 21 36 21 14 17 17 18 16 14 21 15 18 14 15 36 27\n",
      " 21 17 21 16 21 15 15 27 14 21 14 21 14 14 15 17 21 17 14 21 21 21 21 21\n",
      " 21 21 16 16 14 27 17 21]\n",
      "pred:  [14 21 14 16 23 21 17 14 16 21 21 27 17 14 23 21 21 17 21 21 15 21 27 16\n",
      " 14 21 15 17 23 17 21 14 21 15 14 21 16 16 17 27 21 14 21 14 16 21 16 21\n",
      " 27 17 16 31 16 34 16 14 16 14 14 14 14 36 21 23 21 21 21 21 14 14 16 16\n",
      " 14 16 16 21 16 23 23 21 14 17 21 15 27 18 18 21 16 14 21 18 21 15 21 20\n",
      " 14 21 15 21 14 36 14 14 27 17 14 14 14 17 27 17 22 16 17 14 16 21 17 15\n",
      " 36 18 21 14 14 17 21 14]\n",
      "pred:  [15 14 14 15 20 14 14 16 15 16 14 17 15 14 14 16 17 21 14 14 14 23 15 14\n",
      " 21 21 21 17 29 15 17 29 17 17 21 21 21 21 14 14 17 16 17 23 15 16 14 17\n",
      " 33 14 16 21 15 17 15 15 21 14 21 14 14 14 17 21 16 17 14 15 18 14 21 25\n",
      " 21 27 23 21 14 27 21 16 17 13 14 21 14 17 16 15 16 14 16 15 14 15 14 14\n",
      " 16 17 14 27 21 14 15 21 17 14 15 17 29 15 14 14 14 17 14 17 23 14 15 14\n",
      " 18 16 25 21 15 15 21 20]\n",
      "pred:  [14 15 29 16 21 21 15 15 21 16 14 34 15 25 16 16 16 16 23 16 16 16 16 17\n",
      " 21 14 15 21 16 21 15 21 14 16 14 21 17 14 16 16 16 15 21 23 14 16 15 21\n",
      " 17 17 15 16 16 17 21 16 21 28 16 21 21 15 14 14 17 16 23 17 17 21 25 16\n",
      " 15 16 15 14 27 21 14 17 14 16 21 17 17 15 17 16 17 17 14 15 17 16 14 15\n",
      " 21 15 15 15 17 16 16 15 14 15 17 15 17 16 14 14 21 16 17 15 17 14 16 15\n",
      " 21 17 17 21 21 14 15 21]\n",
      "Epoch 1: Iteration 25: with minibatch training loss = 0.0949 and accuracy of 0.11\n",
      "pred:  [17 14 21 17 15 15 15 21 33 15 15 21 15 21 21 16 16 21 21 29 18 14 21 21\n",
      " 15 14 23 28 15 15 17 17 14 15 29 14 15 15 21 16 15 15 16 14 29 21 21 16\n",
      " 23 14 16 18 27 14 21 16 14 15 16 14 21 16 15 16 17 16 14 16 14 15 15 21\n",
      " 21 17 14 14 17 14 17 21 29 14 15 18 14 15 14 14 15 17 16 21 21 17 29 14\n",
      " 15 15 14 21 17 15 21 17 17 14 14 17 16 17 14 17 21 21 14 14 25 21 21 21\n",
      " 17 15 16 15 15 16 21 15]\n",
      "pred:  [16 15 14 14 15 14 14 17 35 16 15 15 21 14 14 14 15 14 16 21 15 21 17 15\n",
      " 21 14 21 15 21 16 29 17 15 35 16 15 16 17 29 17 15 34 15 15 15 16 21 15\n",
      " 29 14 21 14 15 17 16 16 15 16 17 14 14 14 17 15 15 14 17 21 15 14 14 15\n",
      " 23 16 21 15 18 14 21 16 15 15 18 29 14 23 14 16 14 21 15 34 16 15 14 14\n",
      " 15 15 15 16 29 16 16 15 16 34 15 15 17 17 21 29 17 15 16 16 29 16 15 15\n",
      " 16 17 15 15 15 15 14 16]\n",
      "pred:  [14 14 14 14 29 15 15 15 16 21 17 14 14 29 17 29 16 14 17 15 21 21 29 21\n",
      " 15 34 21 15 14 14 14 16 14 16 23 16 21 29 15 15 14 15 15 29 16 15 15 15\n",
      " 14 16 14 21 16 15 14 14 16 14 17 17 16 14 15 14 15 21 15 18 15 14 21 15\n",
      " 17 16 29 23 14 14 16 14 29 15 16 16 15 16 15 15 16 17 16 29 14 16 21 16\n",
      " 17 14 16 15 15 14 21 14 16 21 21 21 16 21 15 18 16 17 16 16 15 15 15 21\n",
      " 16 14 21 17 15 15 16 15]\n",
      "pred:  [16 15 15 16 21 14 16 15 15 15 21 31 15 17 14 17 15 14 21 14 14 14 15 16\n",
      " 16 21 17 14 16 14 17 21 16 29 16 35 23 16 14 14 21 15 15 21 17 29 15 15\n",
      " 21 14 21 15 15 16 15 21 15 16 16 14 14 14 21 15 21 14 15 16 17 15 15 16\n",
      " 15 16 14 29 14 15 14 16 16 15 14 21 21 21 17 17 16 15 17 16 16 26 14 21\n",
      " 16 16 15 15 15 16 16 14 16 15 16 23 14 25 16 14 16 14 17 17 14 15 21 16\n",
      " 29 15 15 14 23 14 16 14]\n",
      "pred:  [14 15 15 15 35 34 14 17 16 15 15 15 14 16 15 14 17 15 14 17 14 29 14 14\n",
      " 34 16 21 21 14 35 14 14 15 35 14 14 15 14 15 16 15 15 16 17 16 21 16 16\n",
      " 29 15 14 16 14 15 29 16 21 15 14 21 15 17 14 14 21 14 14 14 35 14 14 16\n",
      " 23 16 34 17 35 23 21 14 16 14 21 14 16 17 15 14 15 15 16 14 15 15 15 15\n",
      " 16 14 16 15 16 16 22 16 23 16 15 14 14 15 17 15 23 21 14 29 17 15 29 17\n",
      " 15 29 14 14 16 15 16 15]\n",
      "Epoch 1: Iteration 30: with minibatch training loss = 0.0944 and accuracy of 0.07\n",
      "pred:  [14 16 14 35 14 29 14 15 21 15 14 21 16 14 15 15 15 15 21 16 15 15 15 16\n",
      " 16 34 17 35 16 14 23 15 17 14 15 16 14 14 15 15 16 29 15 16 35 21 16 21\n",
      " 23 15 15 15 15 14 15 14 15 15 17 15 23 15 34 14 15 21 15 17 14 14 16 14\n",
      " 16 14 14 15 21 15 14 14]\n",
      "Epoch 2 Overall loss = 0.0963 and accuracy of 0.0785\n",
      "pred:  [14 15 15 16 14 14 15 35 16 15 14 14 21 17 14 16 15 16 16 21 14 14 29 14\n",
      " 14 17 15 16 15 15 15 14 15 16 21 15 15 15 14 15 14 17 15 15 15 15 15 14\n",
      " 35 21 15 29 15 21 21 15 15 15 16 14 14 35 16 15 16 16 14 16 35 16 15 17\n",
      " 16 15 21 15 21 14 14 15 23 21 15 15 15 16 15 14 16 16 14 35 14 15 15 14\n",
      " 16 15 21 14 14 14 16 14 14 15 15 15 15 14 14 14 35 15 15 29 14 17 15 16\n",
      " 14 17 14 21 17 16 15 14]\n",
      "pred:  [16 21 15 35 22 16 35 35 14 15 14 34 14 35 35 14 16 14 14 15 15 21 15 14\n",
      " 23 16 16 17 14 35 23 35 15 14 16 15 15 15 15 15 16 35 21 15 15 16 21 29\n",
      " 16 15 15 29 17 15 15 29 16 15 15 21 14 14 14 15 14 15 35 16 14 15 16 15\n",
      " 21 15 16 14 21 15 15 15 29 15 15 14 29 29 14 15 15 21 15 21 13 14 16 15\n",
      " 15 21 15 13 14 15 14 15 14 14 15 14 15 14 15 23 16 15 21 16 16 14 15 29\n",
      " 16 35 21 16 34 14 17 14]\n",
      "pred:  [14 21 15 16 21 15 15 21 14 15 15 23 15 16 15 14 35 16 15 14 29 14 15 17\n",
      " 14 35 16 16 15 14 15 14 21 15 14 15 14 15 21 23 14 15 14 14 15 15 14 21\n",
      " 15 15 15 29 15 14 23 21 14 14 16 16 16 35 35 14 14 15 16 15 16 14 14 29\n",
      " 16 16 15 29 14 29 35 17 14 29 23 16 35 16 16 15 16 29 14 14 14 34 17 14\n",
      " 15 16 14 29 15 14 14 15 17 14 35 16 15 16 15 16 23 15 16 16 14 35 15 35\n",
      " 35 14 17 29 14 23 15 15]\n",
      "pred:  [15 21 29 14 35 15 15 16 15 16 35 15 35 29 16 34 21 15 16 16 14 14 16 15\n",
      " 21 16 14 16 15 21 15 15 35 14 15 15 16 14 35 35 35 29 14 15 15 21 16 34\n",
      " 15 16 16 14 14 15 16 11 34 23 14 15 15 15 21 14 15 21 15 16 14 14 14 15\n",
      " 15 35 15 21 16 15 14 16 14 35 16 15 21 15 14 35 29 21 14 23 23 14 15 15\n",
      " 21 16 34 35 35 21 35 15 14 15 14 16 21 16 15 21 14 17 15 15 14 15 16 14\n",
      " 35 14 14 21 35 15 16 14]\n",
      "Epoch 2: Iteration 35: with minibatch training loss = 0.0915 and accuracy of 0.062\n",
      "pred:  [16 21 16 15 21 16 14 15 16 15 14 15 34 14 35 14 14 35 23 14 15 34 14 15\n",
      " 23 15 21 14 35 16 35 14 17 14 15 16 15 17 17 16 35 15 17 14 35 15 15 15\n",
      " 35 15 14 35 16 35 15 21 15 29 17 15 17 15 16 15 15 23 14 15 16 15 14 15\n",
      " 14 16 35 15 23 21 16 31 14 14 35 14 15 35 16 15 15 21 14 15 15 35 14 21\n",
      " 35 15 23 15 23 15 15 14 15 14 14 21 16 21 35 15 14 14 15 34 14 21 29 15\n",
      " 15 17 15 16 16 15 17 14]\n",
      "pred:  [23 17 14 14 35 35 17 16 15 21 23 15 16 21 16 34 14 15 21 21 21 16 14 35\n",
      " 31 21 15 23 14 17 15 15 15 29 14 17 16 15 17 15 16 14 23 14 21 14 14 23\n",
      " 35 23 29 35 15 35 16 15 21 35 14 21 15 15 15 21 16 21 16 14 15 14 16 35\n",
      " 17 21 21 21 16 16 15 35 35 15 16 21 16 15 21 35 15 15 15 17 14 15 35 15\n",
      " 15 14 16 23 14 17 21 15 16 14 14 16 14 15 16 17 23 17 15 35 16 15 17 15\n",
      " 14 35 14 15 23 35 14 14]\n",
      "pred:  [15 23 15 14 15 14 17 34 23 23 21 14 21 14 23 15 15 16 16 15 35 17 14 15\n",
      " 16 17 21 21 14 14 21 21 17 15 35 29 15 17 15 14 15 15 35 16 17 23 21 35\n",
      " 14 14 17 21 23 14 15 16 14 29 15 14 14 17 35 15 17 35 29 21 15 21 21 17\n",
      " 16 14 21 15 17 21 14 14 14 35 29 16 21 21 16 14 14 14 15 21 23 13 35 16\n",
      " 21 14 16 21 21 16 35 14 21 15 14 29 17 15 16 21 21 13 15 35 15 15 21 21\n",
      " 17 15 16 15 16 15 15 16]\n",
      "pred:  [14 16 29 17 16 15 17 34 21 29 15 35 35 21 15 15 21 15 29 35 21 16 21 35\n",
      " 21 15 15 15 15 35 14 14 14 23 21 15 35 15 35 17 34 21 29 14 14 35 17 14\n",
      " 14 16 16 29 17 17 16 35 35 23 17 14 21 21 14 14 21 15 21 14 14 16 14 14\n",
      " 29 34 21 16 16 13 21 35 15 14 21 21 21 17 15 34 35 14 15 14 21 15 16 17\n",
      " 21 35 29 29 17 17 14 15 15 17 35 17 16 21 16 21 14 17 15 17 15 21 13 17\n",
      " 15 21 14 34 16 16 14 16]\n",
      "pred:  [15 35 15 14 21 14 17 17 34 15 14 16 29 21 34 14 21 16 15 29 21 17 35 14\n",
      " 34 23 29 21 21 35 21 16 21 35 15 23 14 21 14 17 17 17 34 16 21 29 21 16\n",
      " 21 16 17 15 17 15 17 15 17 21 16 35 15 21 35 34 23 14 35 16 15 21 21 23\n",
      " 14 17 17 14 14 13 14 14 17 23 29 16 16 29 14 21 14 21 14 21 16 14 14 21\n",
      " 17 29 23 23 35 21 21 16 21 21 17 21 16 16 29 21 16 15 17 15 17 14 23 15\n",
      " 21 35 13 29 15 15 17 15]\n",
      "Epoch 2: Iteration 40: with minibatch training loss = 0.0903 and accuracy of 0.062\n",
      "pred:  [14 21 23 16 13 16 23 15 26 14 15 23 35 14 17 15 16 21 17 17 17 21 35 23\n",
      " 29 13 16 14 29 29 15 21 14 15 14 21 15 14 21 16 20 15 15 16 14 15 35 15\n",
      " 35 23 15 34 15 15 35 35 16 14 14 17 15 13 16 21 21 35 16 21 16 23 35 23\n",
      " 14 15 17 17 16 14 14 14 14 14 14 14 34 17 16 14 17 14 21 22 35 21 15 16\n",
      " 15 16 15 17 14 16 21 29 14 21 17 14 17 21 15 15 15 21 17 16 14 14 21 16\n",
      " 26 26 14 15 17 14 35 14]\n",
      "pred:  [23 21 16 17 35 14 26 21 14 21 15 15 21 29 16 21 21 21 14 35 15 15 21 35\n",
      " 17 15 34 17 13 16 15 17 15 15 16 13 14 16 21 23 14 21 17 21 29 29 21 17\n",
      " 17 34 16 35 26 29 21 21 21 35 29 17 21 14 21 21 23 21 16 15 21 15 21 21\n",
      " 17 13 23 17 22 16 15 29 21 16 15 16 21 14 23 21 21 23 35 21 16 16 15 17\n",
      " 34 14 14 17 15 17 15 16 17 17 15 21 21 35 16 16 14 16 15 14 15 13 21 35\n",
      " 21 34 15 35 15 21 21 29]\n",
      "pred:  [35 34 16 16 16 21 14 29 21 29 21 29 14 16 17 35 13 35 21 16 17 17 15 21\n",
      " 26 16 14 29 14 15 34 35 34 22 35 22 15 26 14 13 16 21 23 13 16 29 14 16\n",
      " 21 21 29 17 13 16 14 15 15 14 14 21 29 15 34 21 35 17 14 21 21 16 14 23\n",
      " 21 14 34 29 14 17 14 15 14 13 35 17 21 34 14 23 21 13 15 14 23 17 29 21\n",
      " 29 17 29 15 15 17 31 14 21 17 14 15 14 21 35 14 29 14 16 17 29 21 14 16\n",
      " 14 17 16 17 15 21 15 17]\n",
      "pred:  [14 14 21 35 17 17 14 26 17 21 17 29 21 14 16 21 17 21 29 12 21 17 15 21\n",
      " 17 16 13 21 34 16 29 13 34 21 17 16 14 17 15 26 16 16 26 14 21 35 21 14\n",
      " 17 15 34 14 17 14 14 17 21 15 15 21 17 17 16 16 17 13 16 14 34 15 16 34\n",
      " 17 14 26 16 17 13 21 16 13 34 21 15 17 15 16 15 21 15 17 35 17 14 17 26\n",
      " 17 14 13 21 26 31 27 21 17 16 16 26 21 17 15 15 13 15 14 29 16 15 16 29\n",
      " 21 13 15 14 15 15 26 16]\n",
      "pred:  [14 14 35 17 21 21 14 29 17 15 15 16 17 16 34 15 15 21 21 15 15 21 15 16\n",
      " 16 15 34 16 16 17 15 21 23 16 21 14 21 21 34 35 29 16 17 15 17 14 17 15\n",
      " 29 34 14 21 14 13 16 31 17 16 21 29 14 35 16 23 14 29 13 15 17 15 29 14\n",
      " 13 16 21 15 30 21 21 15 14 16 21 14 29 21 29 16 21 15 35 16 13 16 35 14\n",
      " 23 22 22 21 17 16 14 26 34 15 16 16 21 21 14 21 16 13 26 15 16 15 13 14\n",
      " 14 16 21 16 21 21 13 14]\n",
      "Epoch 2: Iteration 45: with minibatch training loss = 0.0873 and accuracy of 0.12\n",
      "pred:  [13 29 13 14 26 17 16 14 26 16 14 16 21 17 29 13 21 22 14 15 16 26 21 21\n",
      " 23 14 35 16 14 21 16 15 26 17 15 26 17 29 14 15 14 16 17 26 26 14 16 15\n",
      " 14 16 16 14 14 29 31 21 35 15 14 21 16 21 22 14 14 16 29 34 14 21 13 13\n",
      " 21 14 15 35 16 15 21 29 14 16 15 17 17 15 15 15 26 21 34 17 16 17 26 15\n",
      " 29 14 16 34 15 15 15 15 21 16 15 21 15 21 14 16 35 13 29 16 17 14 16 15\n",
      " 13 21 17 34 16 15 15 17]\n",
      "pred:  [21 35 21 17 29 16 17 15 13 14 14 13 14 21 21 21 15 15 16 13 15 29 23 13\n",
      " 15 13 21 35 35 16 17 16 23 14 15 14 14 15 26 26 16 30 15 16 13 26 15 21\n",
      " 14 17 16 23 15 13 16 29 14 13 14 17 31 13 26 16 14 21 16 15 14 15 35 15\n",
      " 26 17 30 31 15 15 13 16]\n",
      "Epoch 3 Overall loss = 0.0903 and accuracy of 0.0925\n",
      "pred:  [17 17 21 16 15 15 15 14 17 35 26 16 17 14 14 21 26 21 16 26 16 21 15 14\n",
      " 31 14 35 34 23 15 21 35 14 13 15 27 21 14 15 14 14 15 15 16 21 29 17 16\n",
      " 14 15 16 15 21 15 23 14 35 21 13 21 16 23 15 13 13 17 16 13 14 14 15 21\n",
      " 13 15 15 15 21 15 30 16 35 21 30 15 16 16 35 14 35 14 34 14 17 16 17 15\n",
      " 14 14 15 14 14 15 14 21 14 15 15 27 15 21 14 17 21 21 21 15 34 35 15 21\n",
      " 14 15 16 14 21 14 14 14]\n",
      "pred:  [14 16 16 13 17 29 14 16 29 21 21 13 13 15 23 15 16 15 29 16 15 14 14 15\n",
      " 16 15 15 21 16 17 15 14 15 16 15 21 15 21 14 15 16 16 16 23 35 15 13 21\n",
      " 16 22 16 35 13 16 15 15 14 21 21 15 14 16 16 34 14 26 16 15 16 23 13 21\n",
      " 15 34 17 14 23 15 15 17 21 14 35 14 17 21 14 15 16 22 29 21 15 21 34 21\n",
      " 14 15 14 35 16 29 16 22 21 26 14 21 13 29 14 15 15 15 16 16 17 21 14 15\n",
      " 15 16 21 17 15 13 15 14]\n",
      "pred:  [21 22 14 14 23 16 15 21 21 21 15 16 21 14 16 21 34 35 21 15 15 15 16 35\n",
      " 16 35 15 15 14 13 15 14 17 21 15 17 35 16 16 34 14 29 14 14 14 14 14 15\n",
      " 21 21 15 14 14 15 15 21 14 14 17 16 29 34 14 17 22 21 21 14 17 14 15 15\n",
      " 23 15 14 16 22 21 14 14 14 15 21 21 14 14 21 21 35 15 16 17 30 14 15 14\n",
      " 16 15 14 15 14 15 14 16 15 14 15 21 21 16 21 15 13 14 14 14 34 23 15 15\n",
      " 13 16 26 16 14 21 15 35]\n",
      "Epoch 3: Iteration 50: with minibatch training loss = 0.0878 and accuracy of 0.078\n",
      "pred:  [21 21 21 15 15 14 35 21 21 15 21 14 15 35 14 16 15 15 16 15 29 21 21 15\n",
      " 14 21 15 14 21 16 13 15 15 15 15 14 29 14 14 21 14 21 14 21 29 16 29 15\n",
      " 16 15 16 15 14 15 21 14 15 16 16 16 15 26 14 15 15 15 23 15 16 16 15 14\n",
      " 14 15 16 30 14 14 21 22 16 35 16 29 14 15 14 15 35 15 21 14 15 21 15 21\n",
      " 26 15 15 15 16 16 15 13 21 14 15 14 21 16 15 21 17 16 14 15 16 15 14 15\n",
      " 16 15 14 23 14 30 16 35]\n",
      "pred:  [15 30 15 30 15 15 16 16 16 21 13 21 26 21 21 16 16 15 16 14 22 34 14 15\n",
      " 14 21 14 14 16 13 29 14 16 14 15 15 16 15 15 21 15 15 14 21 13 15 14 15\n",
      " 26 14 14 15 29 16 16 15 16 15 16 15 21 21 15 15 14 35 15 15 15 29 21 21\n",
      " 14 15 16 15 35 14 21 21 35 34 15 14 14 16 22 15 15 29 14 15 21 17 16 15\n",
      " 17 21 17 21 14 15 14 21 14 15 15 14 15 14 15 14 21 16 14 21 14 34 16 16\n",
      " 21 14 15 14 16 15 16 15]\n",
      "pred:  [29 17 14 14 21 16 14 15 21 35 21 21 32 15 15 21 15 15 14 14 14 14 15 35\n",
      " 14 17 14 15 15 17 26 16 16 14 15 21 14 17 15 35 35 14 16 16 26 14 15 15\n",
      " 14 15 22 21 14 16 15 14 14 15 15 14 14 15 21 15 21 14 15 14 35 14 29 26\n",
      " 21 23 17 21 21 14 14 14 14 21 34 15 16 17 21 15 15 14 21 34 14 16 14 14\n",
      " 16 17 16 15 14 14 16 14 14 17 17 15 13 15 26 29 15 35 15 16 17 16 15 14\n",
      " 15 15 26 15 14 14 16 13]\n",
      "pred:  [23 21 14 17 14 14 15 13 16 14 21 15 21 17 21 35 26 14 14 30 14 21 15 15\n",
      " 21 35 16 29 16 21 16 21 21 16 15 17 17 15 34 14 15 14 30 21 16 14 16 21\n",
      " 16 26 16 14 14 17 15 29 14 30 14 14 14 15 15 14 16 29 21 17 30 14 14 16\n",
      " 34 15 17 21 15 26 14 15 15 30 14 23 15 34 34 17 15 30 14 15 14 16 13 14\n",
      " 17 21 16 15 14 14 14 14 17 21 16 14 14 23 35 14 21 14 15 14 15 21 35 14\n",
      " 15 16 21 13 21 16 14 21]\n",
      "pred:  [17 14 15 16 14 30 15 16 30 15 14 14 16 14 16 17 29 29 16 35 31 16 14 15\n",
      " 17 16 15 16 15 21 34 21 16 14 14 16 14 21 16 14 23 26 14 21 17 22 17 35\n",
      " 17 15 22 34 14 16 14 15 14 21 14 21 21 16 30 15 26 14 14 29 14 14 13 17\n",
      " 15 34 14 26 21 14 14 15 15 34 30 22 26 14 21 14 15 21 21 36 14 14 16 15\n",
      " 15 15 21 15 34 17 17 15 17 15 15 15 14 21 14 16 14 17 15 21 14 21 21 14\n",
      " 16 15 26 17 14 17 14 17]\n",
      "Epoch 3: Iteration 55: with minibatch training loss = 0.0845 and accuracy of 0.12\n",
      "pred:  [14 30 16 14 35 29 21 17 13 16 14 21 17 14 17 15 21 14 17 15 21 35 30 15\n",
      " 17 21 14 17 14 17 26 26 21 35 29 21 21 14 17 15 21 15 16 14 16 16 17 15\n",
      " 14 15 17 15 16 16 26 14 16 15 15 14 14 17 15 14 16 14 14 17 29 16 21 15\n",
      " 30 16 16 22 15 14 23 21 16 17 26 15 15 17 34 30 12 15 14 21 17 17 15 14\n",
      " 14 15 16 14 21 22 15 23 15 35 15 23 21 16 35 14 16 17 30 14 21 30 15 15\n",
      " 15 14 29 14 16 16 16 14]\n",
      "pred:  [21 21 13 17 15 30 14 15 21 21 21 14 15 36 21 21 17 27 14 14 15 22 16 14\n",
      " 30 29 14 17 34 15 15 13 23 15 14 21 15 15 14 16 16 16 16 17 15 15 23 21\n",
      " 14 15 15 16 16 15 29 30 36 14 21 14 15 16 15 26 15 21 16 35 21 14 17 30\n",
      " 15 29 15 17 34 23 23 15 16 14 14 16 21 21 21 16 16 21 35 17 21 14 15 16\n",
      " 21 34 16 14 15 20 23 14 15 21 14 21 34 30 16 16 29 21 14 16 14 26 15 23\n",
      " 21 17 16 15 17 21 17 21]\n",
      "pred:  [16 29 14 16 30 16 36 15 15 14 14 30 17 15 16 15 13 15 29 16 21 21 21 14\n",
      " 29 16 16 15 15 16 14 17 14 21 16 16 17 15 29 15 21 16 15 21 14 15 21 14\n",
      " 17 14 13 14 16 15 14 15 17 15 21 26 30 21 17 21 23 30 14 17 26 15 21 16\n",
      " 17 14 15 16 21 29 23 17 30 23 16 14 17 14 14 21 16 15 13 16 16 17 21 14\n",
      " 15 31 17 13 23 15 15 22 17 13 21 15 21 17 16 14 15 17 15 13 26 34 16 21\n",
      " 16 14 15 29 30 16 30 15]\n",
      "pred:  [15 23 29 17 17 26 16 34 15 17 14 14 15 21 26 16 17 17 15 15 16 17 17 21\n",
      " 30 14 15 13 21 21 21 14 14 21 16 16 15 15 16 15 16 16 36 15 23 14 34 17\n",
      " 15 14 16 21 16 16 16 30 23 16 31 15 29 17 15 35 16 16 14 30 21 17 34 16\n",
      " 15 21 17 14 13 17 30 16 23 17 17 21 34 15 14 17 21 14 15 15 14 14 29 15\n",
      " 15 16 14 21 35 16 21 14 29 13 15 35 15 35 16 17 17 34 15 16 17 21 16 21\n",
      " 15 15 23 21 16 13 29 14]\n",
      "pred:  [16 15 30 21 16 15 16 15 29 15 14 35 26 34 15 17 34 17 17 16 14 17 21 22\n",
      " 29 15 26 21 16 15 15 34 21 15 15 21 16 15 23 30 15 14 16 17 14 21 15 14\n",
      " 15 15 15 15 17 13 17 16 34 34 17 13 21 13 21 14 14 17 15 16 16 21 15 14\n",
      " 29 16 15 16 15 17 22 16 13 17 20 26 14 17 35 13 35 15 26 14 29 14 14 30\n",
      " 16 29 15 35 30 16 15 21 15 17 15 29 26 16 14 15 26 14 16 14 30 21 30 27\n",
      " 29 15 21 15 15 17 21 16]\n",
      "Epoch 3: Iteration 60: with minibatch training loss = 0.0832 and accuracy of 0.13\n",
      "pred:  [17 34 30 15 13 15 29 15 17 14 15 15 14 14 35 15 15 16 30 15 16 21 17 22\n",
      " 29 16 30 13 21 15 21 29 15 14 16 26 30 14 21 22 21 16 15 14 14 15 17 14\n",
      " 34 17 21 35 16 14 21 29 16 21 21 14 21 14 17 14 14 17 15 35 14 31 15 15\n",
      " 15 16 16 15 16 15 15 17 17 34 35 13 22 35 29 30 12 17 12 13 16 16 15 15\n",
      " 15 16 15 29 21 16 16 30 29 29 14 16 16 21 17 14 35 35 26 34 15 14 17 30\n",
      " 15 21 21 35 15 21 16 30]\n",
      "pred:  [17 15 14 34 36 17 17 29 30 15 35 14 15 35 14 15 17 16 17 14 21 35 31 29\n",
      " 16 15 15 21 29 17 35 17 14 15 16 26 23 30 14 15 16 35 16 21 21 29 30 21\n",
      " 21 17 14 29 16 21 14 21 12 17 35 16 16 30 14 14 16 29 35 14 23 14 16 35\n",
      " 21 21 30 29 17 15 15 14 14 15 13 34 15 21 15 16 30 16 14 29 21 16 21 15\n",
      " 26 16 13 14 17 16 29 14 17 29 23 14 35 30 30 16 35 35 30 15 17 16 29 14\n",
      " 30 16 21 15 21 35 15 35]\n",
      "pred:  [15 15 14 21 14 36 15 35 15 15 16 14 16 16 35 15 16 21 15 16 15 31 35 16\n",
      " 35 15 14 31 35 14 14 16 34 16 16 16 14 14 26 16 16 29 16 35 35 30 30 21\n",
      " 15 16 22 21 34 34 35 16 16 15 16 14 30 35 17 35 21 16 16 21 15 15 29 16\n",
      " 30 15 30 15 23 29 14 15]\n",
      "Epoch 4 Overall loss = 0.0857 and accuracy of 0.117\n",
      "pred:  [21 16 16 16 16 13 16 14 15 15 16 35 16 35 34 36 30 30 35 30 14 15 13 29\n",
      " 16 21 15 23 12 14 15 23 15 16 14 21 16 14 15 30 16 15 35 23 13 14 15 16\n",
      " 11 16 29 16 15 21 26 15 15 15 35 17 15 14 14 14 14 14 21 15 14 15 15 16\n",
      " 15 21 21 23 23 26 30 34 29 15 23 14 15 21 14 15 21 16 34 15 14 15 16 21\n",
      " 31 15 29 13 16 34 16 14 14 35 14 35 21 13 13 15 16 17 16 35 15 26 21 30\n",
      " 17 14 15 13 15 17 14 15]\n",
      "pred:  [16 35 27 16 21 21 15 21 16 16 15 14 15 16 21 21 16 17 30 16 16 21 16 15\n",
      " 16 15 13 14 21 16 15 35 16 15 21 13 21 15 21 14 15 14 36 21 34 30 14 15\n",
      " 22 21 23 15 21 30 17 15 35 17 35 36 14 16 16 16 15 31 14 16 14 21 14 16\n",
      " 16 30 26 14 21 15 13 14 26 16 14 15 29 15 21 15 16 16 14 23 15 21 21 16\n",
      " 16 30 15 16 14 15 23 16 15 15 17 35 17 15 29 16 14 15 30 15 21 15 35 15\n",
      " 21 15 21 14 34 15 16 16]\n",
      "Epoch 4: Iteration 65: with minibatch training loss = 0.0829 and accuracy of 0.12\n",
      "pred:  [15 21 14 15 21 35 21 14 15 21 15 17 14 30 16 15 14 30 16 14 16 16 14 15\n",
      " 30 13 15 21 14 21 21 21 16 17 35 16 16 21 23 14 14 15 14 14 30 30 30 17\n",
      " 14 15 16 15 15 15 17 15 15 15 35 21 14 35 15 15 35 36 17 21 14 21 15 14\n",
      " 22 15 13 26 35 35 13 15 26 14 16 35 15 15 31 14 16 34 17 15 30 21 35 17\n",
      " 14 35 36 15 16 15 29 17 23 34 16 21 14 21 23 14 13 15 35 30 15 16 15 16\n",
      " 29 14 30 21 14 14 17 16]\n",
      "pred:  [21 36 14 15 15 36 14 21 21 16 26 21 15 14 14 35 13 11 22 35 30 14 17 16\n",
      " 34 14 21 17 14 21 17 17 14 21 16 15 15 15 21 26 29 16 14 29 21 17 14 15\n",
      " 21 29 14 15 35 26 21 21 14 15 14 16 15 16 15 17 16 21 16 16 15 15 17 14\n",
      " 34 31 15 31 21 14 21 15 17 15 15 29 29 35 29 15 15 23 15 14 15 13 14 16\n",
      " 21 26 15 14 14 16 16 15 14 21 21 14 21 13 14 15 15 14 16 15 21 15 16 21\n",
      " 14 16 14 21 35 14 16 15]\n",
      "pred:  [15 30 26 14 35 29 34 14 21 26 14 14 26 17 15 21 22 14 16 15 17 15 16 15\n",
      " 15 16 15 34 16 14 16 14 16 14 15 15 14 35 15 15 21 23 21 14 23 16 15 16\n",
      " 36 17 14 35 14 14 14 13 36 16 16 23 35 14 16 14 16 16 26 13 23 16 29 14\n",
      " 14 16 14 17 35 21 30 21 15 15 36 15 14 15 14 21 17 21 15 15 15 16 14 14\n",
      " 35 22 16 21 14 21 14 36 21 15 21 21 14 14 29 20 14 21 34 14 14 16 13 21\n",
      " 30 14 35 16 14 14 14 14]\n",
      "pred:  [14 16 14 29 14 15 15 17 17 21 26 30 15 14 21 16 35 21 26 29 21 36 17 34\n",
      " 14 21 35 21 21 14 26 23 14 16 13 21 16 15 35 17 15 17 12 17 30 16 16 16\n",
      " 14 17 21 16 14 15 23 15 14 14 21 14 16 16 16 21 14 14 23 14 14 15 16 26\n",
      " 15 21 21 23 15 16 14 21 16 17 15 17 21 16 21 21 14 15 15 26 14 16 30 23\n",
      " 17 17 16 15 15 23 15 21 21 15 14 15 14 14 26 16 16 14 15 14 16 13 17 16\n",
      " 14 17 16 14 14 35 21 14]\n",
      "pred:  [16 14 21 15 21 17 15 15 14 15 30 17 15 15 14 15 30 15 14 16 15 21 21 14\n",
      " 17 13 16 35 21 26 21 15 14 17 21 15 14 22 15 14 15 14 26 26 14 23 26 16\n",
      " 14 26 17 17 21 21 15 35 14 16 21 15 14 13 35 21 15 21 26 15 29 15 17 14\n",
      " 15 35 16 21 13 29 35 16 14 21 14 14 21 35 13 14 21 21 17 34 14 14 14 22\n",
      " 21 16 14 14 16 15 14 17 35 16 14 15 14 36 14 21 30 15 15 16 15 21 26 17\n",
      " 14 16 15 34 22 15 14 16]\n",
      "Epoch 4: Iteration 70: with minibatch training loss = 0.078 and accuracy of 0.14\n",
      "pred:  [15 29 17 16 16 26 16 15 36 14 13 17 22 34 15 14 14 15 21 14 17 21 14 21\n",
      " 14 22 14 16 14 14 14 21 22 14 21 14 17 16 16 17 21 16 14 23 17 23 13 21\n",
      " 14 15 21 30 23 35 14 35 15 29 15 21 16 14 26 17 30 35 14 14 16 16 14 29\n",
      " 14 13 21 14 35 15 26 29 17 34 36 17 21 15 14 14 14 17 14 26 17 17 21 15\n",
      " 13 14 29 14 17 15 23 14 14 17 16 29 14 36 13 16 21 16 17 36 17 26 15 15\n",
      " 15 14 26 16 16 21 21 14]\n",
      "pred:  [17 22 29 13 17 21 21 15 16 21 26 21 21 29 15 14 16 16 15 15 21 13 21 34\n",
      " 14 30 16 17 16 29 21 26 17 14 29 21 17 15 14 29 17 16 16 29 29 29 14 16\n",
      " 21 17 29 17 17 22 26 14 23 14 17 15 13 17 17 17 16 16 13 16 23 17 21 29\n",
      " 30 23 15 14 35 16 29 21 13 23 23 16 16 17 14 30 17 14 23 21 15 15 15 15\n",
      " 15 29 16 21 34 14 21 21 21 14 15 17 31 15 17 17 16 17 35 21 21 26 16 15\n",
      " 16 14 17 15 14 16 29 14]\n",
      "pred:  [21 17 21 15 13 36 22 21 17 16 30 17 14 26 26 16 14 16 22 14 21 16 16 14\n",
      " 30 17 15 29 14 30 22 17 21 23 13 14 17 34 15 16 26 34 17 29 14 14 23 35\n",
      " 17 17 17 21 14 17 17 26 30 15 34 15 15 17 14 21 15 16 16 15 14 21 16 26\n",
      " 15 29 17 16 14 15 14 15 16 17 29 36 30 15 17 16 21 16 17 14 26 29 12 16\n",
      " 21 35 17 14 13 15 16 21 17 14 15 22 21 26 14 14 14 21 15 21 16 21 15 22\n",
      " 21 17 16 29 17 34 29 26]\n",
      "pred:  [23 29 13 14 31 14 21 17 21 21 29 26 21 14 22 17 17 29 15 14 14 21 15 16\n",
      " 16 15 16 17 14 29 15 16 13 12 15 17 13 15 29 15 23 15 17 26 14 15 21 29\n",
      " 17 14 34 21 21 16 36 16 16 16 21 35 30 13 14 13 16 30 17 15 21 15 21 21\n",
      " 17 23 15 23 17 17 16 16 26 29 16 34 15 15 13 14 26 17 35 17 15 21 16 21\n",
      " 15 15 22 15 17 15 21 15 14 21 15 17 16 35 15 29 15 13 17 15 30 34 16 14\n",
      " 15 17 16 17 30 26 26 17]\n",
      "pred:  [16 15 29 21 34 31 29 15 17 34 21 17 14 15 26 16 17 17 21 13 13 17 13 16\n",
      " 30 14 17 21 21 17 16 14 14 31 16 14 35 21 13 13 16 17 26 15 16 16 15 29\n",
      " 21 16 16 21 17 15 14 30 16 16 17 16 17 29 15 22 22 35 22 29 16 31 15 16\n",
      " 14 21 14 14 17 16 21 13 14 17 17 29 14 15 21 29 36 14 17 29 15 29 30 15\n",
      " 16 16 16 26 16 16 30 14 23 34 22 29 15 23 14 16 16 14 22 16 14 22 17 14\n",
      " 22 17 29 21 35 21 17 15]\n",
      "Epoch 4: Iteration 75: with minibatch training loss = 0.0792 and accuracy of 0.17\n",
      "pred:  [16 29 29 13 16 16 14 15 16 34 14 14 15 17 14 17 13 27 14 13 17 13 17 14\n",
      " 15 17 30 15 17 14 14 15 15 22 21 16 15 29 21 21 29 23 16 14 17 18 22 17\n",
      " 29 21 17 15 16 15 15 15 16 34 17 12 22 29 15 16 35 34 35 16 23 21 29 14\n",
      " 23 23 16 15 22 15 22 29 34 34 16 31 14 14 35 30 23 29 30 34 16 14 34 30\n",
      " 34 14 35 23 30 16 14 13 35 17 16 16 21 26 15 35 36 21 14 22 30 21 26 21\n",
      " 17 12 22 15 35 16 26 29]\n",
      "pred:  [17 35 22 12 34 17 16 16 29 15 29 16 15 14 34 14 21 15 30 34 22 30 12 22\n",
      " 29 15 26 15 31 21 16 16 16 14 15 30 26 16 22 14 35 14 34 13 13 15 17 15\n",
      " 13 15 35 29 15 29 16 29 16 30 21 14 29 22 15 14 12 16 12 17 35 34 13 30\n",
      " 16 29 34 15 21 15 16 15 15 14 35 35 29 29 16 29 31 17 14 29 15 22 17 23\n",
      " 35 15 29 34 26 17 17 26 29 22 14 15 22 16 34 34 22 17 26 34 13 14 35 31\n",
      " 15 15 22 22 16 14 14 30]\n",
      "pred:  [13 14 15 14 30 15 34 14 30 22 15 15 15 16 16 17 21 15 14 21 14 30 35 22\n",
      " 15 15 15 16 15 35 13 16 35 15 16 16 15 30 17 17 15 16 13 16 23 16 30 15\n",
      " 30 15 15 15 34 17 14 21 13 13 30 14 16 22 35 14 16 22 22 34 16 16 35 29\n",
      " 14 35 30 35 15 15 35 16 14 15 35 35 35 21 14 15 16 14 35 35 36 16 31 34\n",
      " 22 29 14 15 29 16 15 15 34 14 29 16 23 30 21 22 15 29 22 14 17 15 29 13\n",
      " 29 23 15 15 14 17 29 14]\n",
      "pred:  [16 31 22 21 16 14 16 16 15 21 16 13 29 16 13 15 14 34 15 15 15 16 15 16\n",
      " 35 15 16 31 17 14 15 16 13 16 16 15 31 15 30 16 22 29 21 20 15 14 30 21\n",
      " 34 17 23 15 13 13 35 15 21 15 14 14 26 14 31 35 14 23 16 17 29 16 29 13\n",
      " 30 17 26 14 16 15 35 35]\n",
      "Epoch 5 Overall loss = 0.0812 and accuracy of 0.144\n",
      "pred:  [21 21 27 16 16 35 15 14 15 16 15 16 15 21 15 36 30 26 23 26 23 14 15 16\n",
      " 13 15 15 15 15 15 21 15 15 29 13 21 15 13 16 14 21 14 29 21 13 30 16 29\n",
      " 12 23 16 29 35 21 30 15 35 14 14 16 14 22 17 13 16 14 16 13 35 15 14 15\n",
      " 15 15 14 15 15 21 26 35 16 21 16 15 15 22 22 17 16 17 34 13 34 12 16 21\n",
      " 15 14 16 23 16 13 30 14 12 15 15 16 13 13 14 35 29 15 21 15 13 26 21 14\n",
      " 35 29 22 34 12 16 21 35]\n",
      "Epoch 5: Iteration 80: with minibatch training loss = 0.0739 and accuracy of 0.23\n",
      "pred:  [16 14 14 14 16 14 16 22 15 14 15 14 13 15 16 12 22 13 14 15 35 26 14 15\n",
      " 16 23 14 15 21 15 29 16 15 17 13 16 16 16 26 15 21 16 26 15 13 31 34 16\n",
      " 23 14 14 15 12 31 21 15 15 14 22 15 14 15 35 14 16 30 15 21 14 30 16 16\n",
      " 21 14 14 20 21 15 13 15 30 17 15 35 15 17 12 16 15 16 14 26 16 14 23 13\n",
      " 22 22 15 14 16 16 35 16 16 21 14 15 13 14 15 35 21 34 30 15 16 14 15 15\n",
      " 15 15 21 16 14 16 15 15]\n",
      "pred:  [15 15 14 16 21 16 16 14 22 21 15 15 21 26 16 16 15 26 15 17 15 14 14 17\n",
      " 30 14 15 14 21 14 14 14 35 15 35 15 15 30 23 16 13 15 14 14 30 36 30 15\n",
      " 29 14 22 16 15 22 14 16 14 35 15 15 15 29 14 15 15 16 14 21 14 21 15 13\n",
      " 22 14 14 30 16 21 14 35 31 21 14 16 35 16 14 16 16 15 15 16 30 21 14 14\n",
      " 15 16 23 35 15 15 14 16 21 15 35 30 13 22 14 35 14 35 14 16 16 15 16 35\n",
      " 16 16 36 22 14 21 34 35]\n",
      "pred:  [21 30 14 14 27 21 34 36 21 14 26 15 15 13 14 15 14 16 14 14 15 16 21 22\n",
      " 14 14 23 21 21 21 14 15 21 15 15 14 16 15 14 15 15 17 12 23 21 17 14 26\n",
      " 14 23 22 36 15 30 16 21 14 15 14 14 13 30 21 14 22 21 16 21 14 16 16 36\n",
      " 14 26 16 30 13 21 30 16 15 15 15 15 16 29 23 14 15 16 21 27 14 21 14 15\n",
      " 21 30 14 13 14 16 14 21 21 12 21 14 13 14 14 21 21 14 16 14 21 21 15 30\n",
      " 35 22 14 12 21 13 16 16]\n",
      "pred:  [16 36 26 14 21 23 15 29 30 26 17 12 21 14 15 26 14 14 31 27 23 15 21 16\n",
      " 14 35 16 14 16 14 21 14 14 16 14 15 12 16 23 14 35 21 14 14 29 15 35 16\n",
      " 16 14 15 21 14 15 14 13 22 21 15 23 34 14 21 13 23 21 30 13 15 17 15 21\n",
      " 16 30 14 14 14 14 21 11 14 14 36 14 26 15 15 14 14 35 15 16 15 15 14 17\n",
      " 21 30 21 21 14 17 14 30 14 15 14 21 21 14 14 21 17 15 15 14 15 15 13 21\n",
      " 21 15 15 15 35 21 15 14]\n",
      "pred:  [14 15 16 22 14 16 14 21 13 21 26 21 16 14 21 21 17 15 30 21 21 36 15 15\n",
      " 34 21 16 21 21 15 26 22 17 16 14 21 31 14 15 13 17 17 13 15 36 22 26 15\n",
      " 14 21 30 16 34 22 14 17 16 14 15 21 16 15 21 34 22 14 21 21 21 12 16 21\n",
      " 17 16 13 14 14 14 14 16 21 17 35 21 29 15 21 13 14 15 16 14 14 21 26 21\n",
      " 17 15 21 17 35 17 23 21 21 21 15 12 14 23 21 14 14 21 17 14 16 21 17 16\n",
      " 21 16 26 12 14 15 34 14]\n",
      "Epoch 5: Iteration 85: with minibatch training loss = 0.0812 and accuracy of 0.14\n",
      "pred:  [23 14 21 17 21 15 15 13 21 14 36 17 22 15 21 17 21 17 15 15 14 12 14 21\n",
      " 17 17 16 21 21 31 35 15 21 17 17 16 14 22 13 21 15 14 30 26 17 21 22 21\n",
      " 14 26 15 17 13 14 17 16 15 16 21 15 15 15 17 21 14 22 23 21 23 17 21 14\n",
      " 17 16 21 22 14 14 35 21 15 22 15 23 21 17 34 14 16 16 16 17 16 14 17 21\n",
      " 16 21 14 11 16 14 13 17 13 14 23 15 14 14 27 35 21 14 15 17 17 30 26 16\n",
      " 15 21 17 15 23 23 13 20]\n",
      "pred:  [14 35 17 17 21 29 22 15 21 14 17 14 15 16 17 17 14 14 21 34 14 21 15 17\n",
      " 34 35 17 22 34 15 17 21 15 34 21 17 17 23 20 16 22 26 14 15 21 23 13 21\n",
      " 17 17 21 14 23 14 14 14 13 22 21 34 22 14 30 15 26 21 13 35 17 14 23 23\n",
      " 17 14 15 21 16 17 36 22 17 15 36 16 22 17 14 13 12 14 17 26 16 27 17 17\n",
      " 34 17 29 17 21 17 23 13 34 16 17 14 34 30 35 21 17 17 34 30 17 30 14 15\n",
      " 21 15 30 15 17 15 16 14]\n",
      "pred:  [17 15 17 34 17 16 26 15 17 21 31 23 15 16 11 14 21 27 16 16 26 17 30 13\n",
      " 17 30 15 17 16 17 14 30 21 14 14 13 17 34 14 17 17 16 17 22 15 16 34 14\n",
      " 21 16 35 17 17 23 21 17 15 13 17 17 13 17 12 13 15 16 34 22 22 21 21 35\n",
      " 26 23 15 15 13 14 21 15 12 15 26 21 22 17 14 21 12 34 15 21 15 34 21 17\n",
      " 23 16 17 21 17 22 15 17 17 35 17 15 15 16 16 17 23 16 23 11 21 21 16 16\n",
      " 17 14 14 15 21 29 21 29]\n",
      "pred:  [12 21 12 17 14 26 35 17 14 14 30 17 13 29 26 22 13 23 31 15 17 22 29 21\n",
      " 36 17 23 16 17 36 15 16 21 22 14 21 17 35 17 22 22 15 15 17 17 34 16 31\n",
      " 15 17 15 29 14 17 17 26 30 17 12 13 16 21 34 21 17 21 17 17 22 21 13 30\n",
      " 15 21 17 23 14 23 31 16 15 16 35 26 26 22 34 15 29 35 17 14 36 29 13 29\n",
      " 21 14 16 14 14 22 29 21 17 15 17 15 15 22 34 15 16 26 13 29 15 36 15 23\n",
      " 12 17 16 17 17 29 15 26]\n",
      "pred:  [15 14 13 14 14 13 26 17 29 16 23 36 21 16 22 17 16 15 16 15 14 21 23 26\n",
      " 35 17 17 16 34 31 15 13 15 12 16 17 15 16 35 17 35 15 17 26 14 15 21 17\n",
      " 13 34 14 29 29 14 30 15 15 15 13 29 26 21 14 16 17 30 34 15 26 17 16 21\n",
      " 17 21 14 21 21 29 15 29 30 15 22 29 15 29 34 21 26 14 16 35 17 34 17 17\n",
      " 14 17 29 14 21 17 15 29 13 17 34 17 15 34 15 29 29 16 17 14 26 15 21 35\n",
      " 16 14 29 16 26 20 30 15]\n",
      "Epoch 5: Iteration 90: with minibatch training loss = 0.0778 and accuracy of 0.19\n",
      "pred:  [23 13 22 17 17 26 15 16 23 34 23 16 29 17 26 17 29 16 35 13 12 17 13 26\n",
      " 36 14 17 17 13 17 16 34 13 26 15 14 35 31 29 16 29 15 26 34 29 29 16 17\n",
      " 21 29 35 12 17 29 14 30 15 16 34 15 35 23 17 22 15 17 21 31 23 26 34 21\n",
      " 14 21 21 14 17 16 26 16 14 29 17 17 17 34 13 16 30 14 17 14 17 22 16 15\n",
      " 15 23 21 26 17 17 26 13 16 17 16 29 34 16 17 16 16 17 21 16 14 23 17 21\n",
      " 29 14 29 13 16 12 17 15]\n",
      "pred:  [16 14 29 34 15 14 34 16 15 15 15 15 23 13 15 17 35 35 15 12 17 13 29 29\n",
      " 15 14 31 23 29 13 12 29 13 16 13 29 17 14 30 30 17 21 22 13 16 22 29 15\n",
      " 34 13 27 16 15 15 15 29 17 29 17 13 29 15 17 15 15 21 34 22 21 14 21 14\n",
      " 16 26 21 16 15 34 29 15 15 17 15 29 21 22 23 12 23 35 26 34 16 14 13 31\n",
      " 17 13 16 22 30 16 14 13 34 13 29 29 30 21 15 29 26 13 13 16 26 13 26 26\n",
      " 15 13 15 14 16 14 26 29]\n",
      "pred:  [13 35 35 13 13 34 16 16 34 17 22 16 14 14 14 13 12 35 30 35 16 30 13 22\n",
      " 26 17 21 17 22 13 16 15 15 14 22 30 30 35 16 15 29 14 14 14 17 23 17 15\n",
      " 13 16 35 35 17 16 31 29 29 12 21 15 16 21 35 14 13 17 34 21 34 34 14 31\n",
      " 29 15 15 14 22 17 14 15 15 34 16 14 17 14 16 31 21 35 15 13 16 16 29 21\n",
      " 16 34 15 34 30 13 16 25 15 29 35 16 16 35 16 13 26 34 26 13 13 14 15 22\n",
      " 35 15 16 35 15 13 15 26]\n",
      "pred:  [13 22 35 14 30 29 35 13 30 22 29 21 15 29 14 16 21 16 13 14 21 20 35 22\n",
      " 35 15 16 22 34 35 35 16 23 29 21 36 16 26 29 15 29 29 29 16 16 16 35 16\n",
      " 35 15 17 16 34 17 13 17 13 13 26 22 15 22 22 14 16 29 35 13 16 21 35 16\n",
      " 34 22 26 35 15 15 16 14 15 21 14 15 16 13 14 15 20 35 34 16 30 22 30 14\n",
      " 29 29 14 35 15 20 15 17 13 29 26 15 15 30 26 22 16 34 29 13 15 13 26 13\n",
      " 29 15 29 14 35 16 34 29]\n",
      "pred:  [16 14 15 13 22 30 35 14 15 15 16 11 31 23 14 15 14 14 29 23 17 29 22 14\n",
      " 16 16 21 15 15 15 14 14 13 11 17 22 26 15 36 15 17 29 21 16 35 30 30 30\n",
      " 16 29 29 16 13 34 14 16 16 23 15 12 30 13 34 35 14 15 16 14 15 29 35 14\n",
      " 14 15 30 15 16 16 35 17]\n",
      "Epoch 5: Iteration 95: with minibatch training loss = 0.0761 and accuracy of 0.2\n",
      "Epoch 6 Overall loss = 0.0776 and accuracy of 0.186\n",
      "pred:  [16 13 15 17 14 15 17 13 15 15 15 29 21 35 15 36 36 26 16 26 21 12 15 16\n",
      " 35 15 15 22 13 16 16 16 16 14 15 14 16 13 29 15 21 14 35 17 13 29 14 29\n",
      " 12 16 35 29 13 21 26 14 17 14 14 15 14 35 35 34 13 13 29 15 35 15 35 15\n",
      " 16 15 13 16 15 21 36 16 15 30 16 15 17 16 16 29 16 17 35 14 14 14 35 21\n",
      " 14 35 14 15 15 15 22 14 12 16 15 15 14 13 14 21 29 16 15 35 16 30 14 30\n",
      " 13 35 35 35 15 15 16 16]\n",
      "pred:  [14 16 15 14 16 35 14 14 35 14 15 35 29 22 16 14 14 15 21 16 15 14 14 17\n",
      " 17 16 17 15 21 15 16 35 16 29 13 14 13 14 30 14 14 21 31 16 17 30 34 14\n",
      " 16 20 22 16 13 35 15 15 14 14 31 26 14 16 29 35 16 15 15 23 15 30 21 14\n",
      " 35 36 14 14 13 16 14 15 36 21 34 16 15 23 15 16 22 15 14 30 15 21 29 15\n",
      " 14 31 15 14 14 16 31 16 17 26 15 14 35 34 35 16 35 14 30 16 16 14 14 17\n",
      " 35 35 21 15 15 35 16 35]\n",
      "pred:  [15 15 14 35 14 35 14 14 22 21 17 17 13 30 15 14 14 14 15 35 15 21 14 15\n",
      " 30 14 16 15 12 14 14 14 16 35 14 15 15 30 22 17 15 15 15 15 36 14 26 23\n",
      " 15 14 14 16 14 14 34 16 14 35 15 14 14 34 14 15 16 14 14 21 15 21 15 14\n",
      " 16 14 12 31 15 21 14 16 14 13 21 29 22 15 14 15 16 14 16 35 30 21 16 14\n",
      " 14 16 22 21 15 16 34 14 21 14 16 36 14 16 16 16 14 15 34 15 35 15 16 15\n",
      " 27 35 36 14 14 13 14 26]\n",
      "pred:  [21 30 14 14 15 15 15 30 21 34 30 15 15 14 14 17 14 17 22 14 16 15 35 22\n",
      " 34 29 21 14 35 14 15 35 21 26 15 15 15 13 13 35 15 21 13 21 21 15 14 14\n",
      " 14 22 21 20 15 21 21 13 14 15 14 14 15 29 21 16 35 13 15 16 14 15 21 26\n",
      " 14 14 15 30 14 21 26 21 29 16 15 21 35 35 22 14 34 17 35 29 14 21 14 15\n",
      " 14 30 14 14 14 15 14 15 21 13 16 14 21 14 14 21 21 14 16 15 21 17 15 21\n",
      " 16 22 13 12 35 15 21 23]\n",
      "pred:  [21 26 26 14 35 29 14 15 26 36 14 21 26 14 15 30 22 14 22 15 16 15 23 17\n",
      " 16 21 15 15 22 13 21 14 21 16 14 17 21 17 16 14 16 13 12 14 16 17 15 16\n",
      " 26 14 15 21 14 15 15 14 15 23 15 16 15 14 21 35 22 16 26 14 17 14 15 14\n",
      " 14 26 14 21 14 12 36 17 34 34 36 14 21 14 16 17 17 22 15 29 21 14 14 14\n",
      " 21 14 16 14 14 14 14 26 13 29 12 12 21 17 35 21 17 15 34 14 14 21 14 16\n",
      " 21 16 14 15 35 17 17 35]\n",
      "Epoch 6: Iteration 100: with minibatch training loss = 0.0738 and accuracy of 0.2\n",
      "pred:  [15 16 17 22 13 29 34 16 16 21 26 21 34 14 21 21 16 21 36 15 21 26 17 21\n",
      " 15 16 14 35 21 14 26 22 17 16 15 36 16 14 14 35 17 17 12 16 21 22 30 23\n",
      " 14 14 14 35 34 15 14 15 16 14 26 21 16 26 21 17 15 14 35 14 21 14 35 30\n",
      " 27 22 14 14 14 15 35 17 14 12 35 21 14 15 21 14 14 15 23 14 14 15 20 26\n",
      " 15 15 21 17 23 21 14 13 21 14 15 14 17 21 26 14 14 35 17 14 15 21 17 22\n",
      " 11 17 26 17 14 15 13 34]\n",
      "pred:  [15 26 14 17 16 14 16 34 35 14 36 17 22 15 15 17 21 29 17 21 17 21 14 21\n",
      " 15 15 21 35 13 25 35 15 21 17 17 29 15 14 15 17 15 14 26 30 35 21 22 21\n",
      " 14 12 14 21 21 21 17 35 15 22 14 15 14 14 35 21 14 22 26 16 26 17 23 14\n",
      " 17 21 15 16 16 14 14 35 17 21 14 29 21 17 34 15 17 21 17 16 14 14 29 15\n",
      " 15 23 17 12 15 17 14 17 14 35 16 15 14 26 17 17 36 34 22 17 17 30 21 17\n",
      " 21 16 23 17 26 21 14 22]\n",
      "pred:  [17 14 17 15 23 16 21 14 21 14 13 17 16 14 17 17 14 14 21 17 14 21 15 11\n",
      " 34 21 17 22 34 34 16 21 22 16 13 17 17 23 35 29 17 26 14 17 21 16 14 21\n",
      " 21 15 22 29 17 23 14 29 13 15 17 34 21 15 26 17 26 23 17 29 17 14 17 35\n",
      " 21 34 22 21 35 15 30 21 17 15 26 15 16 17 36 15 34 14 12 36 29 17 17 17\n",
      " 34 14 14 12 21 15 22 13 16 17 17 17 17 21 34 35 16 17 34 26 17 30 34 15\n",
      " 22 15 30 15 15 17 14 17]\n",
      "pred:  [23 14 35 14 17 16 21 15 17 14 14 21 35 17 13 14 21 15 17 15 21 16 26 15\n",
      " 17 26 14 21 26 17 14 26 21 14 15 21 17 17 14 14 29 22 22 23 22 23 13 17\n",
      " 21 16 17 21 17 15 26 15 23 12 17 21 13 17 17 17 29 16 14 22 15 17 21 21\n",
      " 26 29 15 15 16 13 23 15 17 21 30 21 14 21 17 30 12 14 17 21 17 15 21 16\n",
      " 16 17 17 21 17 21 15 12 21 17 17 16 14 22 16 21 21 17 16 34 21 36 16 17\n",
      " 17 14 14 15 29 29 21 13]\n",
      "pred:  [34 16 12 16 13 26 21 17 17 17 30 17 12 26 26 21 13 16 29 14 16 22 29 17\n",
      " 26 34 17 15 15 20 23 27 21 16 34 35 13 34 15 22 22 34 17 17 14 34 16 29\n",
      " 17 17 17 21 12 17 17 30 21 17 21 17 15 15 34 21 17 23 17 35 15 21 15 21\n",
      " 17 17 17 17 14 21 14 15 17 13 17 35 30 22 34 16 35 15 23 14 26 16 12 15\n",
      " 21 17 17 13 13 22 14 29 17 14 14 15 34 21 34 17 14 31 21 22 17 36 17 22\n",
      " 34 17 16 17 17 29 17 26]\n",
      "Epoch 6: Iteration 105: with minibatch training loss = 0.0741 and accuracy of 0.22\n",
      "pred:  [17 15 34 15 16 13 30 17 21 29 29 36 21 31 14 29 34 17 27 17 13 21 21 29\n",
      " 29 27 17 17 29 22 16 17 13 34 16 15 29 16 29 16 29 29 16 21 14 14 26 16\n",
      " 17 34 13 34 35 13 30 17 16 29 21 26 21 17 14 15 21 30 17 15 14 16 17 17\n",
      " 17 15 14 22 13 17 17 29 26 14 15 34 17 21 13 34 21 17 16 29 29 34 15 17\n",
      " 16 29 29 15 15 13 15 16 13 14 17 16 22 34 15 20 29 34 17 16 26 15 15 29\n",
      " 16 29 16 34 29 35 26 27]\n",
      "pred:  [22 12 14 17 13 31 14 34 35 34 17 29 14 17 30 27 17 27 16 13 12 17 12 30\n",
      " 31 15 17 17 34 17 31 12 13 30 34 14 35 14 35 14 23 34 30 15 15 16 15 29\n",
      " 13 17 17 21 29 29 14 26 15 22 17 22 34 17 17 29 16 17 23 21 23 18 29 17\n",
      " 17 21 21 15 29 35 26 29 14 23 13 17 13 29 13 17 30 14 15 34 17 23 35 34\n",
      " 23 23 29 30 16 21 30 34 29 13 22 29 34 29 16 15 35 16 29 21 13 23 15 12\n",
      " 16 17 21 13 15 13 17 16]\n",
      "pred:  [16 35 35 16 15 21 34 16 15 16 21 13 15 14 13 17 34 29 35 21 34 12 15 21\n",
      " 15 13 30 16 17 12 34 16 34 15 12 16 23 34 31 26 16 15 22 13 35 15 22 15\n",
      " 29 13 16 16 15 13 16 28 21 34 17 12 35 29 21 29 15 21 15 15 17 35 17 14\n",
      " 23 35 17 22 16 15 21 15 29 14 15 22 12 29 35 13 22 35 30 13 15 14 12 30\n",
      " 12 34 17 14 26 23 14 12 34 17 17 15 26 21 16 35 26 17 13 16 26 21 26 21\n",
      " 15 12 17 17 17 16 30 16]\n",
      "pred:  [35 30 22 11 13 34 15 15 15 15 23 16 15 14 34 14 12 23 26 13 22 30 23 22\n",
      " 22 17 21 35 15 13 23 17 23 14 22 26 30 16 31 15 16 14 13 14 29 29 17 14\n",
      " 34 14 21 35 17 16 29 16 16 21 21 28 14 29 35 14 12 21 12 21 13 34 16 32\n",
      " 35 22 23 16 17 15 14 34 34 12 16 15 17 14 15 26 15 15 13 13 23 22 29 15\n",
      " 17 15 16 34 30 14 15 30 29 22 15 16 16 35 13 12 29 29 30 15 13 14 27 30\n",
      " 17 23 29 35 21 13 14 30]\n",
      "pred:  [13 23 34 14 30 35 34 14 30 22 21 15 15 16 14 13 21 15 13 15 34 23 16 29\n",
      " 17 15 15 16 34 17 35 16 16 13 15 30 16 30 16 17 27 35 14 16 15 23 35 35\n",
      " 29 23 17 14 13 23 13 17 13 12 14 15 15 35 16 14 16 16 35 13 16 16 15 15\n",
      " 13 15 20 14 17 16 16 35 14 35 34 14 31 13 14 16 30 31 15 35 30 35 26 13\n",
      " 35 21 14 35 16 14 15 17 13 29 23 21 16 30 30 16 35 13 22 21 16 15 29 13\n",
      " 35 17 16 14 14 16 16 35]\n",
      "Epoch 6: Iteration 110: with minibatch training loss = 0.0701 and accuracy of 0.3\n",
      "pred:  [15 14 23 13 15 30 14 13 16 21 23 13 14 35 16 16 14 14 16 15 16 35 20 14\n",
      " 29 23 21 22 21 29 13 15 12 23 16 16 30 15 30 15 17 14 21 35 35 30 26 34\n",
      " 14 29 35 16 13 21 13 35 21 15 14 13 26 13 34 14 15 16 23 13 14 15 16 35\n",
      " 29 15 30 14 16 22 27 17]\n",
      "Epoch 7 Overall loss = 0.0727 and accuracy of 0.225\n",
      "pred:  [16 14 17 21 15 13 16 15 16 14 15 21 15 35 16 30 35 30 29 30 23 14 35 29\n",
      " 35 15 15 22 12 16 15 22 15 15 13 14 15 13 16 14 21 14 23 17 35 14 16 34\n",
      " 21 29 29 22 14 12 30 34 15 15 14 16 35 22 16 35 15 14 35 14 16 14 14 15\n",
      " 15 23 13 14 15 21 30 14 16 35 16 15 17 15 15 15 22 17 15 14 14 34 31 21\n",
      " 31 14 15 15 14 16 14 14 21 29 22 15 14 13 14 35 21 23 14 15 21 26 15 26\n",
      " 14 35 16 35 15 17 16 29]\n",
      "pred:  [23 16 14 14 35 21 34 29 14 14 15 34 15 16 21 13 21 15 30 15 15 14 14 21\n",
      " 17 21 14 15 35 16 15 35 15 35 11 16 14 15 26 15 21 21 31 35 14 36 34 14\n",
      " 16 22 29 22 13 31 16 15 15 13 21 22 14 23 16 29 16 36 15 15 14 36 21 15\n",
      " 16 21 14 22 12 16 34 15 30 21 15 27 14 16 12 15 16 15 14 21 16 21 26 21\n",
      " 14 36 15 13 14 15 20 22 16 35 16 15 14 35 15 16 35 16 30 15 15 14 14 21\n",
      " 21 14 15 14 34 14 16 14]\n",
      "pred:  [14 15 14 26 34 16 15 16 16 21 21 21 12 30 15 15 15 36 15 15 16 35 14 15\n",
      " 36 14 17 15 14 14 14 14 16 15 22 16 16 30 16 21 16 15 14 34 29 36 30 15\n",
      " 15 15 14 21 14 14 34 15 15 15 15 15 14 14 16 14 23 31 14 21 15 21 14 13\n",
      " 15 14 12 36 15 21 14 16 36 14 21 21 26 22 35 15 16 35 15 21 36 21 15 35\n",
      " 14 21 15 16 15 15 14 15 21 35 17 36 35 22 16 15 14 15 14 21 16 16 35 35\n",
      " 35 16 30 22 35 12 35 35]\n",
      "pred:  [21 30 14 15 15 20 14 30 21 16 30 15 15 15 14 21 14 17 15 14 16 16 35 14\n",
      " 35 17 16 14 35 15 15 16 23 26 15 15 15 15 14 26 14 15 12 21 21 21 14 22\n",
      " 14 23 20 36 15 31 21 13 15 15 13 14 15 26 15 15 16 13 17 35 13 15 17 35\n",
      " 14 36 21 26 14 21 30 23 16 15 15 35 22 35 22 14 34 21 35 16 16 21 15 27\n",
      " 13 21 14 14 14 17 14 15 21 14 14 14 13 14 14 21 20 14 15 14 21 17 15 36\n",
      " 16 14 35 34 35 14 17 17]\n",
      "Epoch 7: Iteration 115: with minibatch training loss = 0.0692 and accuracy of 0.23\n",
      "pred:  [26 36 26 15 35 35 35 15 26 36 17 14 30 13 14 26 22 14 22 17 17 16 21 17\n",
      " 27 21 15 17 21 13 35 14 16 16 14 15 14 15 21 15 16 17 12 14 29 17 17 35\n",
      " 35 14 14 35 14 14 14 15 22 16 15 16 14 35 15 16 23 15 26 17 17 13 15 14\n",
      " 14 22 31 21 14 17 36 14 34 35 21 14 26 14 15 15 13 16 16 21 17 15 34 15\n",
      " 21 35 16 15 14 17 14 26 12 34 12 21 21 21 35 16 35 15 34 15 14 35 14 21\n",
      " 11 14 14 15 15 13 17 34]\n",
      "pred:  [22 22 15 21 21 21 29 17 13 12 30 21 15 17 13 35 21 17 30 15 21 36 16 21\n",
      " 15 17 14 35 26 15 36 22 15 16 15 21 35 15 14 15 17 17 11 15 30 22 20 21\n",
      " 14 15 29 35 34 21 14 17 16 15 23 21 35 16 35 21 36 14 35 13 22 16 21 26\n",
      " 17 21 14 14 14 15 15 21 15 23 26 21 22 14 21 11 14 17 21 23 14 16 14 35\n",
      " 17 16 16 15 35 21 21 23 35 23 17 14 13 17 30 17 14 27 16 14 21 20 21 22\n",
      " 34 17 35 13 14 35 13 34]\n",
      "pred:  [23 26 26 14 21 17 15 34 23 14 31 17 22 17 26 15 32 17 35 31 29 21 11 14\n",
      " 17 15 21 35 12 21 35 21 16 21 12 16 34 22 16 17 14 14 36 26 15 13 16 21\n",
      " 15 26 14 17 13 15 17 17 16 22 17 14 14 17 35 21 14 16 26 15 26 17 21 14\n",
      " 17 16 15 15 15 14 16 35 17 23 14 22 21 17 13 15 35 14 21 17 14 34 35 15\n",
      " 15 21 16 12 14 14 14 15 14 26 21 22 13 26 18 17 36 14 16 15 17 26 35 17\n",
      " 21 16 21 17 29 21 16 35]\n",
      "pred:  [15 34 14 15 14 36 16 31 31 14 34 17 17 21 17 21 14 29 17 17 16 21 15 12\n",
      " 17 35 17 22 34 34 34 21 22 17 17 17 17 22 21 17 16 35 35 17 17 17 16 21\n",
      " 17 17 16 35 21 35 14 14 17 22 17 13 22 17 30 17 30 21 17 16 21 14 23 29\n",
      " 23 13 15 21 26 27 21 26 17 17 20 14 26 17 26 34 12 14 17 26 34 15 17 17\n",
      " 34 17 26 12 21 15 22 13 15 17 17 14 34 25 34 26 17 17 34 36 17 26 34 16\n",
      " 22 15 21 16 17 17 14 15]\n",
      "pred:  [17 22 17 14 17 14 36 34 17 34 31 16 17 16 13 14 21 17 14 16 26 16 26 17\n",
      " 17 26 29 17 26 17 14 26 17 15 14 12 12 14 17 35 29 16 21 22 14 21 13 15\n",
      " 21 35 29 15 16 15 26 16 16 34 15 21 17 17 13 17 17 22 29 22 22 21 30 26\n",
      " 26 32 15 22 17 17 16 17 12 29 30 22 29 17 13 30 12 34 17 21 17 14 17 17\n",
      " 27 21 21 21 15 22 14 13 17 17 34 15 22 16 17 21 35 17 16 13 22 26 22 17\n",
      " 21 31 14 15 20 35 26 34]\n",
      "Epoch 7: Iteration 120: with minibatch training loss = 0.068 and accuracy of 0.27\n",
      "pred:  [13 21 13 29 35 36 36 17 14 17 21 17 12 26 26 22 12 16 22 17 17 29 35 12\n",
      " 30 34 15 21 16 32 22 35 21 21 34 29 23 34 15 16 26 15 14 17 14 34 16 16\n",
      " 15 17 17 21 13 35 17 21 20 15 12 27 16 17 34 21 17 21 17 17 21 35 34 26\n",
      " 16 17 15 16 13 21 31 23 17 17 29 35 26 22 13 17 21 17 17 17 26 21 12 17\n",
      " 21 13 17 14 13 14 16 29 17 15 35 15 34 20 17 17 35 29 11 22 17 30 15 29\n",
      " 34 17 17 17 27 29 14 26]\n",
      "pred:  [29 22 17 14 31 13 26 16 26 29 29 36 21 31 15 15 35 17 16 17 13 21 23 35\n",
      " 35 17 17 17 15 22 17 17 17 34 17 13 34 16 26 17 29 17 34 30 34 31 30 29\n",
      " 13 13 13 35 26 14 26 17 29 15 23 31 30 12 14 15 21 30 16 23 15 17 21 17\n",
      " 29 15 14 31 12 17 15 29 30 31 22 34 17 23 17 13 30 14 34 17 29 34 23 17\n",
      " 17 15 17 34 17 17 15 16 34 12 17 17 22 34 35 29 15 13 17 16 30 15 15 26\n",
      " 15 17 29 34 31 26 30 34]\n",
      "pred:  [16 12 14 17 13 14 34 34 29 34 16 13 15 17 30 16 29 17 18 17 11 17 12 26\n",
      " 30 16 17 14 34 17 31 34 14 26 15 15 29 14 16 17 29 15 26 35 22 26 17 34\n",
      " 12 17 29 21 34 29 14 26 15 22 21 16 29 16 27 29 21 17 22 20 16 26 34 23\n",
      " 12 21 20 14 15 29 30 13 14 17 27 17 12 15 12 17 26 15 14 34 17 29 29 17\n",
      " 34 23 16 26 23 23 36 27 23 13 16 27 34 16 15 15 29 35 18 16 13 15 17 12\n",
      " 29 15 29 12 16 13 13 17]\n",
      "pred:  [16 29 22 15 17 16 34 14 17 15 15 14 14 15 15 17 15 17 34 11 15 13 21 20\n",
      " 15 13 30 15 27 11 34 29 13 23 12 29 16 15 31 26 16 15 16 13 28 22 29 16\n",
      " 29 13 29 16 15 15 14 16 21 34 17 12 35 17 21 15 16 21 15 15 21 34 17 14\n",
      " 23 26 21 22 14 15 31 17 29 14 15 29 13 29 29 21 15 29 30 34 16 14 13 30\n",
      " 17 34 17 22 30 15 14 13 34 17 27 29 30 21 15 29 35 12 34 16 30 17 30 21\n",
      " 17 12 15 13 27 23 30 22]\n",
      "pred:  [14 35 29 13 17 13 16 15 15 15 29 35 35 14 34 13 13 23 31 17 29 30 34 22\n",
      " 22 29 21 35 23 13 15 23 15 31 15 25 31 29 23 15 29 31 13 34 34 16 23 15\n",
      " 34 15 21 35 15 15 29 22 27 21 21 15 14 22 13 31 12 17 14 23 34 34 13 30\n",
      " 35 29 17 14 17 14 31 35 35 13 35 35 17 34 23 30 15 15 14 34 23 29 29 23\n",
      " 17 15 14 34 30 13 35 30 35 29 17 17 22 34 15 34 36 34 36 14 13 31 29 31\n",
      " 16 21 29 35 23 13 14 31]\n",
      "Epoch 7: Iteration 125: with minibatch training loss = 0.0652 and accuracy of 0.27\n",
      "pred:  [13 16 35 14 30 34 34 16 30 16 23 23 16 17 16 12 20 15 14 14 34 16 26 35\n",
      " 35 17 15 15 35 17 29 16 23 15 23 35 15 26 15 15 15 35 29 15 15 23 35 15\n",
      " 26 21 17 22 35 15 13 27 13 12 16 15 15 29 16 15 22 22 35 12 16 15 15 15\n",
      " 34 15 30 14 15 15 15 15 15 35 13 14 16 12 14 15 20 14 34 15 30 20 30 14\n",
      " 22 17 14 14 29 22 15 17 13 16 29 21 16 30 31 16 29 35 16 14 15 14 29 13\n",
      " 26 15 21 14 36 16 29 35]\n",
      "pred:  [15 14 16 15 16 36 17 15 15 23 16 11 31 16 14 16 15 14 17 15 23 35 22 14\n",
      " 29 16 17 14 16 15 13 15 13 21 15 21 35 15 30 15 17 14 21 35 35 30 30 21\n",
      " 15 35 22 15 15 13 35 27 27 23 15 14 26 13 34 14 15 16 29 13 15 15 29 15\n",
      " 35 35 35 15 15 16 35 27]\n",
      "Epoch 8 Overall loss = 0.0685 and accuracy of 0.264\n",
      "pred:  [23 12 15 17 14 35 35 13 15 16 15 15 21 35 15 36 30 30 35 30 21 14 16 29\n",
      " 14 27 15 16 14 16 15 16 15 21 14 14 15 13 22 14 21 14 16 23 13 29 15 35\n",
      " 13 16 35 23 14 12 36 34 15 14 16 17 34 35 15 15 15 14 35 15 35 14 15 15\n",
      " 16 23 13 15 15 21 30 14 15 30 35 15 29 14 16 17 22 21 13 14 35 34 14 21\n",
      " 15 14 14 23 31 14 29 14 12 35 15 15 12 14 14 21 23 23 14 15 17 26 14 30\n",
      " 35 35 29 14 21 27 21 35]\n",
      "pred:  [14 35 14 15 35 35 34 29 16 14 15 34 15 16 16 13 16 15 30 16 15 14 14 16\n",
      " 17 23 15 14 21 15 15 35 15 35 11 14 15 14 26 15 15 16 14 17 14 30 34 14\n",
      " 16 30 16 16 15 15 16 16 15 15 35 35 14 35 17 35 16 30 15 21 14 35 21 14\n",
      " 16 36 14 22 13 16 13 16 30 17 17 17 15 21 12 14 23 23 14 26 21 14 35 12\n",
      " 15 36 15 34 29 16 22 16 16 35 13 14 15 15 15 29 35 14 36 23 21 13 14 21\n",
      " 21 15 23 21 34 15 21 15]\n",
      "pred:  [15 15 15 35 34 16 15 14 22 21 16 17 21 36 15 16 14 26 15 15 21 29 15 17\n",
      " 26 35 23 35 12 31 13 14 15 29 35 15 21 36 22 21 14 14 15 34 36 30 30 21\n",
      " 15 14 22 23 14 16 34 16 15 35 17 15 14 34 13 15 23 14 14 21 15 21 16 14\n",
      " 15 14 13 30 21 21 14 15 22 13 17 35 16 22 32 14 23 34 35 29 36 21 21 15\n",
      " 15 21 15 16 16 15 13 15 17 14 21 30 34 21 16 17 14 15 14 15 23 21 23 15\n",
      " 27 16 30 14 34 14 14 29]\n",
      "Epoch 8: Iteration 130: with minibatch training loss = 0.0647 and accuracy of 0.31\n",
      "pred:  [21 30 14 15 15 29 15 36 21 27 36 21 16 14 14 17 14 17 21 15 22 16 35 14\n",
      " 34 17 23 14 16 14 21 17 21 18 16 15 15 14 14 35 15 23 14 17 21 21 14 14\n",
      " 14 16 35 36 13 36 23 21 16 14 13 14 14 36 23 15 35 12 16 20 14 15 17 35\n",
      " 14 26 21 30 21 21 26 23 15 15 15 21 16 18 16 14 34 17 35 17 34 21 35 29\n",
      " 34 36 14 14 14 16 15 34 21 11 21 14 14 14 14 21 20 14 16 14 21 21 14 30\n",
      " 16 22 34 34 18 14 17 21]\n",
      "pred:  [35 36 26 15 35 16 17 15 26 36 15 14 36 12 27 36 22 29 22 15 15 15 21 17\n",
      " 14 21 14 15 22 13 35 14 16 16 14 15 12 27 21 14 16 12 17 14 21 21 15 35\n",
      " 30 14 14 21 14 14 14 15 16 23 15 16 15 15 21 35 22 15 35 13 17 14 15 21\n",
      " 15 16 14 21 14 21 26 11 34 34 26 14 26 14 15 14 14 23 15 35 21 15 31 14\n",
      " 35 29 21 15 15 23 31 26 11 35 14 12 21 21 34 14 29 15 34 15 14 27 13 21\n",
      " 13 16 14 16 15 14 17 34]\n",
      "pred:  [14 22 15 22 13 21 35 17 14 21 26 21 17 14 12 35 23 17 26 15 21 21 15 15\n",
      " 17 17 16 35 21 16 30 22 16 16 14 36 16 15 14 15 17 17 14 14 36 22 22 21\n",
      " 16 21 20 35 34 22 14 15 28 15 21 21 23 21 35 21 36 14 21 14 21 12 21 26\n",
      " 17 17 14 14 14 15 35 21 21 23 21 21 26 14 21 17 14 15 21 22 31 15 26 26\n",
      " 14 15 21 15 35 27 22 12 21 35 14 13 14 21 21 17 14 26 21 34 17 20 17 16\n",
      " 34 17 14 12 14 15 14 34]\n",
      "pred:  [21 21 14 15 14 16 15 34 27 14 36 17 22 17 29 17 25 16 35 21 21 21 12 14\n",
      " 21 14 22 29 11 21 26 17 23 21 13 22 34 22 14 21 17 14 26 26 29 12 22 23\n",
      " 16 25 13 12 17 14 16 21 16 22 14 15 14 17 21 21 13 22 35 15 26 17 21 16\n",
      " 17 22 15 15 16 14 15 35 15 15 13 22 14 17 13 21 16 15 35 17 13 34 29 15\n",
      " 16 16 16 13 14 16 16 17 14 22 21 16 14 14 18 26 26 34 23 17 17 26 35 17\n",
      " 21 16 21 17 29 21 16 31]\n",
      "pred:  [17 35 17 17 16 29 16 14 26 14 13 17 17 13 17 21 14 29 17 17 14 21 15 14\n",
      " 14 29 16 23 34 34 34 21 16 13 11 17 17 22 35 17 22 35 35 21 17 16 16 21\n",
      " 21 17 16 26 29 35 14 15 16 16 17 21 15 15 30 16 20 23 15 23 21 14 17 16\n",
      " 21 16 21 21 35 15 26 22 17 35 26 16 29 29 31 34 12 16 23 21 35 15 21 15\n",
      " 34 13 26 12 17 16 16 35 14 17 17 17 29 30 34 26 29 21 29 26 17 30 34 16\n",
      " 22 15 26 15 15 23 14 17]\n",
      "Epoch 8: Iteration 135: with minibatch training loss = 0.0655 and accuracy of 0.27\n",
      "pred:  [17 22 32 13 27 22 26 29 17 34 14 23 17 27 13 17 17 15 17 15 26 35 21 29\n",
      " 17 21 35 21 35 17 14 26 17 15 14 12 17 34 17 15 29 22 23 16 16 35 34 17\n",
      " 21 15 26 23 17 15 30 14 16 34 17 21 35 15 14 21 16 16 29 21 22 21 26 26\n",
      " 26 29 15 22 14 16 29 23 13 15 26 16 16 17 14 36 12 14 17 17 17 14 17 16\n",
      " 17 17 17 21 21 22 14 12 17 17 35 23 22 22 17 11 35 17 26 17 21 36 22 17\n",
      " 17 14 16 15 18 21 20 35]\n",
      "pred:  [34 22 13 15 13 26 26 14 23 17 26 17 12 29 20 22 16 35 20 21 17 29 17 12\n",
      " 26 34 15 22 15 21 23 35 21 14 13 21 15 34 15 22 32 13 16 17 16 15 29 16\n",
      " 14 29 17 18 13 35 17 26 26 29 34 23 28 17 34 21 17 21 17 15 22 21 34 26\n",
      " 29 27 15 17 14 21 14 29 34 13 29 26 26 22 34 17 16 35 21 13 35 29 12 23\n",
      " 21 13 17 14 14 22 22 29 29 15 14 15 29 29 35 14 14 16 17 22 17 36 15 29\n",
      " 34 17 29 16 29 35 16 30]\n",
      "pred:  [29 22 13 14 14 17 26 15 29 29 35 36 21 22 22 14 13 17 23 27 13 21 23 26\n",
      " 18 17 17 17 15 29 14 15 13 12 17 16 28 22 26 29 17 17 17 36 34 15 26 17\n",
      " 17 13 12 29 35 14 26 17 16 15 12 29 26 17 14 15 23 26 29 15 31 29 23 17\n",
      " 17 15 14 26 12 15 15 20 26 31 15 34 17 21 14 13 26 13 35 17 29 34 23 13\n",
      " 17 17 35 13 15 15 15 29 14 12 11 29 22 34 14 17 29 15 15 14 26 15 15 26\n",
      " 15 15 35 35 35 35 26 29]\n",
      "pred:  [22 12 14 17 29 31 15 34 29 29 14 16 15 17 26 29 17 17 29 15 12 17 13 26\n",
      " 31 14 17 13 34 17 31 34 16 30 15 14 29 14 29 13 35 15 26 13 29 35 17 35\n",
      " 13 17 29 21 17 35 14 35 15 22 17 22 35 23 35 35 15 17 22 20 21 26 34 23\n",
      " 13 21 20 14 14 29 26 13 14 17 17 17 13 15 13 17 14 14 29 16 29 31 20 17\n",
      " 16 23 16 26 29 21 26 29 23 34 16 35 34 18 15 15 18 29 16 17 13 15 15 12\n",
      " 35 15 35 13 16 13 15 17]\n",
      "pred:  [28 34 31 15 35 22 34 16 29 15 15 14 31 15 13 17 29 29 34 12 15 12 23 29\n",
      " 15 14 30 15 29 13 34 29 13 21 13 35 21 35 31 30 27 15 22 14 15 15 29 17\n",
      " 35 12 16 22 15 35 34 16 17 34 17 12 29 15 21 15 15 21 15 15 21 29 14 14\n",
      " 12 20 17 16 16 15 29 16 35 14 15 20 14 29 29 21 15 29 30 34 15 14 13 30\n",
      " 14 13 17 22 30 35 14 13 34 12 29 29 35 30 16 26 30 12 13 22 30 11 26 20\n",
      " 15 12 15 13 17 35 26 22]\n",
      "Epoch 8: Iteration 140: with minibatch training loss = 0.0636 and accuracy of 0.34\n",
      "pred:  [13 26 26 12 15 15 15 15 15 15 29 35 34 14 34 13 12 35 30 14 16 30 23 22\n",
      " 35 17 20 35 14 12 15 15 15 31 15 30 30 29 29 15 16 15 13 34 15 35 15 15\n",
      " 34 29 17 29 17 15 29 20 27 21 21 29 15 29 16 31 12 17 12 23 34 34 14 26\n",
      " 29 22 17 16 17 15 31 15 29 13 34 35 17 34 29 20 15 15 14 29 23 35 27 21\n",
      " 17 17 16 34 30 13 15 30 29 35 15 17 22 29 14 34 26 34 31 14 34 14 26 29\n",
      " 15 21 35 35 15 13 14 26]\n",
      "pred:  [13 15 14 14 30 29 34 16 20 22 18 23 14 17 14 12 21 15 15 15 34 22 29 30\n",
      " 15 17 15 15 34 17 15 16 21 15 22 30 15 30 34 15 17 29 15 15 15 23 35 13\n",
      " 35 21 29 22 13 23 14 17 14 12 35 15 16 14 29 14 22 16 26 12 15 22 15 16\n",
      " 34 15 30 13 23 15 21 15 14 29 35 14 15 34 34 15 35 14 14 35 30 20 30 14\n",
      " 35 17 14 14 17 22 15 17 14 29 29 16 16 30 30 22 29 14 29 12 15 15 31 14\n",
      " 35 17 16 34 30 15 29 34]\n",
      "pred:  [15 14 16 21 22 36 15 13 28 21 27 11 31 35 35 16 14 13 17 15 23 35 16 14\n",
      " 16 15 21 22 17 15 34 35 14 23 21 16 31 15 30 15 17 14 17 35 34 36 30 34\n",
      " 15 35 29 15 14 14 29 29 26 15 15 13 26 11 34 14 15 16 16 14 15 15 16 15\n",
      " 30 16 30 22 15 16 34 17]\n",
      "Epoch 9 Overall loss = 0.0642 and accuracy of 0.321\n",
      "pred:  [21 14 17 17 14 15 17 13 15 22 15 17 23 35 15 30 30 30 35 30 21 12 14 35\n",
      " 13 15 15 22 14 16 15 22 15 16 13 14 15 15 15 31 21 14 20 17 13 30 35 34\n",
      " 12 35 29 16 14 11 26 35 15 14 16 35 34 16 15 14 15 35 29 14 27 14 15 15\n",
      " 15 23 13 15 15 21 30 15 15 35 35 15 15 16 16 17 22 17 14 13 35 34 31 21\n",
      " 14 14 22 15 31 15 29 14 12 35 15 15 13 13 14 20 23 23 14 15 21 30 31 30\n",
      " 14 35 35 14 23 17 23 16]\n",
      "pred:  [14 35 14 14 30 20 34 20 16 13 35 34 15 21 35 12 22 21 26 15 15 31 14 17\n",
      " 21 21 15 15 20 15 15 35 15 17 13 14 14 14 36 14 21 21 31 29 14 30 34 35\n",
      " 16 32 20 22 13 14 21 15 15 17 35 30 14 23 17 34 21 30 15 23 15 30 21 14\n",
      " 16 30 14 22 13 15 13 35 30 21 15 14 15 35 23 16 15 15 14 30 16 14 35 14\n",
      " 16 35 15 35 21 15 16 16 16 29 15 34 14 15 15 16 29 14 30 16 23 14 14 21\n",
      " 21 15 23 23 35 15 15 15]\n",
      "Epoch 9: Iteration 145: with minibatch training loss = 0.061 and accuracy of 0.36\n",
      "pred:  [14 15 34 26 34 16 14 21 16 21 15 17 12 36 15 15 16 36 16 15 21 29 15 17\n",
      " 30 35 16 34 15 14 13 14 17 35 16 15 17 36 16 21 21 15 15 34 29 26 36 23\n",
      " 15 15 20 16 16 14 34 16 15 35 15 15 16 34 14 17 17 14 14 21 15 21 13 14\n",
      " 15 14 12 36 21 23 14 16 14 13 17 26 16 22 20 15 16 35 14 18 30 21 14 15\n",
      " 15 21 15 16 14 15 14 15 21 14 17 36 15 21 21 15 14 16 14 15 23 21 16 35\n",
      " 27 16 30 16 34 21 29 35]\n",
      "pred:  [21 30 14 15 15 20 15 30 21 27 36 15 21 14 14 17 34 17 15 14 16 16 20 16\n",
      " 34 17 23 14 35 12 15 17 21 35 15 17 16 15 34 26 16 21 14 21 21 21 14 20\n",
      " 31 35 26 36 13 30 21 21 29 14 12 15 14 32 21 14 35 12 21 26 14 15 17 20\n",
      " 14 26 23 36 11 21 30 17 15 15 14 18 22 35 16 14 34 20 26 35 34 21 34 27\n",
      " 34 36 14 12 14 15 14 29 21 14 21 31 14 14 14 21 21 14 16 15 23 17 14 26\n",
      " 21 22 13 34 18 23 17 17]\n",
      "pred:  [35 36 30 15 35 35 35 16 26 26 34 14 36 14 16 20 22 35 22 15 15 29 21 17\n",
      " 14 20 15 16 16 16 35 14 16 22 14 17 12 16 21 16 21 16 13 14 20 17 15 16\n",
      " 30 14 15 27 16 15 14 15 22 16 15 15 15 34 21 35 21 21 35 14 16 14 15 34\n",
      " 21 33 31 21 31 17 30 14 34 34 30 31 30 31 15 14 15 16 15 23 21 15 14 15\n",
      " 26 29 21 15 14 21 14 26 12 35 11 12 21 14 35 14 35 14 34 14 13 27 14 14\n",
      " 21 35 14 34 14 14 16 34]\n",
      "pred:  [22 16 23 21 13 16 35 17 13 12 30 21 15 17 14 23 21 17 26 15 21 26 15 14\n",
      " 15 23 14 27 20 17 26 22 14 35 14 36 20 15 21 15 17 17 17 16 26 16 22 23\n",
      " 14 23 16 26 34 22 16 15 16 15 21 21 26 21 16 11 36 14 35 17 21 11 16 36\n",
      " 17 16 14 23 14 15 35 17 14 23 35 17 20 35 21 13 13 14 23 22 31 16 20 23\n",
      " 35 15 23 16 35 27 21 12 21 35 15 14 35 21 36 17 14 26 21 34 17 20 17 29\n",
      " 34 17 21 17 14 15 14 35]\n",
      "pred:  [21 36 20 15 21 16 16 34 16 14 36 17 16 17 21 15 30 16 29 31 27 12 14 14\n",
      " 21 15 22 26 13 26 29 17 21 21 16 20 34 22 16 21 17 14 21 26 29 21 22 21\n",
      " 35 30 14 12 17 14 17 17 14 16 14 23 14 15 27 21 16 14 26 15 26 17 21 17\n",
      " 27 22 15 15 15 14 34 16 17 21 13 22 14 17 16 21 29 15 17 17 16 34 35 15\n",
      " 15 16 17 16 35 17 14 17 15 16 22 16 17 26 16 29 25 34 21 17 17 35 26 17\n",
      " 21 16 21 17 36 23 16 16]\n",
      "Epoch 9: Iteration 150: with minibatch training loss = 0.0626 and accuracy of 0.3\n",
      "pred:  [15 34 17 17 15 23 29 31 21 14 13 15 16 17 17 29 34 36 17 13 16 21 15 12\n",
      " 34 29 17 22 34 34 35 21 22 35 13 15 17 15 18 17 16 35 13 17 17 16 16 21\n",
      " 17 16 16 26 23 35 14 14 14 29 17 21 16 29 26 17 30 21 14 35 21 14 15 26\n",
      " 23 13 21 21 35 17 36 21 16 34 32 16 14 17 14 34 12 16 23 26 29 17 17 15\n",
      " 29 13 29 12 14 17 22 14 15 17 16 15 29 36 34 26 17 17 29 30 17 30 34 15\n",
      " 21 15 36 15 17 21 14 21]\n",
      "pred:  [17 22 34 16 27 16 31 13 17 34 14 21 15 26 13 13 27 17 17 15 26 14 26 29\n",
      " 12 26 29 17 35 17 14 36 17 14 31 12 13 14 15 16 17 22 23 16 16 16 13 15\n",
      " 21 29 26 21 17 15 30 14 16 34 17 21 34 17 14 14 17 16 35 22 16 23 26 26\n",
      " 36 26 15 22 17 13 29 23 12 15 30 16 22 17 13 21 12 15 17 17 29 14 11 15\n",
      " 27 17 17 21 21 16 14 17 17 17 16 17 22 22 17 17 29 17 35 13 23 26 22 21\n",
      " 17 14 34 27 35 22 26 35]\n",
      "pred:  [34 23 13 13 16 31 35 14 16 17 30 27 12 29 30 16 16 35 22 12 17 22 17 12\n",
      " 30 31 15 22 15 26 22 29 23 14 14 18 13 29 15 29 31 29 34 16 14 15 35 16\n",
      " 31 15 29 23 13 17 17 31 30 35 34 15 31 17 34 21 17 14 17 29 21 34 34 30\n",
      " 27 29 15 15 35 23 14 16 29 13 29 35 30 22 34 17 17 17 23 14 26 16 12 27\n",
      " 21 35 17 14 13 22 22 14 17 15 14 15 29 31 35 17 35 29 13 22 17 30 17 22\n",
      " 34 17 29 15 15 29 17 26]\n",
      "pred:  [17 14 11 17 14 13 26 29 26 35 26 30 21 31 14 15 13 21 23 29 13 21 23 26\n",
      " 35 17 21 17 15 29 29 29 13 13 15 29 15 29 29 35 29 17 29 30 34 14 30 17\n",
      " 13 13 13 35 26 14 26 29 29 15 23 29 26 12 14 17 23 26 29 15 31 17 21 17\n",
      " 27 15 35 20 12 15 15 26 30 31 15 34 17 23 14 13 20 14 16 20 27 34 23 14\n",
      " 21 17 29 13 23 13 15 16 12 11 15 15 29 29 14 26 29 15 29 23 30 35 15 35\n",
      " 15 15 29 29 29 26 26 29]\n",
      "pred:  [16 12 31 17 15 31 15 34 29 29 23 15 35 17 30 29 29 17 18 14 12 17 12 26\n",
      " 30 14 17 13 34 17 14 13 13 30 15 14 35 14 29 16 29 15 30 15 21 35 29 35\n",
      " 11 17 27 23 29 29 14 35 15 16 21 16 35 27 29 29 23 16 22 21 15 35 34 17\n",
      " 14 21 20 14 15 29 26 15 14 27 29 17 12 15 13 17 31 14 13 13 29 16 20 29\n",
      " 29 23 16 30 16 23 26 29 16 12 16 29 34 16 15 15 26 34 16 17 17 15 29 12\n",
      " 29 35 29 13 16 11 29 17]\n",
      "Epoch 9: Iteration 155: with minibatch training loss = 0.0556 and accuracy of 0.45\n",
      "pred:  [28 29 22 15 29 14 34 29 29 29 23 14 15 15 15 17 15 27 35 12 15 13 21 35\n",
      " 15 14 25 15 29 34 34 27 14 23 12 35 21 29 31 36 23 15 22 13 15 15 29 15\n",
      " 35 12 27 22 15 15 14 16 17 34 17 12 35 15 21 15 15 21 15 15 21 35 17 14\n",
      " 23 26 17 16 22 15 29 16 14 16 15 29 14 29 29 21 15 34 30 35 15 14 13 30\n",
      " 17 13 17 22 30 29 14 12 34 12 29 22 26 21 15 29 20 12 13 16 30 13 30 21\n",
      " 15 13 15 15 17 18 30 22]\n",
      "pred:  [14 26 20 12 17 35 15 15 15 15 35 35 35 14 34 16 13 29 31 29 35 36 23 16\n",
      " 22 17 21 35 14 12 15 21 15 14 15 26 31 20 31 15 23 15 14 34 16 35 16 15\n",
      " 13 29 27 29 15 15 20 16 29 21 21 15 16 29 15 31 13 17 12 23 34 34 13 30\n",
      " 35 22 27 13 16 15 31 15 34 12 29 35 17 34 29 29 15 15 14 35 23 29 35 22\n",
      " 17 15 15 34 36 14 15 30 35 29 15 17 16 29 15 13 35 29 26 13 16 31 27 29\n",
      " 15 23 29 35 14 13 31 31]\n",
      "pred:  [34 29 34 14 36 15 15 13 30 22 35 12 15 17 16 12 21 15 14 15 34 22 35 29\n",
      " 15 17 15 21 29 17 15 18 21 15 14 30 15 26 13 15 15 35 15 23 15 16 35 16\n",
      " 20 23 35 22 14 21 14 17 13 12 18 15 15 32 16 15 16 35 35 13 14 15 15 15\n",
      " 34 15 30 13 21 15 15 15 14 29 14 14 15 13 34 34 30 14 14 15 26 20 30 14\n",
      " 20 17 13 14 17 22 15 17 13 35 29 21 16 30 26 29 16 14 35 12 15 15 35 13\n",
      " 20 17 23 34 16 15 29 35]\n",
      "pred:  [15 14 22 14 22 30 15 11 28 23 21 13 31 35 16 16 15 16 17 23 21 29 20 14\n",
      " 35 15 27 22 21 15 35 15 13 23 21 20 35 15 30 15 17 22 17 35 34 36 30 21\n",
      " 14 35 22 15 13 12 15 35 29 15 15 13 26 13 21 14 15 16 29 13 15 15 35 15\n",
      " 30 17 26 14 14 16 27 21]\n",
      "Epoch 10 Overall loss = 0.0588 and accuracy of 0.377\n",
      "pred:  [21 13 15 17 35 14 17 13 15 22 15 17 21 35 15 36 35 30 35 30 21 13 16 29\n",
      " 16 16 15 22 13 16 15 22 15 15 14 14 15 13 15 31 34 14 35 16 13 14 15 35\n",
      " 13 35 35 16 15 14 36 34 15 14 16 16 34 23 15 15 15 35 35 14 27 14 15 15\n",
      " 15 23 13 15 15 21 36 15 15 26 35 15 16 15 16 17 21 21 34 13 16 34 16 23\n",
      " 14 35 22 21 31 14 20 14 13 35 22 15 12 13 14 20 23 21 14 15 21 21 15 26\n",
      " 35 35 16 14 21 17 16 18]\n",
      "Epoch 10: Iteration 160: with minibatch training loss = 0.0558 and accuracy of 0.4\n",
      "pred:  [14 35 14 34 35 21 34 29 16 35 14 34 15 22 23 13 23 21 21 15 15 31 14 21\n",
      " 17 21 15 21 34 15 15 35 15 16 12 14 15 15 35 15 21 16 31 27 16 36 34 35\n",
      " 18 29 29 16 14 14 16 35 16 13 35 21 14 23 17 34 21 30 15 23 15 26 27 14\n",
      " 35 36 14 14 14 28 13 35 26 17 17 16 15 27 12 22 16 15 14 36 21 14 35 12\n",
      " 16 26 15 13 21 15 14 22 16 26 14 14 16 15 14 27 18 13 36 21 21 16 31 21\n",
      " 21 35 23 21 29 13 21 15]\n",
      "pred:  [17 15 35 35 34 16 14 14 16 21 16 17 12 26 15 15 35 35 21 15 17 35 13 17\n",
      " 21 35 16 34 12 14 14 14 17 35 35 15 16 26 16 14 15 15 15 29 32 30 35 21\n",
      " 15 14 22 21 16 22 34 16 15 35 16 15 16 34 11 15 17 31 14 21 27 21 14 14\n",
      " 15 14 14 25 23 23 14 16 22 13 21 35 35 22 20 15 16 34 14 26 30 21 14 15\n",
      " 15 21 15 35 15 15 34 16 27 14 17 36 35 14 14 15 14 15 16 16 21 23 23 16\n",
      " 27 16 30 21 34 12 35 35]\n",
      "pred:  [21 26 14 17 15 20 16 30 21 17 26 15 17 15 14 17 34 27 15 16 22 23 20 14\n",
      " 34 27 21 16 26 12 23 27 21 35 17 17 16 15 34 26 14 21 16 17 21 21 14 20\n",
      " 15 16 35 30 14 36 21 17 17 14 16 15 15 23 21 14 35 12 16 26 14 15 17 26\n",
      " 15 36 23 26 14 21 30 16 14 15 14 18 29 18 16 14 34 27 29 16 34 21 34 17\n",
      " 34 30 16 17 34 16 14 29 21 11 21 31 14 16 14 23 20 14 16 15 23 17 14 30\n",
      " 16 16 34 21 29 14 17 17]\n",
      "pred:  [26 36 30 15 34 16 16 31 26 30 34 17 26 17 27 26 14 35 22 15 16 17 21 17\n",
      " 14 21 17 15 16 16 26 14 23 21 15 16 12 17 23 14 23 11 14 16 20 17 14 22\n",
      " 26 16 16 27 16 15 14 15 22 23 15 15 16 34 16 34 22 21 26 14 17 14 15 34\n",
      " 14 20 31 17 14 21 26 12 34 34 30 14 26 31 16 15 14 16 16 23 21 17 34 14\n",
      " 21 22 21 21 14 17 14 26 13 15 12 12 21 13 29 21 16 15 34 35 14 27 11 23\n",
      " 21 23 14 34 16 11 17 34]\n",
      "pred:  [22 16 15 21 13 21 34 27 14 12 30 21 15 16 34 29 17 17 26 15 21 21 15 15\n",
      " 15 21 16 20 21 16 26 20 14 35 14 36 21 15 14 14 17 17 17 15 26 22 20 21\n",
      " 16 23 20 35 34 21 13 15 16 17 15 21 35 35 16 17 35 14 23 16 21 14 34 36\n",
      " 27 17 14 14 16 15 35 21 15 21 27 21 21 35 21 17 13 17 21 21 31 16 22 21\n",
      " 16 29 21 15 18 27 15 11 21 35 15 13 16 21 30 17 14 16 21 31 17 20 17 16\n",
      " 34 17 21 17 14 16 14 34]\n",
      "Epoch 10: Iteration 165: with minibatch training loss = 0.0572 and accuracy of 0.38\n",
      "pred:  [21 30 21 15 14 16 15 34 23 14 36 17 22 17 23 17 26 17 16 14 26 12 14 14\n",
      " 21 15 21 35 13 21 35 17 23 21 17 22 34 22 14 15 21 35 26 26 29 12 22 21\n",
      " 35 26 14 12 11 14 17 27 14 16 14 15 14 17 35 21 14 21 35 15 26 17 21 14\n",
      " 27 16 15 15 17 31 34 18 17 21 16 22 14 17 16 21 16 15 27 17 16 34 34 15\n",
      " 15 16 14 17 35 16 16 17 14 29 20 16 17 21 29 29 36 34 16 21 17 35 29 17\n",
      " 21 16 21 14 29 21 16 22]\n",
      "pred:  [15 34 16 21 14 29 20 31 36 14 16 15 17 14 14 26 31 23 17 13 16 20 28 12\n",
      " 17 16 16 23 34 34 35 21 15 35 14 15 21 16 16 17 16 26 29 21 17 29 35 20\n",
      " 21 17 16 29 35 29 14 16 17 16 17 21 16 14 36 17 26 21 16 35 21 14 15 26\n",
      " 16 16 21 21 29 17 30 21 17 16 26 15 36 16 31 34 13 16 23 26 14 21 17 15\n",
      " 30 13 20 12 17 17 21 15 23 27 17 16 35 26 29 26 17 12 34 26 17 26 34 15\n",
      " 21 15 26 15 17 21 14 15]\n",
      "pred:  [17 22 34 13 29 16 36 34 13 34 31 21 35 27 17 15 17 17 23 15 26 35 26 29\n",
      " 17 30 16 17 35 16 14 31 17 15 15 12 12 35 15 16 20 22 23 16 22 35 13 15\n",
      " 26 15 26 21 27 15 20 35 22 34 23 21 16 21 14 17 16 16 35 16 16 23 36 35\n",
      " 36 35 15 22 14 14 18 21 12 15 26 18 20 17 14 21 12 14 17 17 29 35 12 14\n",
      " 27 27 17 21 23 22 14 17 14 17 35 23 22 22 17 17 26 17 35 34 23 26 22 21\n",
      " 17 31 14 29 20 20 21 14]\n",
      "pred:  [34 23 12 29 13 36 29 14 23 17 30 27 12 26 26 16 13 35 29 12 17 20 29 12\n",
      " 36 34 15 22 29 30 22 26 21 14 13 21 17 29 15 22 30 35 16 31 35 35 31 16\n",
      " 14 14 29 18 13 17 17 30 30 35 34 23 31 17 34 21 17 14 17 15 21 34 34 30\n",
      " 34 29 17 16 35 21 14 16 35 13 35 26 32 22 34 16 29 14 21 14 30 20 12 17\n",
      " 21 35 17 16 14 22 22 16 17 15 35 15 29 30 13 14 16 29 14 29 17 36 29 22\n",
      " 34 17 16 16 15 29 17 26]\n",
      "pred:  [29 22 14 16 31 13 30 15 20 35 18 30 21 14 15 14 14 23 17 27 13 21 23 34\n",
      " 16 17 17 29 15 29 14 15 13 13 15 35 14 22 20 13 26 17 14 31 34 31 26 29\n",
      " 17 13 15 35 20 14 26 17 16 29 23 20 26 11 14 15 17 30 34 15 31 14 23 17\n",
      " 35 15 14 29 12 15 15 27 26 14 15 35 17 16 13 12 30 15 14 20 29 34 23 17\n",
      " 21 17 29 14 23 15 15 23 12 12 14 29 22 34 35 29 28 15 15 14 26 15 15 35\n",
      " 15 14 35 13 29 26 30 13]\n",
      "Epoch 10: Iteration 170: with minibatch training loss = 0.0539 and accuracy of 0.46\n",
      "pred:  [22 12 31 27 15 31 15 34 35 35 23 13 35 17 30 35 27 17 35 14 13 17 15 30\n",
      " 30 35 17 13 34 17 14 34 13 30 23 14 35 31 13 14 29 15 30 13 22 35 17 29\n",
      " 12 17 29 23 29 35 14 30 15 16 17 16 16 23 29 29 23 15 22 20 23 36 34 17\n",
      " 13 21 20 14 14 29 30 17 14 17 29 17 17 15 12 17 30 14 29 13 29 29 29 17\n",
      " 14 21 16 35 17 23 26 13 29 12 16 27 34 16 15 15 29 15 16 23 14 15 13 11\n",
      " 29 14 29 13 16 13 13 17]\n",
      "pred:  [29 29 22 29 29 16 34 29 29 15 23 35 14 15 15 17 29 29 35 13 15 34 23 18\n",
      " 15 13 30 15 27 13 34 16 35 21 12 29 16 35 31 36 23 15 16 13 15 15 29 28\n",
      " 29 12 27 22 15 15 35 29 15 31 17 13 35 15 23 15 15 21 14 15 21 35 17 14\n",
      " 23 26 17 16 22 14 29 17 15 16 15 20 13 26 29 21 15 35 30 35 15 14 12 36\n",
      " 13 13 17 22 30 35 14 12 34 21 29 20 35 20 15 29 30 23 13 16 26 21 26 20\n",
      " 28 13 15 14 27 16 30 29]\n",
      "pred:  [13 35 20 12 21 14 16 15 15 15 16 29 13 14 34 16 12 29 30 35 35 26 23 22\n",
      " 20 17 20 35 14 12 21 23 23 14 15 30 30 20 29 14 35 15 15 34 14 35 31 35\n",
      " 13 15 17 26 15 15 29 20 27 21 21 15 22 29 15 31 17 17 13 21 34 15 13 30\n",
      " 35 22 27 16 16 14 31 15 34 13 17 35 17 34 29 29 15 15 14 35 23 29 27 21\n",
      " 17 15 15 34 26 13 15 30 35 29 15 17 22 35 15 15 35 29 30 13 13 31 27 29\n",
      " 15 23 35 35 21 13 15 30]\n",
      "pred:  [13 23 35 14 30 15 29 13 30 22 29 23 15 17 13 12 21 15 14 15 34 20 18 29\n",
      " 15 17 15 15 34 17 15 16 23 15 14 30 15 25 13 15 31 35 15 22 15 16 35 15\n",
      " 30 21 29 29 13 21 14 27 13 12 22 15 28 29 16 15 21 36 35 13 14 15 15 15\n",
      " 34 15 21 14 23 16 16 15 14 29 13 14 15 13 14 34 30 15 13 29 30 20 26 13\n",
      " 20 17 13 14 29 22 15 17 11 35 29 21 16 30 30 22 35 14 29 11 21 14 35 13\n",
      " 26 17 23 34 14 28 29 20]\n",
      "pred:  [15 14 22 21 22 36 23 14 28 23 23 11 14 35 13 16 14 16 17 21 23 35 16 14\n",
      " 16 15 17 22 21 15 35 15 14 23 23 16 35 15 36 15 17 22 17 26 35 30 30 21\n",
      " 15 29 16 15 14 13 15 35 20 15 15 13 30 13 34 15 21 23 23 14 15 15 27 15\n",
      " 35 16 35 14 15 16 27 17]\n",
      "Epoch 10: Iteration 175: with minibatch training loss = 0.0476 and accuracy of 0.55\n",
      "Epoch 11 Overall loss = 0.0539 and accuracy of 0.442\n",
      "pred:  [21 11 31 17 35 15 16 14 15 22 15 17 23 35 15 30 36 36 35 30 21 13 14 16\n",
      " 14 16 15 22 12 16 15 16 15 15 14 14 15 13 15 31 21 14 18 16 13 14 14 35\n",
      " 14 35 29 16 35 13 36 34 21 14 16 17 34 35 15 15 15 14 35 14 27 14 14 15\n",
      " 15 21 13 15 15 21 31 15 27 36 26 15 17 16 16 17 21 17 15 13 35 34 31 21\n",
      " 14 35 22 23 14 15 21 14 15 35 22 15 13 13 14 20 23 23 14 15 11 21 14 30\n",
      " 13 18 16 14 23 17 21 35]\n",
      "pred:  [14 35 14 14 36 20 34 29 16 35 16 34 16 22 35 13 16 15 26 27 15 31 20 17\n",
      " 17 21 15 21 20 15 34 35 15 35 12 15 15 35 36 14 21 21 31 17 14 36 34 35\n",
      " 16 21 20 22 17 14 23 34 17 15 35 36 14 21 27 34 16 36 15 23 15 30 16 14\n",
      " 23 36 15 29 17 28 13 34 30 17 29 27 15 27 23 16 17 15 14 30 21 13 26 12\n",
      " 22 35 15 13 21 15 22 16 16 35 14 13 16 15 15 27 18 14 30 16 21 14 31 17\n",
      " 23 14 23 21 35 15 21 29]\n",
      "pred:  [21 15 35 26 34 16 14 14 21 21 16 17 12 36 15 16 35 26 16 15 27 29 13 27\n",
      " 30 35 17 34 14 31 14 31 31 29 23 15 27 36 16 11 15 15 15 29 20 26 32 21\n",
      " 15 14 14 21 16 22 34 22 16 16 17 14 16 34 14 17 17 14 14 21 29 21 13 14\n",
      " 21 14 13 36 23 21 14 23 14 14 21 35 35 16 20 28 16 34 14 35 30 17 21 14\n",
      " 15 23 15 16 14 15 34 28 21 14 17 30 29 21 14 14 13 29 16 15 16 21 35 17\n",
      " 27 23 30 22 34 12 35 35]\n",
      "pred:  [21 30 14 15 15 20 16 30 23 16 30 15 21 15 31 21 14 27 21 15 16 16 26 32\n",
      " 34 27 23 16 35 12 15 35 21 26 31 17 15 15 34 26 14 21 17 17 21 23 14 21\n",
      " 31 23 35 30 14 21 22 21 35 28 14 15 14 20 21 15 29 12 17 35 13 28 17 26\n",
      " 12 20 21 36 17 21 21 31 15 31 28 18 14 18 16 31 34 27 29 16 34 21 35 27\n",
      " 34 36 16 16 34 16 17 15 23 14 21 31 14 16 16 23 20 14 16 15 14 17 14 30\n",
      " 14 22 14 34 29 14 17 17]\n",
      "pred:  [26 26 30 15 35 23 16 31 30 30 34 14 36 12 16 26 22 35 22 15 31 17 23 17\n",
      " 14 21 14 16 21 16 26 14 21 22 31 17 16 34 21 14 18 17 14 16 27 17 14 16\n",
      " 26 16 15 27 16 14 14 14 16 16 15 16 14 34 21 16 21 21 26 14 31 14 15 34\n",
      " 22 29 31 17 16 21 25 17 34 34 30 31 21 31 31 17 14 36 16 35 21 17 34 14\n",
      " 35 20 22 15 16 12 31 26 12 29 12 12 21 34 29 14 34 14 34 14 12 27 14 21\n",
      " 11 16 16 34 14 14 17 34]\n",
      "Epoch 11: Iteration 180: with minibatch training loss = 0.0489 and accuracy of 0.55\n",
      "pred:  [22 16 31 21 14 18 29 17 14 12 26 21 15 16 34 35 17 17 30 15 21 30 15 14\n",
      " 15 23 14 33 20 14 30 22 14 23 17 30 29 15 14 15 17 17 17 28 25 22 26 17\n",
      " 16 23 20 26 34 22 14 15 16 17 14 20 26 35 29 17 36 14 18 17 21 12 26 36\n",
      " 17 17 14 14 13 15 35 17 21 21 26 17 21 35 21 17 14 17 17 16 31 16 21 18\n",
      " 14 17 21 14 26 27 14 21 21 31 15 16 16 21 26 17 14 35 23 31 17 21 17 16\n",
      " 34 17 22 16 14 35 14 34]\n",
      "pred:  [17 30 33 15 14 35 31 34 27 14 36 16 22 17 23 29 26 16 16 14 27 12 14 14\n",
      " 23 16 22 26 12 26 26 21 23 23 11 29 34 22 17 14 21 35 26 26 29 12 16 21\n",
      " 35 36 35 12 11 14 14 17 14 29 16 15 14 16 27 21 16 16 35 31 26 16 23 14\n",
      " 17 16 15 15 17 15 34 29 17 16 16 22 14 17 16 21 35 14 27 17 14 34 34 15\n",
      " 15 16 16 17 34 16 16 17 15 29 20 16 14 32 26 29 30 34 35 21 31 26 35 17\n",
      " 21 15 23 17 23 16 16 20]\n",
      "pred:  [15 34 15 21 15 23 35 31 26 14 21 15 16 14 17 26 31 21 17 14 35 20 28 12\n",
      " 15 23 16 16 34 34 35 21 16 13 17 15 21 16 23 17 29 26 35 21 17 29 16 21\n",
      " 17 29 16 35 35 35 14 14 14 29 17 21 16 17 26 17 26 21 14 31 23 14 31 29\n",
      " 21 16 16 21 26 17 36 29 17 16 26 15 23 17 14 29 13 16 23 30 16 21 17 15\n",
      " 30 14 21 12 14 17 16 14 15 17 31 14 35 26 29 26 17 12 29 26 21 26 29 15\n",
      " 20 15 26 15 29 21 14 15]\n",
      "pred:  [27 22 34 16 26 22 31 16 17 34 31 23 34 27 12 13 17 17 21 15 26 16 26 15\n",
      " 12 26 26 17 23 16 14 26 17 15 14 12 12 35 15 15 26 22 22 29 16 23 16 15\n",
      " 21 15 26 21 27 15 26 35 16 34 23 23 16 23 14 11 17 16 35 16 16 23 26 26\n",
      " 26 14 15 22 12 13 16 23 12 15 26 29 29 17 13 30 12 13 17 17 17 35 14 14\n",
      " 27 17 27 21 23 29 14 17 17 17 35 17 22 16 17 21 18 17 18 34 21 30 22 23\n",
      " 17 31 16 28 23 22 26 35]\n",
      "pred:  [34 21 13 29 13 30 23 14 14 21 26 27 13 29 36 29 16 23 29 11 17 20 27 12\n",
      " 36 34 15 22 29 30 21 29 23 14 16 21 14 35 15 22 29 35 13 15 35 29 23 23\n",
      " 28 17 17 16 13 15 17 26 26 35 34 23 15 16 34 21 17 16 17 15 15 20 16 26\n",
      " 17 29 15 17 34 21 14 28 16 14 29 26 26 16 34 17 18 15 23 13 26 20 12 16\n",
      " 21 35 17 14 13 21 22 29 17 15 13 15 29 29 14 17 16 29 14 22 27 36 31 22\n",
      " 34 21 31 16 15 29 17 26]\n",
      "Epoch 11: Iteration 185: with minibatch training loss = 0.0477 and accuracy of 0.5\n",
      "pred:  [27 22 14 13 15 12 30 15 26 29 16 30 21 14 14 15 14 21 21 27 13 21 23 26\n",
      " 18 17 21 29 15 22 35 15 14 34 17 15 14 16 20 35 27 17 17 26 34 31 26 27\n",
      " 14 13 13 29 21 15 35 29 23 15 23 21 26 12 14 17 23 25 34 15 31 13 21 17\n",
      " 29 15 15 29 12 14 15 26 35 31 15 35 17 21 13 13 26 15 17 20 17 34 23 14\n",
      " 21 17 29 13 21 15 15 16 13 17 15 17 22 29 35 29 28 29 29 14 26 15 15 26\n",
      " 15 17 23 29 29 26 26 17]\n",
      "pred:  [21 11 15 27 15 31 15 34 29 35 21 15 35 17 30 35 29 27 29 15 12 17 12 36\n",
      " 30 35 17 13 34 17 14 34 13 30 21 14 26 31 13 13 29 15 30 34 23 29 16 35\n",
      " 11 17 29 23 34 29 14 30 15 16 21 22 35 23 27 35 21 31 22 20 21 36 34 17\n",
      " 13 21 20 14 15 35 32 15 14 27 29 17 16 15 13 17 30 14 13 16 29 29 20 29\n",
      " 29 21 16 30 17 21 26 15 16 11 22 20 34 16 15 15 29 34 16 23 17 15 15 12\n",
      " 29 14 23 11 16 12 13 17]\n",
      "pred:  [28 35 20 14 29 14 34 29 29 29 23 35 14 15 15 17 15 23 35 12 15 15 23 20\n",
      " 15 14 31 15 27 12 34 29 35 21 14 35 22 29 31 30 23 15 16 13 14 15 16 16\n",
      " 35 14 27 22 15 15 13 28 21 34 17 12 35 15 23 29 15 21 15 15 21 35 11 14\n",
      " 23 26 17 16 22 21 29 16 15 16 15 29 13 20 27 21 15 34 30 13 15 14 12 30\n",
      " 14 13 27 22 31 35 14 12 34 21 35 20 36 21 15 18 30 23 13 15 30 11 35 20\n",
      " 15 12 15 15 27 29 30 22]\n",
      "pred:  [14 35 21 12 21 35 15 15 29 15 35 35 15 14 34 13 12 29 36 29 28 26 23 22\n",
      " 22 17 20 29 14 17 21 17 23 14 15 35 26 29 29 15 26 15 15 30 14 29 31 23\n",
      " 13 29 17 29 29 15 29 22 27 21 21 15 22 29 15 31 17 17 13 21 34 15 13 21\n",
      " 29 16 16 13 16 17 31 15 35 12 29 35 17 34 29 29 15 21 14 35 23 29 29 22\n",
      " 27 21 15 34 26 13 15 26 35 16 13 17 22 35 15 13 29 29 26 14 13 31 27 14\n",
      " 35 21 35 35 23 14 35 36]\n",
      "pred:  [13 29 35 14 36 29 31 13 30 22 23 23 15 17 13 13 21 15 15 15 34 29 29 29\n",
      " 17 16 15 16 34 17 35 16 21 15 14 30 15 30 14 11 31 35 15 21 15 16 36 14\n",
      " 29 23 29 22 35 23 14 17 13 12 21 15 16 29 16 15 21 36 35 13 14 21 15 15\n",
      " 34 15 21 13 21 15 27 15 14 20 13 14 15 13 34 34 21 14 35 34 26 20 26 13\n",
      " 21 27 29 14 29 16 15 17 17 29 29 23 29 30 30 22 29 14 36 12 21 14 31 13\n",
      " 27 17 21 34 29 15 29 21]\n",
      "Epoch 11: Iteration 190: with minibatch training loss = 0.0464 and accuracy of 0.55\n",
      "pred:  [15 14 22 21 16 31 21 14 28 21 21 11 14 35 16 16 31 13 17 21 21 35 21 14\n",
      " 36 16 27 22 21 14 16 15 14 21 23 35 36 15 30 15 17 22 17 35 35 31 30 21\n",
      " 15 35 20 15 35 13 15 35 14 16 15 12 30 13 21 14 21 21 29 14 15 29 27 35\n",
      " 35 29 35 22 15 21 27 27]\n",
      "Epoch 12 Overall loss = 0.0478 and accuracy of 0.522\n",
      "pred:  [21 12 16 17 35 14 16 14 15 22 15 31 23 18 17 30 36 30 35 30 21 13 16 23\n",
      " 14 17 15 16 12 16 15 16 29 15 13 15 15 13 15 31 21 14 18 16 14 14 14 35\n",
      " 13 35 35 16 35 11 30 34 21 21 13 34 34 35 15 14 15 16 35 35 27 14 15 15\n",
      " 15 21 14 15 15 21 30 14 29 30 35 15 17 15 16 17 22 17 35 14 13 34 15 23\n",
      " 16 35 22 21 16 14 20 14 34 35 22 31 13 16 13 20 14 21 14 15 21 21 14 21\n",
      " 13 16 35 14 23 16 22 35]\n",
      "pred:  [14 35 14 13 36 20 34 29 16 14 35 34 16 16 35 12 35 15 30 29 15 31 14 17\n",
      " 17 21 15 21 20 15 34 35 15 35 12 14 15 35 36 14 21 21 31 16 14 36 34 35\n",
      " 16 35 29 22 17 14 23 34 32 14 26 30 14 23 17 34 20 30 15 23 15 35 17 14\n",
      " 35 31 15 22 17 16 13 16 21 17 17 16 15 27 12 22 16 21 14 30 21 14 35 13\n",
      " 22 34 15 13 14 15 20 22 16 35 14 35 14 15 14 23 18 35 36 16 21 16 14 21\n",
      " 23 14 23 14 29 15 21 15]\n",
      "pred:  [21 15 14 26 15 35 14 14 18 21 16 17 12 30 15 16 35 26 16 15 21 18 13 31\n",
      " 21 35 16 34 12 31 14 14 31 16 23 15 17 36 22 14 16 14 15 29 35 26 26 23\n",
      " 15 14 22 21 14 22 34 22 29 16 16 14 16 34 17 29 17 14 14 21 16 34 14 14\n",
      " 16 14 13 30 23 21 14 16 22 17 27 35 35 22 21 31 16 34 14 26 26 17 14 15\n",
      " 15 23 15 23 35 15 34 28 17 14 17 30 29 22 14 14 13 28 16 16 16 16 16 14\n",
      " 27 35 30 20 34 14 35 35]\n",
      "pred:  [21 30 14 17 14 21 16 30 21 35 36 15 23 15 31 23 13 27 15 32 16 29 26 29\n",
      " 34 27 23 13 35 14 21 16 23 26 16 17 16 15 34 35 14 21 17 17 21 23 14 20\n",
      " 31 35 23 32 14 36 21 21 16 14 13 14 14 23 21 14 29 11 16 26 14 28 17 26\n",
      " 15 21 23 35 17 21 30 31 15 28 23 18 23 18 22 14 34 26 20 16 34 21 34 27\n",
      " 34 26 16 16 34 16 11 29 23 13 21 31 14 35 16 23 34 14 16 15 21 17 14 36\n",
      " 18 16 16 34 29 12 17 17]\n",
      "Epoch 12: Iteration 195: with minibatch training loss = 0.0454 and accuracy of 0.59\n",
      "pred:  [35 26 30 15 29 23 29 16 30 31 34 14 36 12 17 21 22 32 22 17 31 29 16 17\n",
      " 14 21 17 14 21 14 26 14 16 20 31 17 12 17 23 16 22 12 14 16 26 17 17 16\n",
      " 26 16 15 27 16 15 14 16 16 21 15 16 17 34 22 34 21 12 26 14 16 14 15 34\n",
      " 14 22 31 17 14 21 36 17 34 34 30 31 30 31 28 16 14 23 17 23 21 28 31 14\n",
      " 26 20 22 15 16 21 31 26 12 29 11 12 21 13 29 14 34 14 34 35 14 27 13 21\n",
      " 11 31 13 34 14 14 17 34]\n",
      "pred:  [16 22 31 21 13 16 30 17 16 12 32 21 17 35 34 18 17 17 30 15 21 26 15 17\n",
      " 15 23 17 26 20 17 25 22 14 23 17 26 23 15 14 14 17 17 17 28 25 22 30 17\n",
      " 16 23 20 35 34 22 14 17 23 14 36 20 23 23 29 11 23 14 18 17 20 17 27 36\n",
      " 17 17 14 14 16 15 35 17 15 23 26 17 23 35 21 11 13 15 17 16 31 16 21 18\n",
      " 16 17 21 17 18 27 22 12 22 23 16 16 16 21 30 11 14 26 23 30 17 20 17 16\n",
      " 34 17 21 16 35 14 14 34]\n",
      "pred:  [17 21 20 17 14 16 31 34 16 14 30 17 22 16 14 17 26 14 35 14 27 12 16 14\n",
      " 23 17 16 29 13 30 35 21 23 21 11 20 34 22 14 14 21 35 30 26 29 12 16 21\n",
      " 14 26 14 11 17 14 17 27 35 22 14 15 14 17 35 21 14 16 26 28 18 17 21 17\n",
      " 17 16 15 15 14 15 34 16 17 21 16 22 14 21 16 21 16 15 26 17 14 34 16 15\n",
      " 15 23 17 17 34 16 16 17 15 29 20 16 14 20 20 29 30 15 16 21 17 26 23 17\n",
      " 21 15 23 17 23 22 16 29]\n",
      "pred:  [15 34 17 21 15 23 16 31 36 14 16 15 17 14 17 27 31 23 17 13 35 20 28 12\n",
      " 15 23 31 16 34 34 35 21 15 29 34 15 21 16 18 17 29 26 35 23 17 16 13 20\n",
      " 21 34 16 36 23 35 14 14 14 29 17 21 14 15 36 17 30 23 15 31 21 14 31 29\n",
      " 21 16 16 21 26 17 36 22 31 14 36 15 23 15 15 30 12 13 23 26 16 21 17 15\n",
      " 30 13 29 12 14 17 22 14 15 34 31 15 35 36 29 26 29 12 29 30 21 30 34 15\n",
      " 22 15 26 15 17 23 14 15]\n",
      "pred:  [17 17 34 16 29 16 26 16 17 34 31 21 15 27 12 13 17 17 23 15 26 13 36 29\n",
      " 12 30 29 17 26 17 14 30 17 15 31 12 12 35 15 29 35 16 21 29 22 23 16 15\n",
      " 21 29 35 23 17 15 26 35 16 12 21 23 35 21 17 14 17 29 29 16 16 23 36 35\n",
      " 30 36 15 22 12 13 21 23 12 15 26 16 29 27 17 30 12 13 17 17 29 35 11 17\n",
      " 26 27 27 21 23 22 14 17 11 17 15 23 22 16 17 11 23 17 35 34 21 36 22 23\n",
      " 17 31 16 27 22 21 26 34]\n",
      "Epoch 12: Iteration 200: with minibatch training loss = 0.0442 and accuracy of 0.55\n",
      "pred:  [34 22 12 34 35 30 36 14 21 21 30 34 12 29 26 16 17 23 29 12 27 29 17 12\n",
      " 26 34 15 22 17 26 21 29 23 14 14 20 14 31 15 29 29 16 13 16 35 15 23 16\n",
      " 28 15 28 16 14 14 17 26 21 35 34 23 28 17 34 21 17 14 17 15 16 20 34 26\n",
      " 29 27 15 17 35 21 14 29 17 17 35 26 26 16 34 16 20 17 23 17 26 20 12 31\n",
      " 21 35 17 16 14 22 22 29 17 15 35 15 29 29 14 17 16 23 14 29 21 30 31 22\n",
      " 34 21 31 15 15 29 14 26]\n",
      "pred:  [29 22 14 16 14 13 26 31 26 36 29 26 21 14 14 14 14 21 23 27 15 21 21 26\n",
      " 16 17 21 29 15 29 35 15 14 34 17 29 14 22 34 35 20 17 14 30 34 31 36 28\n",
      " 13 13 14 35 21 15 26 29 29 31 23 29 36 12 14 21 21 30 34 15 31 15 21 17\n",
      " 17 15 15 29 12 14 15 26 26 31 16 35 17 29 13 12 30 15 16 20 29 34 21 14\n",
      " 27 31 35 14 21 15 15 16 21 12 15 29 22 29 35 27 32 32 29 14 26 15 15 26\n",
      " 15 17 29 35 29 26 26 13]\n",
      "pred:  [22 21 31 27 15 31 35 34 29 35 23 13 35 17 30 23 29 16 35 15 12 17 12 30\n",
      " 30 35 17 13 15 17 15 15 13 26 21 14 26 31 32 16 29 15 26 15 22 35 17 35\n",
      " 12 17 29 23 34 29 14 26 15 16 21 22 16 23 27 29 21 31 22 20 21 36 34 17\n",
      " 13 21 20 14 14 29 26 15 14 27 29 17 17 15 11 17 30 14 14 13 29 29 20 29\n",
      " 31 21 16 30 17 21 35 14 16 13 22 29 34 16 15 15 26 29 16 23 17 15 15 12\n",
      " 35 14 29 12 16 13 15 17]\n",
      "pred:  [28 35 29 14 29 14 34 29 29 14 21 35 14 15 15 17 15 23 35 13 15 34 21 21\n",
      " 15 14 26 16 27 12 34 29 35 21 14 35 22 35 31 21 23 15 16 13 14 16 16 16\n",
      " 35 12 27 22 14 15 13 28 21 29 17 12 26 15 21 13 15 21 14 15 21 35 21 14\n",
      " 23 26 17 16 22 21 22 17 13 13 15 29 14 21 27 21 15 34 30 16 15 14 12 36\n",
      " 14 13 17 22 26 23 14 12 34 21 17 29 26 20 15 16 32 23 16 15 26 11 26 20\n",
      " 15 13 15 14 17 29 26 29]\n",
      "pred:  [13 35 20 12 21 29 15 15 15 15 29 31 16 14 34 16 12 29 30 29 35 30 23 22\n",
      " 20 17 20 29 14 13 21 16 21 14 15 35 30 16 14 15 23 14 14 30 14 35 31 21\n",
      " 13 15 17 18 29 13 29 14 27 21 21 15 22 29 15 31 12 17 12 23 34 16 17 26\n",
      " 29 16 27 16 16 15 31 15 29 12 20 35 17 34 29 29 15 21 13 35 23 29 17 21\n",
      " 27 21 15 34 30 13 14 30 35 29 14 16 22 29 15 13 35 29 26 14 13 31 27 29\n",
      " 29 21 29 35 14 11 15 25]\n",
      "Epoch 12: Iteration 205: with minibatch training loss = 0.0423 and accuracy of 0.59\n",
      "pred:  [14 29 34 14 30 29 29 13 14 22 16 23 15 17 14 12 21 15 15 15 34 20 16 29\n",
      " 15 31 15 16 34 17 35 16 21 15 14 30 15 36 14 15 31 35 15 21 15 16 35 16\n",
      " 20 23 17 22 16 23 14 31 13 12 14 15 31 29 16 15 21 36 26 13 21 22 15 29\n",
      " 34 15 21 14 23 15 16 15 14 29 13 14 16 13 14 34 21 14 13 29 25 20 36 14\n",
      " 20 27 29 14 16 22 15 17 17 23 23 21 16 30 30 16 35 14 29 11 15 15 26 14\n",
      " 26 17 21 34 36 31 29 20]\n",
      "pred:  [15 14 22 21 22 30 21 14 28 21 23 11 14 35 13 16 15 13 17 21 21 26 20 14\n",
      " 35 16 21 22 21 15 16 14 14 23 21 21 35 15 36 15 17 22 27 26 34 30 30 21\n",
      " 15 29 20 15 14 13 14 35 21 16 15 13 35 14 21 16 14 21 23 14 15 15 27 14\n",
      " 14 27 26 31 15 16 35 27]\n",
      "Epoch 13 Overall loss = 0.0431 and accuracy of 0.587\n",
      "pred:  [21 12 31 17 35 14 16 14 15 22 15 31 23 35 29 30 30 30 35 30 21 13 34 23\n",
      " 13 16 15 22 13 16 15 29 29 15 13 31 15 13 15 31 21 14 18 16 14 14 14 35\n",
      " 13 35 23 16 35 11 30 34 15 14 16 34 34 23 15 14 15 14 35 35 27 15 15 15\n",
      " 15 21 14 15 15 21 31 14 16 36 35 15 16 16 16 17 22 17 35 14 16 34 16 23\n",
      " 14 35 22 23 15 14 20 14 34 35 22 16 14 14 14 20 21 23 14 16 21 21 16 21\n",
      " 13 18 35 14 23 17 22 35]\n",
      "pred:  [14 35 14 14 16 20 34 36 16 14 34 34 15 22 35 12 16 17 30 16 17 31 14 17\n",
      " 17 21 15 21 20 15 34 35 15 35 11 16 15 35 36 14 21 22 31 16 14 36 34 35\n",
      " 16 32 21 22 17 14 23 34 17 15 35 23 14 35 17 34 16 36 15 21 15 35 27 14\n",
      " 35 30 14 16 17 27 13 16 21 17 14 16 15 27 12 22 16 16 14 30 21 14 35 13\n",
      " 22 32 15 13 14 31 22 22 27 35 13 35 14 15 15 27 18 15 36 16 21 16 31 27\n",
      " 23 15 23 21 35 15 21 34]\n",
      "pred:  [21 15 35 26 34 29 14 14 22 21 16 17 12 36 15 16 35 26 31 15 27 29 13 31\n",
      " 21 35 16 34 12 31 14 31 31 35 35 15 27 30 22 11 13 15 14 29 21 30 36 21\n",
      " 15 14 20 21 14 22 34 22 15 17 31 29 16 34 17 29 17 14 14 21 16 21 14 14\n",
      " 16 14 13 26 21 21 14 29 14 13 21 35 35 16 21 31 16 34 14 35 36 17 14 15\n",
      " 15 23 15 23 35 15 34 28 17 14 17 36 29 21 14 14 14 15 14 16 16 27 16 15\n",
      " 27 35 30 21 34 12 35 31]\n",
      "Epoch 13: Iteration 210: with minibatch training loss = 0.04 and accuracy of 0.62\n",
      "pred:  [21 26 14 16 15 21 16 30 23 17 30 15 21 15 31 17 35 27 16 15 22 23 27 36\n",
      " 34 26 23 16 23 12 21 17 21 35 16 17 15 15 34 35 14 23 17 17 21 23 14 20\n",
      " 31 35 35 30 14 36 22 11 16 28 13 14 14 20 21 14 23 11 16 35 14 28 17 26\n",
      " 15 36 21 26 17 21 21 31 15 28 28 18 29 18 22 31 34 35 35 17 34 21 35 27\n",
      " 34 36 16 17 34 16 11 29 23 14 21 31 13 16 16 21 20 14 16 15 16 17 14 36\n",
      " 22 16 16 34 29 12 17 17]\n",
      "pred:  [35 36 30 15 29 35 16 23 14 30 34 14 31 17 17 21 22 34 16 17 16 17 23 17\n",
      " 14 18 17 14 21 16 35 14 23 22 31 17 13 34 23 16 21 12 13 16 20 17 14 16\n",
      " 26 14 15 27 16 14 14 15 22 21 15 16 14 34 21 34 21 12 26 14 31 13 31 34\n",
      " 22 29 31 17 15 17 36 17 34 34 36 31 21 31 15 16 14 36 17 35 21 29 31 14\n",
      " 35 21 22 15 16 12 31 21 11 29 12 12 12 34 29 14 34 14 34 35 14 23 14 21\n",
      " 17 28 14 34 14 14 17 34]\n",
      "pred:  [22 22 16 21 13 16 29 17 14 12 21 21 15 16 34 29 17 17 36 15 21 36 15 14\n",
      " 15 23 17 35 20 15 36 22 17 35 16 36 23 15 14 15 17 17 17 15 36 22 20 21\n",
      " 16 23 20 26 34 22 16 15 29 17 14 20 23 21 29 14 29 14 18 23 21 13 35 26\n",
      " 17 17 14 15 13 15 35 17 15 23 26 17 21 35 21 17 13 17 17 14 31 16 20 18\n",
      " 35 29 23 14 18 27 16 11 23 23 15 16 16 23 26 17 14 26 23 31 17 20 27 22\n",
      " 34 17 20 17 35 14 14 34]\n",
      "pred:  [21 21 20 15 14 16 31 34 35 14 26 17 22 17 14 29 26 17 16 14 20 12 16 14\n",
      " 23 17 22 29 11 26 26 21 23 23 11 22 34 22 17 11 23 35 30 26 29 11 22 23\n",
      " 35 31 35 12 11 14 17 26 35 22 14 15 13 17 35 21 16 16 26 31 26 17 21 17\n",
      " 29 29 15 15 14 16 34 16 16 16 16 22 14 17 16 21 23 15 20 17 13 34 35 15\n",
      " 15 35 17 17 34 16 16 15 15 29 21 16 14 20 29 29 31 16 16 21 17 26 35 17\n",
      " 21 15 23 11 14 22 16 22]\n",
      "pred:  [15 34 15 21 15 36 20 31 26 14 16 15 17 14 17 35 31 29 17 17 35 20 28 12\n",
      " 15 29 16 29 34 34 35 21 15 29 34 15 21 16 23 17 16 26 34 23 17 29 16 20\n",
      " 17 34 16 26 23 35 14 16 14 23 17 21 15 15 26 28 35 21 14 31 22 14 31 29\n",
      " 21 16 16 21 26 15 36 29 16 16 36 15 36 17 15 29 13 16 23 30 16 21 17 15\n",
      " 29 13 29 12 17 17 22 14 15 27 31 15 35 26 15 26 15 12 29 26 21 36 30 15\n",
      " 22 15 21 15 17 21 14 15]\n",
      "Epoch 13: Iteration 215: with minibatch training loss = 0.0367 and accuracy of 0.66\n",
      "pred:  [17 22 34 13 33 22 30 16 17 34 31 21 15 27 12 13 17 29 28 15 35 13 30 15\n",
      " 17 26 23 17 26 16 14 26 17 15 15 12 12 35 15 15 35 22 21 29 22 23 16 15\n",
      " 21 15 18 21 17 15 30 35 22 34 23 21 29 21 14 11 17 29 35 16 16 21 36 26\n",
      " 30 36 15 14 13 13 16 23 12 15 26 29 29 27 17 26 12 13 17 17 29 35 11 13\n",
      " 26 27 27 21 23 22 14 17 11 17 35 17 22 22 17 11 23 16 35 34 21 26 22 23\n",
      " 17 14 16 23 21 21 21 35]\n",
      "pred:  [34 22 13 34 16 30 36 14 14 21 26 27 12 29 26 29 17 29 23 12 17 29 26 12\n",
      " 26 34 15 21 17 26 21 29 23 14 16 21 14 29 15 29 29 35 13 16 35 15 23 16\n",
      " 32 17 17 18 13 17 27 26 35 35 34 23 28 16 34 21 17 14 17 15 16 34 34 26\n",
      " 29 29 15 16 34 21 14 16 34 17 35 35 30 22 34 17 16 14 23 17 30 20 12 16\n",
      " 21 35 17 16 14 22 22 29 16 15 35 16 29 29 17 14 16 16 11 22 21 31 31 16\n",
      " 34 21 31 16 15 29 17 26]\n",
      "pred:  [29 22 14 16 14 14 26 15 20 29 18 26 21 14 14 14 14 23 23 27 13 21 21 26\n",
      " 18 17 21 28 15 29 35 17 14 34 31 13 13 22 26 35 20 17 17 26 34 31 26 35\n",
      " 17 13 13 35 21 14 26 28 29 15 23 29 26 12 14 21 16 30 34 15 31 14 23 17\n",
      " 17 15 14 29 12 11 15 27 30 14 15 35 17 16 13 12 30 15 16 20 16 34 23 12\n",
      " 21 17 29 12 21 15 15 16 13 12 15 17 22 29 35 35 28 29 29 16 21 15 15 26\n",
      " 15 17 29 29 35 26 30 14]\n",
      "pred:  [21 12 15 17 15 31 35 34 29 35 23 14 15 17 30 23 16 17 18 15 12 17 13 31\n",
      " 30 35 17 14 34 27 14 15 16 26 21 14 35 31 13 16 29 15 35 15 22 35 17 35\n",
      " 13 17 29 21 34 35 14 30 15 16 21 22 16 23 27 16 23 31 29 20 21 36 34 17\n",
      " 13 21 20 14 14 28 26 13 14 17 29 17 16 13 13 17 26 14 13 35 29 23 20 29\n",
      " 15 21 16 30 16 21 30 15 16 13 22 35 34 16 15 15 35 29 16 23 17 15 13 11\n",
      " 23 14 29 13 16 12 34 17]\n",
      "pred:  [27 35 22 14 29 14 34 29 29 15 23 35 15 15 15 17 15 27 35 12 15 15 23 21\n",
      " 15 14 30 16 26 12 34 17 35 21 14 29 22 35 31 30 23 15 22 13 14 16 16 16\n",
      " 35 12 27 22 14 15 14 35 21 29 17 13 26 15 23 15 15 21 14 15 21 35 11 14\n",
      " 23 26 17 16 22 21 23 16 13 29 15 29 14 21 27 21 15 34 30 16 15 14 12 30\n",
      " 14 16 27 22 30 28 14 13 34 21 29 22 26 21 15 16 30 23 16 15 30 11 30 20\n",
      " 31 13 15 15 21 29 26 29]\n",
      "Epoch 13: Iteration 220: with minibatch training loss = 0.0369 and accuracy of 0.66\n",
      "pred:  [13 26 27 12 21 35 15 15 29 15 16 32 16 14 34 13 12 16 31 29 31 30 23 22\n",
      " 29 17 20 29 14 12 21 17 21 14 15 30 30 22 14 15 29 14 14 30 14 23 31 23\n",
      " 16 15 17 18 29 15 21 22 27 21 21 15 16 29 14 31 17 17 12 21 34 16 13 35\n",
      " 29 16 27 16 16 14 31 15 15 13 29 35 17 34 35 29 15 21 13 35 23 23 35 21\n",
      " 17 21 15 34 30 16 15 30 23 16 17 17 22 35 15 13 35 29 30 14 13 31 27 29\n",
      " 29 21 29 35 23 14 15 31]\n",
      "pred:  [13 29 35 14 30 29 31 13 30 22 16 23 15 17 13 12 21 15 15 15 34 29 29 23\n",
      " 17 31 15 16 30 17 35 16 21 15 23 30 15 30 14 11 31 23 32 21 15 16 35 29\n",
      " 21 23 17 22 13 23 14 17 14 13 16 15 31 23 16 15 21 36 26 13 14 21 15 31\n",
      " 34 15 21 14 23 15 27 14 14 29 14 14 16 13 34 34 21 14 35 29 30 20 35 14\n",
      " 20 27 35 14 16 22 15 17 13 23 29 23 29 35 36 16 29 14 29 12 21 14 35 13\n",
      " 26 16 21 14 36 16 16 20]\n",
      "pred:  [15 14 22 11 22 30 21 14 28 21 23 11 14 35 16 16 15 16 17 21 21 26 22 14\n",
      " 36 16 27 22 21 15 16 14 14 23 23 18 35 15 30 15 17 29 17 26 34 30 30 21\n",
      " 15 29 17 15 13 13 14 35 21 16 15 12 26 14 21 14 24 21 29 14 15 29 27 15\n",
      " 35 27 26 22 15 18 35 17]\n",
      "Epoch 14 Overall loss = 0.0384 and accuracy of 0.625\n",
      "pred:  [23 13 31 17 35 14 34 14 15 21 15 31 23 29 29 30 36 26 35 30 21 13 16 29\n",
      " 35 17 15 22 11 16 16 23 29 13 14 31 15 13 15 31 21 14 18 16 13 14 14 35\n",
      " 13 35 29 16 35 11 36 34 21 14 16 16 34 23 15 13 14 16 35 35 27 13 15 15\n",
      " 15 21 13 21 15 21 30 14 29 36 36 15 16 16 16 17 22 17 35 13 35 34 15 23\n",
      " 14 29 22 23 15 14 30 14 34 35 22 31 13 17 14 20 21 23 14 16 21 21 14 21\n",
      " 13 16 35 14 23 17 22 35]\n",
      "pred:  [14 35 14 21 36 20 34 36 16 14 32 34 15 22 26 13 36 11 30 16 15 31 14 17\n",
      " 17 21 15 21 20 15 34 35 15 29 12 15 15 35 36 14 27 22 31 27 14 30 34 35\n",
      " 16 20 21 22 17 14 23 34 16 15 26 32 14 23 17 34 20 30 15 21 15 30 17 14\n",
      " 35 30 15 29 17 27 13 16 21 27 29 16 15 27 11 22 16 21 14 30 22 14 35 11\n",
      " 22 21 15 13 14 31 20 16 16 26 14 34 14 15 14 27 18 35 30 17 21 16 14 27\n",
      " 23 15 21 21 29 14 21 15]\n",
      "Epoch 14: Iteration 225: with minibatch training loss = 0.0347 and accuracy of 0.69\n",
      "pred:  [21 15 34 26 34 36 14 14 16 21 16 17 12 25 15 21 35 35 16 15 27 29 14 16\n",
      " 21 35 16 34 12 31 14 31 31 16 31 15 27 30 22 11 16 15 16 29 35 35 26 21\n",
      " 15 14 21 23 14 22 34 16 29 27 31 27 16 34 17 16 27 14 14 21 16 21 16 12\n",
      " 15 14 13 30 23 23 14 28 36 16 21 29 35 22 21 15 16 34 14 26 30 17 14 15\n",
      " 14 23 21 23 32 15 15 28 17 14 17 30 35 21 14 14 14 29 16 16 17 27 18 29\n",
      " 27 35 30 21 34 12 35 35]\n",
      "pred:  [21 26 14 29 15 20 16 25 21 17 30 15 21 15 31 27 35 27 16 35 16 29 27 23\n",
      " 34 27 23 13 36 12 21 16 21 35 31 17 21 15 34 35 14 21 16 17 20 23 14 20\n",
      " 31 35 35 36 14 26 22 21 35 28 14 14 14 21 21 14 35 12 16 26 14 28 17 26\n",
      " 15 21 23 36 17 21 21 31 14 28 32 18 21 18 22 14 34 27 29 35 34 21 35 27\n",
      " 34 36 16 17 34 16 11 29 23 11 21 31 14 16 16 21 20 14 16 15 16 17 14 25\n",
      " 21 29 16 34 29 11 17 17]\n",
      "pred:  [26 25 35 15 29 18 29 31 35 36 34 14 36 12 17 30 16 34 22 17 31 16 14 17\n",
      " 14 16 14 14 21 16 26 14 23 21 31 17 12 34 23 14 29 12 13 16 20 17 14 16\n",
      " 26 17 15 27 16 14 14 15 22 21 15 16 14 34 22 35 22 11 26 14 31 14 32 34\n",
      " 16 29 31 17 14 21 25 16 34 34 36 31 36 31 31 17 14 36 17 35 21 29 34 14\n",
      " 26 20 22 15 13 11 31 26 11 29 12 12 21 34 29 14 29 14 34 35 14 27 14 21\n",
      " 11 28 13 34 14 11 17 34]\n",
      "pred:  [16 20 31 21 13 16 29 27 14 12 26 21 15 16 34 29 17 17 25 15 21 26 15 14\n",
      " 15 23 14 26 20 15 36 22 14 23 14 36 36 15 14 15 16 17 17 28 25 22 20 16\n",
      " 16 23 21 26 34 16 14 17 16 17 14 20 35 21 29 14 14 14 16 11 21 11 26 25\n",
      " 27 17 14 15 14 15 35 17 15 23 34 17 21 35 21 11 13 17 17 14 31 16 21 18\n",
      " 32 17 21 17 18 26 14 12 22 16 16 14 14 21 30 17 14 26 23 31 17 20 27 16\n",
      " 34 17 20 16 35 14 14 34]\n",
      "pred:  [17 21 20 17 14 16 28 34 16 14 26 17 22 17 14 15 26 14 29 14 26 12 13 14\n",
      " 23 15 22 16 13 36 29 23 23 23 11 21 34 22 14 21 21 35 32 36 29 12 16 22\n",
      " 34 36 14 12 11 14 14 26 35 22 14 15 14 15 35 21 16 15 26 28 26 17 23 14\n",
      " 16 21 15 15 14 15 34 18 27 16 16 22 14 27 16 21 35 15 34 17 34 34 35 15\n",
      " 15 35 17 17 34 16 16 29 15 23 21 16 14 21 29 29 31 15 16 21 16 26 35 17\n",
      " 21 15 23 17 29 22 16 20]\n",
      "Epoch 14: Iteration 230: with minibatch training loss = 0.037 and accuracy of 0.64\n",
      "pred:  [15 34 17 21 15 36 18 31 26 14 16 15 17 14 11 26 31 23 17 14 35 20 28 17\n",
      " 15 29 16 16 34 34 35 21 15 34 34 15 21 16 23 17 29 26 35 23 17 28 16 20\n",
      " 21 34 15 26 35 35 14 35 14 29 31 21 16 15 31 15 26 23 14 31 22 14 31 29\n",
      " 21 16 16 21 35 12 26 29 16 32 26 15 36 15 14 29 13 16 23 26 16 21 17 15\n",
      " 29 13 30 12 14 17 22 13 14 27 31 15 35 26 29 26 29 12 29 36 21 26 30 15\n",
      " 22 15 36 15 29 21 14 15]\n",
      "pred:  [27 16 34 13 35 16 25 16 17 34 31 21 34 27 13 13 17 17 23 15 26 16 36 15\n",
      " 12 26 29 17 23 22 14 26 17 15 15 12 12 35 15 15 34 22 21 29 22 26 16 15\n",
      " 21 15 17 21 34 15 26 35 22 34 21 21 29 21 14 11 17 16 35 16 16 21 31 35\n",
      " 32 36 15 16 12 13 16 23 12 15 26 29 20 27 13 26 12 13 17 17 17 35 11 17\n",
      " 17 17 27 21 23 22 14 17 11 17 34 21 22 22 17 11 29 16 35 34 21 26 22 23\n",
      " 17 23 16 27 21 21 30 35]\n",
      "pred:  [34 22 13 35 13 30 29 14 14 21 30 27 12 29 26 23 16 23 29 12 27 22 26 12\n",
      " 30 34 15 22 27 26 21 29 21 14 35 21 14 29 15 22 29 35 17 31 35 15 23 16\n",
      " 28 15 17 16 13 17 27 30 30 35 34 23 28 16 34 21 17 14 17 15 16 20 35 26\n",
      " 34 29 15 16 35 21 14 29 13 13 35 26 35 22 34 16 35 17 23 17 35 18 13 16\n",
      " 21 35 17 16 13 22 22 36 16 15 29 15 29 29 14 13 16 36 14 29 21 26 31 22\n",
      " 34 23 31 15 15 29 17 26]\n",
      "pred:  [29 22 14 16 31 13 26 15 21 29 18 30 21 14 14 14 13 23 23 27 13 21 21 26\n",
      " 18 17 21 29 15 20 35 15 13 34 16 30 15 22 26 34 20 17 13 30 12 31 26 28\n",
      " 17 13 13 35 30 15 30 29 29 15 23 29 26 12 14 21 21 30 34 15 31 17 21 17\n",
      " 16 15 14 30 12 11 15 27 35 31 16 35 17 21 13 13 30 15 16 20 16 34 23 11\n",
      " 21 16 29 13 21 15 15 16 13 12 12 29 22 29 35 26 28 32 29 14 26 15 15 26\n",
      " 15 17 29 35 31 26 26 13]\n",
      "pred:  [22 11 31 27 15 31 35 34 29 35 23 14 35 17 30 35 16 17 18 15 12 17 12 26\n",
      " 26 35 17 13 15 16 31 15 13 26 23 14 23 31 15 16 23 15 30 15 22 26 17 35\n",
      " 14 17 29 21 34 29 14 30 15 16 21 22 35 23 27 23 21 31 22 20 21 36 34 16\n",
      " 13 21 20 14 14 35 26 14 14 27 27 17 16 14 13 17 26 14 14 13 17 29 20 29\n",
      " 28 21 16 26 16 21 26 14 16 11 22 35 34 16 15 15 35 15 16 23 12 15 15 12\n",
      " 29 14 29 13 16 14 32 17]\n",
      "Epoch 14: Iteration 235: with minibatch training loss = 0.03 and accuracy of 0.73\n",
      "pred:  [27 35 22 14 29 14 34 29 29 15 23 35 14 15 15 17 15 22 35 12 15 15 23 22\n",
      " 15 14 30 16 35 12 34 16 35 21 14 35 22 35 31 30 23 15 22 13 13 16 16 16\n",
      " 35 12 27 22 14 15 13 28 21 30 17 12 26 17 23 14 15 21 14 15 21 14 11 14\n",
      " 23 27 17 16 16 21 14 16 13 13 15 29 14 29 27 21 16 34 30 16 16 14 12 30\n",
      " 14 16 27 22 30 28 14 11 34 21 35 22 26 20 15 29 32 23 16 15 30 13 26 20\n",
      " 31 11 15 15 21 16 26 29]\n",
      "pred:  [13 35 21 12 21 35 15 15 15 15 16 32 16 14 34 13 12 29 30 29 35 30 23 22\n",
      " 29 17 20 35 14 17 21 16 21 14 15 26 30 20 14 31 35 14 14 31 14 29 31 21\n",
      " 13 29 17 18 29 15 29 22 27 21 21 15 22 29 14 31 17 17 12 21 34 16 13 30\n",
      " 29 16 27 16 16 13 31 14 34 13 16 35 17 34 29 20 15 21 14 35 23 29 35 21\n",
      " 17 21 15 34 36 16 14 30 23 16 14 16 22 31 15 13 35 29 31 14 13 31 27 29\n",
      " 29 23 29 35 21 14 15 36]\n",
      "pred:  [14 29 34 14 30 29 29 13 30 16 16 23 15 17 13 12 21 15 14 15 34 33 18 29\n",
      " 17 31 15 15 30 17 29 16 21 15 21 30 15 36 14 11 31 23 16 21 15 14 35 29\n",
      " 30 23 16 22 13 21 14 17 14 12 21 15 31 29 16 15 21 36 35 13 21 21 15 31\n",
      " 34 15 21 14 23 15 17 14 14 18 13 14 16 13 34 34 21 14 29 29 30 20 26 12\n",
      " 20 27 13 14 29 16 15 17 16 16 36 23 16 26 30 16 35 14 29 11 24 14 26 16\n",
      " 34 17 21 14 36 31 16 20]\n",
      "pred:  [15 14 21 21 21 30 21 14 28 21 23 11 14 16 16 16 15 16 17 21 21 35 21 14\n",
      " 36 17 27 22 21 15 16 13 14 23 23 20 36 15 26 15 17 22 17 35 34 31 30 21\n",
      " 15 29 20 15 13 13 14 35 21 15 15 12 26 14 21 14 21 21 23 14 15 29 27 14\n",
      " 30 27 26 16 15 16 34 27]\n",
      "Epoch 15 Overall loss = 0.0334 and accuracy of 0.688\n",
      "pred:  [21 12 16 17 35 14 16 14 15 22 15 31 23 35 29 26 30 26 35 30 21 13 35 29\n",
      " 13 16 15 16 13 16 16 29 29 17 13 31 15 13 15 31 21 14 18 16 14 14 14 35\n",
      " 13 35 29 16 35 11 36 34 24 14 16 16 34 23 15 14 14 16 35 35 27 14 15 15\n",
      " 15 21 13 16 15 21 30 15 29 36 26 15 31 16 16 17 21 17 35 13 29 34 15 23\n",
      " 14 32 22 23 15 14 20 14 34 35 22 31 14 16 14 20 14 21 14 17 21 21 14 21\n",
      " 13 16 35 14 23 17 16 35]\n",
      "Epoch 15: Iteration 240: with minibatch training loss = 0.0289 and accuracy of 0.74\n",
      "pred:  [14 35 14 12 36 20 34 36 16 14 15 34 15 22 28 11 23 11 26 29 17 31 14 17\n",
      " 17 21 15 23 20 15 34 35 15 34 11 14 15 35 36 15 21 21 31 33 14 26 34 35\n",
      " 18 20 23 22 17 14 23 34 29 15 26 21 14 21 27 34 20 36 15 21 15 21 27 14\n",
      " 35 26 15 14 17 27 13 17 21 17 17 16 15 27 11 16 16 21 14 30 16 14 26 12\n",
      " 22 32 15 15 14 32 20 22 16 35 14 34 13 15 17 27 18 35 30 24 21 16 31 27\n",
      " 23 14 23 21 35 14 21 29]\n",
      "pred:  [21 15 34 26 34 36 14 14 16 21 16 17 12 36 15 16 35 35 16 15 27 29 15 31\n",
      " 21 35 16 34 12 31 14 31 31 17 31 15 27 26 22 11 16 15 16 30 21 30 35 21\n",
      " 15 14 20 23 16 22 34 22 29 29 17 28 16 34 17 29 27 14 14 21 17 21 16 14\n",
      " 15 14 13 36 23 23 14 32 20 16 27 35 23 22 29 28 16 34 14 35 30 17 11 15\n",
      " 15 23 15 29 32 15 15 28 17 16 17 30 29 21 14 17 14 31 16 16 16 27 35 29\n",
      " 27 35 36 21 34 12 35 23]\n",
      "pred:  [21 26 14 29 15 20 16 30 21 17 30 15 21 15 14 27 34 27 16 29 22 35 27 23\n",
      " 34 26 23 13 23 12 23 16 21 26 16 17 16 15 34 26 11 21 17 17 20 23 14 21\n",
      " 31 35 23 30 14 26 22 21 16 28 12 14 14 23 21 14 23 11 17 26 14 32 17 26\n",
      " 15 21 23 30 17 21 21 31 15 28 28 18 23 18 22 14 34 26 29 17 34 21 35 27\n",
      " 34 30 16 17 12 16 11 29 23 13 27 31 14 16 16 21 20 14 16 14 16 17 14 36\n",
      " 20 29 16 34 29 12 17 17]\n",
      "pred:  [26 30 30 15 29 27 16 15 35 30 34 14 26 12 17 21 14 35 22 17 31 17 14 17\n",
      " 14 20 17 17 21 16 35 14 29 20 31 17 12 34 23 16 29 12 13 16 26 17 14 16\n",
      " 26 16 15 27 16 13 14 15 22 21 15 16 14 34 22 35 22 12 26 14 31 14 32 34\n",
      " 22 29 31 17 15 21 36 16 34 34 30 28 30 31 28 29 14 35 17 35 21 27 31 13\n",
      " 26 20 22 15 16 12 31 26 13 29 12 12 21 34 29 14 34 14 34 35 14 27 14 21\n",
      " 11 32 13 34 14 11 17 34]\n",
      "pred:  [22 20 31 20 13 16 29 17 14 12 21 21 17 16 34 29 17 17 30 15 21 30 15 14\n",
      " 15 23 14 35 20 14 26 22 13 35 14 36 29 15 14 15 29 17 17 28 36 22 20 17\n",
      " 16 23 20 26 34 16 14 17 29 17 14 20 23 23 29 11 36 14 18 11 21 17 26 25\n",
      " 27 17 14 15 16 15 35 17 16 23 26 17 20 35 21 11 14 14 17 16 31 16 20 18\n",
      " 16 29 21 14 18 26 16 12 27 16 16 13 13 21 16 11 14 26 23 31 17 20 17 16\n",
      " 34 17 20 17 35 14 14 34]\n",
      "Epoch 15: Iteration 245: with minibatch training loss = 0.0345 and accuracy of 0.63\n",
      "pred:  [17 21 20 15 14 14 32 34 16 14 26 17 22 27 14 17 21 14 29 14 26 12 16 14\n",
      " 23 17 22 29 13 26 29 21 23 23 11 21 34 22 14 11 21 35 30 26 29 11 22 22\n",
      " 35 25 13 17 11 14 17 26 35 22 14 15 14 17 35 21 13 15 26 28 26 17 23 14\n",
      " 27 29 15 16 14 15 34 16 29 16 16 20 14 27 16 23 23 15 35 17 13 34 35 15\n",
      " 15 35 17 17 34 16 13 29 15 29 21 16 14 32 35 29 36 15 16 21 16 26 21 17\n",
      " 21 15 23 17 23 22 16 29]\n",
      "pred:  [15 34 15 21 15 36 20 31 30 14 16 15 17 14 17 35 31 23 17 14 35 20 28 12\n",
      " 15 23 16 16 34 34 35 21 15 32 34 15 21 16 23 17 23 26 34 23 17 29 16 20\n",
      " 21 34 15 26 35 35 14 29 14 29 17 21 14 15 36 17 35 21 15 31 22 14 31 29\n",
      " 21 16 16 21 26 14 36 21 16 29 36 15 36 15 14 23 13 13 23 35 17 23 17 15\n",
      " 29 13 21 12 14 17 22 14 14 27 16 15 35 26 29 26 29 12 29 26 21 26 34 15\n",
      " 21 15 26 15 17 21 14 15]\n",
      "pred:  [27 16 34 13 29 16 26 16 17 34 31 21 15 27 12 13 17 29 24 15 26 34 30 15\n",
      " 12 26 30 27 26 16 14 36 17 14 31 12 12 35 15 15 34 16 21 23 16 32 13 15\n",
      " 20 15 35 21 27 15 35 35 22 34 24 23 29 21 14 14 16 16 35 16 16 21 30 26\n",
      " 26 36 15 16 12 13 16 23 12 15 26 29 20 27 14 26 12 13 17 17 17 35 11 17\n",
      " 26 17 27 21 23 22 14 17 11 14 15 21 22 22 17 11 35 16 26 34 21 26 22 23\n",
      " 17 14 16 27 21 21 21 34]\n",
      "pred:  [34 22 13 29 16 31 36 14 23 21 30 27 12 30 26 16 16 26 22 12 27 29 26 12\n",
      " 36 34 15 16 29 26 21 29 21 14 13 21 15 29 15 26 29 29 14 31 35 15 35 16\n",
      " 28 14 29 16 14 14 27 21 30 35 34 23 15 16 34 21 17 14 17 15 16 20 34 30\n",
      " 29 35 15 16 13 21 14 29 15 17 35 35 30 16 34 16 18 17 23 17 35 18 12 16\n",
      " 21 35 17 16 14 22 22 23 29 15 29 16 29 29 14 14 16 36 14 22 21 31 31 16\n",
      " 34 21 31 15 15 29 13 30]\n",
      "pred:  [29 16 14 16 14 12 30 17 14 36 18 30 21 14 14 14 14 23 23 27 13 21 14 26\n",
      " 18 17 21 29 15 29 35 15 14 34 16 15 14 22 26 29 20 17 14 36 34 31 36 32\n",
      " 11 13 13 35 30 15 30 28 29 15 23 21 30 12 14 21 21 36 30 15 31 14 21 17\n",
      " 16 15 14 29 12 11 15 26 26 14 16 35 27 23 13 12 30 15 16 20 17 34 23 11\n",
      " 27 31 29 14 21 15 15 16 14 11 12 15 16 29 35 26 27 15 28 23 30 15 14 26\n",
      " 15 17 23 29 35 26 30 13]\n",
      "Epoch 15: Iteration 250: with minibatch training loss = 0.0297 and accuracy of 0.72\n",
      "pred:  [21 11 31 27 15 31 35 34 29 35 23 17 35 17 30 23 16 27 18 15 12 17 12 30\n",
      " 30 35 17 13 15 27 14 15 13 35 23 14 26 31 13 16 23 15 30 29 21 35 17 35\n",
      " 13 17 29 21 34 29 14 30 15 16 21 22 35 23 27 35 21 31 22 20 21 30 34 16\n",
      " 13 21 20 14 14 32 26 13 14 28 29 17 13 16 13 17 30 14 13 13 17 23 20 17\n",
      " 15 21 16 30 16 21 26 13 16 11 22 35 34 16 15 15 35 15 16 23 17 15 15 12\n",
      " 23 14 35 13 16 14 29 17]\n",
      "pred:  [27 35 22 13 17 14 34 22 29 15 23 35 14 15 15 17 15 23 35 12 15 15 23 21\n",
      " 15 14 30 16 27 12 34 34 35 21 13 29 22 35 31 36 23 15 22 13 17 16 16 16\n",
      " 35 12 27 22 13 15 16 28 21 29 17 13 26 17 23 14 15 21 14 15 21 16 11 14\n",
      " 23 27 17 16 16 21 14 16 14 13 15 29 14 29 27 21 16 34 36 16 16 14 12 36\n",
      " 13 16 28 22 30 28 14 13 34 21 35 22 26 20 15 35 21 23 16 15 30 11 26 20\n",
      " 31 13 15 15 21 22 30 22]\n",
      "pred:  [14 35 14 12 21 35 15 15 15 15 16 31 16 14 34 16 12 16 30 29 35 30 23 22\n",
      " 22 17 20 17 14 16 21 17 21 14 16 26 30 29 14 15 35 14 14 34 14 35 31 21\n",
      " 13 15 17 29 29 15 29 21 27 21 21 15 22 23 13 31 17 17 13 21 34 15 17 35\n",
      " 29 16 24 16 16 14 31 15 35 13 16 35 17 34 29 21 15 21 14 35 23 29 16 21\n",
      " 17 21 15 34 36 16 17 30 35 16 14 17 22 16 15 13 35 29 36 14 13 31 27 29\n",
      " 16 23 29 35 21 14 15 30]\n",
      "pred:  [14 29 35 14 30 29 29 13 30 22 16 23 15 17 13 15 21 15 29 15 34 35 18 23\n",
      " 13 31 15 17 29 17 35 16 21 15 21 30 15 36 14 15 31 23 15 21 15 16 26 32\n",
      " 29 23 17 22 13 23 14 17 14 12 21 15 31 29 16 15 22 36 26 13 21 21 15 31\n",
      " 34 15 21 13 23 15 27 14 14 20 13 14 16 13 12 34 21 14 16 15 36 18 26 13\n",
      " 20 27 29 14 17 22 15 17 13 22 29 23 29 35 30 16 35 14 29 11 21 11 35 13\n",
      " 27 17 21 12 36 31 16 20]\n",
      "pred:  [15 14 22 21 21 25 21 14 28 21 23 11 14 35 16 16 15 16 17 21 21 26 21 14\n",
      " 36 17 27 22 21 15 16 14 14 21 23 20 35 15 36 15 17 29 17 26 34 36 36 21\n",
      " 15 29 14 15 14 13 13 35 21 24 15 12 26 14 21 14 24 21 29 14 15 29 27 16\n",
      " 35 27 30 22 15 20 34 27]\n",
      "Epoch 15: Iteration 255: with minibatch training loss = 0.0213 and accuracy of 0.82\n",
      "Epoch 16 Overall loss = 0.0298 and accuracy of 0.733\n",
      "pred:  [23 12 16 17 35 14 16 14 15 22 15 31 23 29 17 36 36 25 35 30 22 11 16 23\n",
      " 14 16 15 22 12 16 15 23 29 17 13 31 15 13 15 15 21 14 18 16 14 14 14 35\n",
      " 13 31 29 16 35 11 36 34 21 14 16 16 34 29 15 14 14 13 29 35 27 14 15 15\n",
      " 15 21 14 15 16 21 30 17 29 36 35 15 16 16 16 17 22 17 35 13 35 34 15 23\n",
      " 14 34 22 23 15 14 29 14 34 26 16 31 14 16 14 20 21 23 14 17 21 21 14 21\n",
      " 13 16 35 14 23 17 16 35]\n",
      "pred:  [14 35 14 12 36 20 34 36 16 14 16 34 16 22 35 11 29 11 30 29 17 31 14 17\n",
      " 17 21 15 21 20 15 34 35 15 29 12 15 15 35 36 14 21 21 31 29 13 36 34 35\n",
      " 16 29 29 22 17 14 23 34 17 15 26 14 14 23 17 34 18 36 15 21 15 32 27 14\n",
      " 35 31 15 29 17 27 13 17 21 17 17 16 15 27 11 16 16 15 14 30 16 14 26 12\n",
      " 22 32 15 16 14 31 20 22 29 26 14 35 14 15 17 27 18 35 30 27 21 16 31 27\n",
      " 23 13 23 21 29 14 21 29]\n",
      "pred:  [21 15 34 26 34 36 14 14 16 21 16 17 12 36 15 16 35 26 16 15 27 29 13 31\n",
      " 21 35 16 34 14 31 17 31 31 16 31 15 27 36 16 21 13 15 13 29 21 35 35 21\n",
      " 15 15 20 23 16 16 34 22 29 17 31 28 16 34 17 29 17 14 14 21 17 21 14 17\n",
      " 15 14 13 36 23 23 14 32 20 16 27 23 29 22 21 28 16 34 14 35 30 17 11 15\n",
      " 15 23 15 23 32 15 15 28 17 14 17 30 29 21 15 14 14 29 16 16 17 27 35 17\n",
      " 27 36 30 21 34 12 35 23]\n",
      "pred:  [21 26 14 29 15 20 16 26 23 16 36 15 21 15 31 27 34 27 16 34 16 29 27 29\n",
      " 34 27 23 13 35 12 23 33 21 26 16 17 21 15 34 26 11 21 16 17 20 23 14 20\n",
      " 31 35 23 29 14 26 22 21 17 27 12 14 14 21 21 14 23 12 16 35 13 28 17 26\n",
      " 15 20 23 30 17 21 21 31 15 28 32 18 23 18 22 14 34 26 29 16 34 21 35 27\n",
      " 34 25 16 17 12 16 12 29 23 13 21 31 14 16 16 21 20 14 16 15 16 17 14 36\n",
      " 20 22 16 34 29 11 17 17]\n",
      "pred:  [26 36 30 15 29 18 27 31 26 36 34 14 31 12 17 21 16 35 22 17 31 17 14 17\n",
      " 14 20 14 14 21 16 20 14 29 29 31 17 12 27 21 16 23 12 13 16 26 17 14 16\n",
      " 26 16 15 27 16 13 14 15 22 21 15 16 17 34 22 35 21 11 26 14 16 14 28 34\n",
      " 14 29 31 17 31 21 36 16 34 34 26 31 30 31 28 17 14 35 17 35 21 28 31 14\n",
      " 35 20 21 15 13 12 31 26 11 29 12 12 21 34 30 14 29 14 34 35 14 27 17 21\n",
      " 11 32 13 34 14 13 17 34]\n",
      "Epoch 16: Iteration 260: with minibatch training loss = 0.027 and accuracy of 0.74\n",
      "pred:  [16 29 31 20 13 16 29 27 14 12 21 21 15 34 34 29 17 27 26 15 21 26 15 14\n",
      " 15 23 14 35 20 15 26 20 16 35 14 36 23 15 14 15 28 17 17 28 30 22 20 21\n",
      " 16 23 20 26 34 16 14 17 23 17 14 20 23 16 29 11 23 14 18 13 21 12 26 26\n",
      " 26 17 14 15 13 15 35 17 15 23 26 17 20 35 21 11 14 17 17 16 31 16 21 18\n",
      " 35 29 21 17 18 27 14 12 22 16 13 13 14 21 26 18 14 26 23 31 17 20 27 16\n",
      " 34 17 20 16 23 14 14 34]\n",
      "pred:  [17 21 20 15 14 35 31 34 18 14 26 17 20 29 14 15 26 14 35 14 34 12 16 14\n",
      " 23 14 22 23 13 26 29 23 23 23 11 20 34 22 14 11 21 35 30 36 29 12 16 22\n",
      " 35 31 35 12 13 14 17 35 35 22 14 15 12 17 35 21 13 15 35 28 26 17 23 14\n",
      " 27 23 15 16 14 15 34 16 29 16 16 20 14 27 16 23 29 16 35 17 34 35 35 15\n",
      " 15 35 17 17 34 16 16 27 15 23 21 16 14 21 29 29 26 15 16 21 31 35 23 17\n",
      " 21 15 23 11 29 22 16 29]\n",
      "pred:  [15 34 15 21 15 36 18 31 26 14 16 15 16 14 11 26 31 23 17 14 35 20 28 11\n",
      " 15 23 16 29 34 34 35 21 15 35 34 15 21 16 29 17 29 26 34 23 17 32 16 20\n",
      " 21 34 15 23 35 35 14 13 14 23 31 21 14 15 26 29 26 21 14 31 16 14 31 23\n",
      " 21 16 16 21 35 17 26 29 16 35 26 15 36 15 14 29 13 13 23 26 16 21 17 15\n",
      " 30 13 29 12 14 17 22 17 14 27 31 15 35 26 29 26 28 11 29 30 21 30 34 15\n",
      " 20 15 26 15 29 21 14 15]\n",
      "pred:  [27 16 34 13 35 16 26 16 17 34 31 21 34 27 13 13 17 28 23 15 26 13 30 15\n",
      " 12 26 29 27 26 16 14 26 17 15 15 12 12 35 15 34 34 16 21 29 16 23 13 15\n",
      " 21 15 35 21 27 15 30 35 22 34 24 21 29 21 14 11 16 16 35 15 16 21 31 26\n",
      " 30 36 15 16 13 13 16 23 13 15 26 29 29 27 14 30 12 13 17 17 29 35 11 14\n",
      " 26 35 27 21 23 22 14 17 11 11 35 21 22 22 17 11 29 16 35 34 21 26 22 23\n",
      " 17 14 16 28 21 22 30 35]\n",
      "pred:  [34 22 13 34 14 30 36 14 14 21 30 27 12 29 26 16 16 23 23 11 28 22 35 12\n",
      " 30 34 15 22 28 26 21 29 21 14 16 21 14 29 15 29 29 29 14 31 35 15 35 16\n",
      " 28 13 29 16 14 14 27 31 30 35 34 23 28 16 34 21 17 14 17 15 16 20 35 30\n",
      " 34 16 15 16 34 21 14 29 34 17 35 26 30 22 34 16 18 14 23 17 26 21 13 16\n",
      " 21 35 17 16 14 22 22 29 16 15 13 16 29 29 13 14 13 36 14 22 21 30 31 16\n",
      " 34 21 31 16 17 29 17 32]\n",
      "Epoch 16: Iteration 265: with minibatch training loss = 0.027 and accuracy of 0.77\n",
      "pred:  [28 16 14 16 14 13 30 17 14 36 18 30 21 14 14 14 14 23 23 27 13 21 14 27\n",
      " 18 17 21 29 15 29 35 15 13 34 16 32 13 22 26 32 20 17 13 30 12 31 32 33\n",
      " 11 13 14 35 30 15 30 29 29 15 23 29 30 12 14 23 21 30 34 15 31 14 21 17\n",
      " 16 15 14 29 12 11 15 26 35 31 16 35 17 22 13 12 30 15 16 20 16 34 23 11\n",
      " 21 31 29 12 21 15 15 16 14 12 12 29 22 30 35 34 28 29 29 14 30 15 15 26\n",
      " 15 17 23 35 32 26 30 14]\n",
      "pred:  [16 11 31 27 15 31 35 34 29 35 23 17 35 17 30 23 17 27 18 15 12 17 12 30\n",
      " 30 35 17 13 15 27 14 15 13 30 24 14 26 31 32 16 29 15 30 15 22 35 17 35\n",
      " 13 17 29 21 34 23 14 30 15 16 21 22 29 23 27 35 21 31 22 20 21 36 34 16\n",
      " 13 21 20 14 14 32 30 14 14 28 29 17 16 15 13 17 30 14 14 13 16 29 20 17\n",
      " 15 21 16 30 16 21 26 14 16 11 22 35 34 16 15 15 35 15 16 23 17 15 15 12\n",
      " 29 14 23 13 16 14 15 17]\n",
      "pred:  [27 35 22 14 17 14 34 29 29 15 23 35 14 15 15 17 15 22 35 12 15 15 23 22\n",
      " 15 14 26 16 26 13 34 33 35 21 14 35 22 35 31 30 23 15 22 14 14 16 16 16\n",
      " 35 12 27 22 14 15 13 23 21 30 17 13 35 17 23 17 15 21 14 15 21 16 11 14\n",
      " 23 26 17 16 16 21 14 16 17 13 15 29 14 30 27 21 16 34 15 16 16 14 12 30\n",
      " 13 16 28 22 30 28 14 12 34 21 29 22 26 20 15 16 32 23 16 15 30 11 26 20\n",
      " 31 12 15 15 28 16 30 29]\n",
      "pred:  [13 35 14 12 21 35 15 15 15 15 18 29 16 14 34 16 12 22 30 17 35 30 23 22\n",
      " 29 17 20 16 14 17 21 27 21 14 15 26 30 21 14 31 35 14 14 31 14 35 31 24\n",
      " 13 15 17 18 29 15 32 21 27 21 21 15 22 29 17 31 17 17 12 21 34 15 18 35\n",
      " 29 16 27 16 16 14 31 15 35 13 16 35 17 34 29 21 15 21 13 35 23 29 35 21\n",
      " 17 21 15 34 30 16 14 32 23 18 14 16 22 16 15 13 35 29 30 14 13 31 27 29\n",
      " 17 23 35 35 21 14 15 36]\n",
      "pred:  [14 36 34 14 30 29 29 13 30 22 16 23 15 17 13 12 21 15 32 15 34 14 18 29\n",
      " 17 31 15 15 30 17 35 16 21 15 21 30 15 30 14 11 31 29 15 21 15 14 35 32\n",
      " 32 23 16 22 29 23 14 17 14 12 21 15 31 29 16 15 21 36 26 13 21 21 15 31\n",
      " 34 15 21 14 23 15 27 14 14 20 13 14 16 13 12 34 21 14 32 29 32 20 26 13\n",
      " 20 27 29 13 16 16 15 17 16 22 23 23 29 35 26 16 35 14 29 11 23 11 35 13\n",
      " 27 17 21 12 36 31 17 20]\n",
      "Epoch 16: Iteration 270: with minibatch training loss = 0.0259 and accuracy of 0.82\n",
      "pred:  [15 14 22 21 22 36 21 14 28 21 23 11 14 35 16 16 15 16 17 21 21 26 21 14\n",
      " 36 17 27 22 21 15 16 14 14 23 23 21 35 15 36 15 17 29 17 26 35 31 30 21\n",
      " 15 29 14 15 13 13 13 35 21 24 15 12 26 14 21 14 23 21 23 14 15 29 27 17\n",
      " 35 27 26 22 15 18 34 27]\n",
      "Epoch 17 Overall loss = 0.0266 and accuracy of 0.78\n",
      "pred:  [21 12 31 17 35 14 16 14 15 21 15 31 23 29 17 26 30 36 35 30 22 12 17 29\n",
      " 13 16 15 22 12 16 16 29 29 17 17 31 15 13 15 31 21 14 18 16 14 14 14 35\n",
      " 13 23 16 16 35 11 36 34 23 14 16 16 34 23 15 14 14 13 29 35 27 14 15 15\n",
      " 15 21 14 15 15 21 30 17 29 36 26 15 31 15 16 17 22 17 35 12 29 34 15 23\n",
      " 14 29 22 23 15 17 29 14 34 35 16 31 14 16 16 20 14 23 14 16 21 21 14 21\n",
      " 13 16 28 14 23 27 16 35]\n",
      "pred:  [14 35 14 12 36 20 34 29 16 14 34 34 15 22 35 11 29 11 32 27 17 31 14 17\n",
      " 17 21 15 21 20 15 34 35 15 29 12 15 15 35 36 15 21 21 31 16 14 30 34 35\n",
      " 16 21 32 22 17 14 23 34 16 15 26 32 14 21 17 34 18 36 15 21 15 32 17 14\n",
      " 35 36 15 29 17 27 16 17 21 17 16 16 15 27 11 22 16 16 14 30 23 14 26 12\n",
      " 22 35 15 13 14 32 20 16 16 26 14 34 13 15 17 27 18 35 30 24 21 16 31 27\n",
      " 23 14 23 21 29 14 21 29]\n",
      "pred:  [21 15 34 26 34 35 14 14 18 21 16 17 12 30 15 16 35 35 16 15 27 29 14 31\n",
      " 21 35 16 34 12 31 14 31 31 16 31 15 27 36 22 11 13 15 14 29 21 26 35 21\n",
      " 15 15 22 23 16 22 34 22 29 16 16 29 16 34 17 29 17 14 14 21 16 21 14 11\n",
      " 16 14 13 30 23 23 14 32 20 16 21 29 23 22 21 28 16 34 14 35 30 17 11 14\n",
      " 15 23 15 18 29 15 15 28 17 16 17 36 29 21 14 17 14 29 16 16 17 24 18 29\n",
      " 27 35 36 21 34 12 35 35]\n",
      "pred:  [21 26 14 29 15 21 16 30 21 27 36 15 21 15 31 27 34 27 21 34 22 35 27 23\n",
      " 34 26 23 13 21 12 23 16 21 26 16 17 14 15 34 26 14 21 16 17 20 23 14 20\n",
      " 31 35 23 30 14 26 22 21 17 27 12 23 14 21 21 14 23 12 16 26 14 28 17 26\n",
      " 15 30 23 30 17 21 21 31 15 28 28 18 23 18 16 14 34 26 29 33 34 21 35 27\n",
      " 34 26 16 16 34 16 12 29 23 13 21 14 14 17 16 21 20 14 16 15 16 17 14 36\n",
      " 20 29 16 34 29 11 17 17]\n",
      "Epoch 17: Iteration 275: with minibatch training loss = 0.0255 and accuracy of 0.77\n",
      "pred:  [26 36 36 15 29 16 29 32 26 36 34 14 26 12 17 21 16 29 22 17 31 17 14 17\n",
      " 14 18 14 14 21 16 35 14 23 29 31 17 12 33 23 14 29 12 13 16 26 17 14 16\n",
      " 26 16 15 27 16 13 14 32 23 21 15 16 14 34 22 35 21 11 26 14 31 14 28 34\n",
      " 16 29 31 17 14 21 36 16 34 34 32 31 30 31 28 35 14 35 17 35 21 29 31 16\n",
      " 26 20 21 15 13 11 31 30 12 29 12 12 21 34 29 14 34 14 34 35 14 27 12 21\n",
      " 11 32 13 34 14 13 17 34]\n",
      "pred:  [16 29 31 21 13 22 29 27 14 12 30 21 15 35 34 29 17 27 36 15 21 25 15 14\n",
      " 15 23 14 35 20 29 14 22 14 29 14 36 23 15 14 15 29 17 17 28 25 22 33 17\n",
      " 16 23 20 35 34 16 14 17 23 17 14 20 23 21 29 11 23 14 18 18 21 12 26 26\n",
      " 26 17 14 15 13 15 35 17 15 23 26 17 20 35 21 11 13 17 17 16 31 16 20 18\n",
      " 34 29 21 14 18 27 16 12 22 16 16 13 16 21 32 11 14 26 23 31 17 20 27 16\n",
      " 34 17 20 17 35 14 14 34]\n",
      "pred:  [17 21 20 15 14 35 32 34 18 14 25 17 22 29 14 29 26 14 34 14 20 12 14 14\n",
      " 23 14 22 29 13 26 29 21 23 23 11 29 34 22 14 11 21 35 30 26 29 12 16 22\n",
      " 35 26 29 12 11 14 17 35 35 16 14 15 12 17 35 21 13 15 26 28 26 17 23 14\n",
      " 27 16 15 16 14 15 34 16 17 16 16 22 14 21 16 23 23 16 26 17 35 34 35 15\n",
      " 15 29 17 17 34 16 16 29 15 29 21 16 14 20 35 29 36 15 16 21 31 26 20 17\n",
      " 21 16 23 11 23 22 16 29]\n",
      "pred:  [15 34 13 21 15 36 20 31 31 14 16 15 16 14 11 35 31 23 17 14 35 20 28 11\n",
      " 15 23 16 16 34 34 35 21 15 34 34 15 21 16 23 17 29 26 35 23 17 32 16 20\n",
      " 21 34 15 35 35 35 14 29 13 23 16 21 15 15 30 29 26 21 15 31 16 14 16 23\n",
      " 21 16 16 20 26 12 26 20 16 13 36 15 36 15 14 29 13 13 23 26 16 23 17 15\n",
      " 29 13 29 12 14 14 22 14 14 26 16 15 35 26 29 26 29 11 29 30 21 36 31 15\n",
      " 22 15 26 15 29 21 14 15]\n",
      "pred:  [24 22 34 13 35 15 31 16 17 34 31 21 34 27 12 13 17 29 23 15 26 34 30 15\n",
      " 12 26 29 27 35 16 14 26 17 15 31 12 12 35 15 29 34 22 21 29 16 31 13 15\n",
      " 21 15 35 21 27 16 30 35 22 34 24 21 35 21 14 11 17 16 35 15 16 21 30 35\n",
      " 30 36 15 16 14 13 16 23 12 15 26 29 22 27 14 30 12 13 17 17 28 35 11 13\n",
      " 17 17 27 21 23 22 14 17 11 11 35 21 22 22 17 11 35 16 26 34 21 31 22 23\n",
      " 17 14 16 27 21 21 30 34]\n",
      "Epoch 17: Iteration 280: with minibatch training loss = 0.0208 and accuracy of 0.82\n",
      "pred:  [34 22 13 34 13 31 36 14 14 21 26 27 12 23 26 16 16 23 22 11 27 22 26 12\n",
      " 30 34 15 21 29 26 21 29 21 14 13 21 14 29 15 29 29 35 17 16 35 34 35 16\n",
      " 28 13 17 16 13 14 27 25 30 35 34 23 28 16 34 21 17 14 17 15 16 20 35 26\n",
      " 29 35 15 16 13 21 14 22 15 17 35 35 30 22 34 16 18 14 23 17 35 18 13 16\n",
      " 21 35 17 16 14 22 22 36 16 15 34 16 29 23 14 14 16 36 13 22 21 30 31 16\n",
      " 34 21 31 16 15 29 13 26]\n",
      "pred:  [29 16 14 13 14 13 26 17 14 36 18 30 21 14 14 14 14 23 23 27 13 21 16 26\n",
      " 18 17 21 29 15 29 35 15 13 34 16 32 14 22 26 29 20 17 13 30 12 31 26 27\n",
      " 11 13 13 35 20 15 30 29 29 15 23 32 30 11 14 21 21 30 34 15 31 14 21 17\n",
      " 16 15 14 29 11 14 15 26 21 14 16 35 27 16 13 34 30 15 16 20 16 34 23 11\n",
      " 21 31 35 13 21 15 15 16 14 11 12 17 22 29 35 26 28 32 15 14 32 15 15 26\n",
      " 15 17 23 34 35 26 30 14]\n",
      "pred:  [22 11 31 27 15 31 35 34 29 35 23 14 35 17 30 35 16 27 18 15 12 17 12 30\n",
      " 26 35 17 13 15 27 14 15 13 26 24 14 26 31 34 16 23 15 30 15 22 35 17 35\n",
      " 13 17 29 21 34 23 14 30 15 16 21 22 17 23 27 35 21 31 22 20 21 36 34 16\n",
      " 13 21 20 14 14 32 30 14 14 28 28 17 16 13 13 17 30 14 13 13 16 29 20 17\n",
      " 15 21 16 26 16 21 26 13 16 11 22 35 34 16 15 15 35 15 16 23 17 15 16 12\n",
      " 31 14 29 13 16 14 32 17]\n",
      "pred:  [27 35 33 13 17 14 34 29 17 15 23 35 14 15 15 17 15 22 35 12 15 15 23 21\n",
      " 15 14 30 16 17 12 34 17 35 21 14 35 22 35 31 36 23 15 22 14 17 16 16 16\n",
      " 35 12 27 22 14 15 13 28 21 30 17 13 35 17 23 17 15 21 14 15 21 16 11 14\n",
      " 23 27 17 16 16 21 14 16 13 13 15 20 14 30 27 21 16 34 30 16 15 14 12 30\n",
      " 14 16 27 22 30 28 14 11 34 21 29 22 26 20 15 16 21 23 16 15 30 11 26 20\n",
      " 31 11 15 15 21 16 30 20]\n",
      "pred:  [13 35 14 12 21 35 15 15 15 15 29 32 16 14 34 16 12 16 30 17 35 30 23 16\n",
      " 20 17 20 17 14 13 21 21 21 14 15 26 30 20 14 31 28 14 13 30 13 16 31 24\n",
      " 13 15 17 18 29 15 21 21 27 21 21 15 16 23 17 31 11 17 13 21 34 16 17 35\n",
      " 16 16 27 16 16 14 31 15 35 13 16 35 17 34 29 21 15 21 13 35 23 29 35 21\n",
      " 17 21 15 34 26 17 14 30 35 18 14 16 22 16 15 13 35 29 26 14 13 31 27 29\n",
      " 17 23 35 35 21 14 15 36]\n",
      "Epoch 17: Iteration 285: with minibatch training loss = 0.0227 and accuracy of 0.82\n",
      "pred:  [14 29 34 14 30 29 29 13 30 22 16 23 15 17 13 12 21 15 32 15 34 33 18 29\n",
      " 14 31 15 17 30 17 32 16 21 15 21 30 15 36 14 11 31 23 30 21 15 16 35 32\n",
      " 21 23 16 22 29 23 14 17 14 12 21 15 31 29 16 15 22 36 35 13 21 21 15 31\n",
      " 34 15 21 13 23 15 27 15 14 29 16 14 16 13 34 34 21 14 29 29 30 20 26 14\n",
      " 20 27 29 14 16 16 15 17 17 22 29 23 16 35 26 16 35 14 29 11 24 11 26 17\n",
      " 27 17 21 12 36 31 16 20]\n",
      "pred:  [15 14 22 21 21 30 21 14 28 21 23 11 14 35 16 16 15 16 17 21 21 26 21 14\n",
      " 36 17 27 22 21 15 16 14 14 23 23 20 35 15 30 15 17 20 17 26 34 30 30 21\n",
      " 15 29 14 15 14 13 15 35 21 27 15 12 26 14 21 14 24 21 29 14 15 29 27 14\n",
      " 35 27 26 16 15 18 34 27]\n",
      "Epoch 18 Overall loss = 0.0233 and accuracy of 0.808\n",
      "pred:  [23 12 16 17 35 14 17 14 15 22 15 31 23 35 29 31 30 26 23 30 22 18 16 29\n",
      " 16 16 15 22 11 16 15 29 29 17 17 31 15 13 15 31 21 14 18 16 14 14 14 35\n",
      " 13 31 23 16 35 11 30 34 21 14 16 16 34 23 15 14 14 13 29 35 27 14 15 15\n",
      " 15 21 14 15 15 21 30 17 29 36 26 15 31 16 16 17 22 17 14 17 32 34 15 23\n",
      " 14 13 22 23 15 17 20 14 34 27 22 31 14 16 13 20 14 23 14 17 21 21 14 21\n",
      " 13 16 35 14 23 27 16 35]\n",
      "pred:  [14 35 16 12 36 20 34 36 16 32 33 34 15 16 35 11 29 11 26 29 17 31 14 17\n",
      " 17 21 15 21 20 15 34 35 15 29 12 15 15 35 36 15 21 21 31 33 14 30 34 35\n",
      " 16 29 21 22 17 14 23 34 28 15 26 32 14 23 17 34 18 30 15 21 15 32 27 14\n",
      " 35 36 15 29 17 27 13 17 21 17 17 16 15 27 11 16 16 15 14 30 16 14 26 12\n",
      " 22 32 15 16 14 31 20 16 16 26 14 34 13 15 15 27 18 34 30 24 21 16 31 27\n",
      " 23 14 23 21 29 14 21 29]\n",
      "pred:  [21 15 35 26 34 29 14 14 18 21 16 17 12 30 15 16 35 26 16 15 28 29 14 31\n",
      " 21 35 16 34 12 31 17 31 31 17 31 15 27 36 22 11 13 15 16 29 21 35 35 21\n",
      " 15 15 22 23 16 22 34 22 29 17 31 29 16 34 17 29 17 14 14 21 17 21 13 11\n",
      " 15 14 13 30 23 23 14 28 20 16 27 29 23 16 21 31 16 34 14 35 30 17 11 15\n",
      " 15 23 15 23 32 15 15 28 17 14 17 30 29 21 14 14 14 29 16 15 17 27 35 29\n",
      " 26 35 30 21 34 12 35 23]\n",
      "Epoch 18: Iteration 290: with minibatch training loss = 0.0194 and accuracy of 0.87\n",
      "pred:  [21 26 14 29 15 21 16 25 23 35 30 15 21 15 31 27 29 27 16 29 16 29 27 23\n",
      " 34 26 23 13 21 12 21 16 21 26 16 16 16 15 34 26 11 21 16 17 20 23 14 20\n",
      " 31 35 23 29 14 30 22 21 17 27 12 23 14 20 21 14 29 12 16 35 14 28 17 26\n",
      " 15 21 23 30 17 21 21 31 15 28 28 18 23 18 22 14 34 26 29 16 34 21 35 27\n",
      " 34 26 16 17 12 16 12 29 23 14 21 31 11 35 16 21 20 14 16 15 16 17 14 36\n",
      " 20 29 16 34 29 11 17 17]\n",
      "pred:  [26 36 30 15 29 35 17 32 35 30 34 14 36 12 17 21 16 35 22 17 31 16 14 17\n",
      " 14 18 17 14 21 16 26 14 23 29 31 17 12 27 23 16 29 12 14 16 26 17 14 16\n",
      " 26 16 15 27 16 13 14 15 22 21 15 16 14 34 22 35 21 11 26 14 31 14 32 34\n",
      " 16 29 31 17 15 21 30 17 34 34 26 31 30 31 32 16 14 36 17 35 21 29 30 14\n",
      " 26 20 22 15 13 12 31 35 11 29 12 12 21 34 29 14 34 14 34 35 14 27 14 21\n",
      " 11 32 13 34 14 14 17 34]\n",
      "pred:  [22 29 23 20 13 21 29 27 17 12 21 21 16 35 34 29 17 17 26 14 21 36 15 14\n",
      " 15 23 14 35 20 15 25 22 13 29 14 30 23 15 14 15 29 17 17 28 36 22 20 21\n",
      " 16 23 20 35 34 16 14 15 23 14 14 20 23 21 29 11 23 14 18 18 21 12 27 26\n",
      " 27 17 14 15 13 15 35 17 16 23 26 17 20 35 21 11 13 17 17 16 31 16 21 18\n",
      " 34 28 21 14 18 27 22 12 22 16 13 16 13 21 26 18 14 26 23 31 17 20 27 16\n",
      " 34 17 20 16 35 14 14 34]\n",
      "pred:  [17 21 20 15 14 35 32 34 16 14 36 17 22 17 14 29 26 14 34 14 34 12 16 13\n",
      " 23 15 22 29 13 26 29 21 21 23 11 20 34 22 14 11 21 35 30 26 29 12 16 22\n",
      " 35 36 29 12 11 14 17 35 35 22 14 15 12 15 35 21 13 15 26 28 35 17 23 14\n",
      " 27 23 15 16 14 15 34 16 29 16 16 22 14 21 16 24 35 15 34 17 29 35 35 15\n",
      " 15 35 13 17 34 16 16 29 15 29 21 16 16 32 29 29 26 15 16 21 31 26 35 17\n",
      " 21 15 23 11 23 22 16 29]\n",
      "pred:  [15 34 15 21 15 36 20 31 26 14 16 15 16 14 11 35 31 23 17 14 35 20 28 12\n",
      " 15 23 16 16 34 34 35 21 15 29 34 15 21 16 21 17 18 26 34 23 17 23 16 20\n",
      " 21 34 15 35 35 35 14 32 13 29 31 21 14 15 36 29 26 21 15 31 16 14 31 29\n",
      " 21 16 16 21 35 12 36 20 16 32 21 15 36 15 14 29 13 13 23 26 16 23 17 15\n",
      " 34 13 29 12 14 14 22 14 14 27 16 15 35 26 29 26 29 12 29 30 21 25 30 15\n",
      " 20 15 32 15 29 21 14 15]\n",
      "Epoch 18: Iteration 295: with minibatch training loss = 0.02 and accuracy of 0.83\n",
      "pred:  [27 16 34 13 35 16 31 16 17 34 31 21 16 27 13 13 17 29 23 15 26 29 26 15\n",
      " 12 26 23 27 26 16 14 26 17 15 31 12 12 35 15 29 34 16 21 29 16 31 13 15\n",
      " 21 15 35 21 27 15 30 35 22 34 24 21 34 21 14 11 16 16 35 15 16 21 36 26\n",
      " 30 36 15 16 13 13 16 23 12 15 26 29 29 27 14 26 12 13 17 17 29 35 11 14\n",
      " 35 28 27 21 23 22 14 17 11 11 35 21 22 22 17 11 29 16 35 34 21 31 22 23\n",
      " 17 14 16 27 21 21 30 29]\n",
      "pred:  [34 22 13 34 13 26 36 14 14 21 30 27 12 29 26 16 16 23 23 11 35 29 20 12\n",
      " 30 34 15 22 29 35 21 29 21 14 13 22 14 29 15 29 29 35 13 16 35 32 35 16\n",
      " 32 13 29 16 13 13 27 26 30 35 34 23 28 16 34 21 17 14 17 15 16 21 34 25\n",
      " 33 35 15 16 34 21 14 29 32 17 35 26 30 22 34 16 18 14 23 17 32 18 12 16\n",
      " 21 35 17 16 13 22 22 36 16 15 29 15 29 29 13 14 16 29 13 22 21 36 31 16\n",
      " 34 21 31 16 15 29 17 21]\n",
      "pred:  [29 22 14 16 14 13 32 17 14 36 18 30 21 14 14 14 17 23 23 27 13 21 14 27\n",
      " 18 17 21 28 15 29 35 15 13 34 16 15 14 22 26 32 20 17 13 36 12 31 26 33\n",
      " 11 13 14 35 36 15 30 29 29 15 23 32 26 11 14 21 21 30 34 15 31 11 21 17\n",
      " 16 15 14 29 12 11 15 26 35 14 16 35 17 16 13 13 30 15 16 20 16 34 23 11\n",
      " 21 17 29 13 21 15 15 16 14 11 12 17 16 30 35 26 32 29 28 14 32 15 15 26\n",
      " 15 17 23 35 35 26 30 14]\n",
      "pred:  [22 11 31 27 15 31 35 34 29 35 23 14 35 17 30 35 16 17 18 15 12 17 12 30\n",
      " 30 35 17 13 15 27 14 15 13 35 24 14 35 31 35 16 29 15 30 29 22 35 17 35\n",
      " 13 17 29 21 34 23 14 30 15 16 21 22 17 23 26 29 21 31 22 20 21 36 34 16\n",
      " 13 21 20 14 14 32 26 17 14 27 28 17 13 13 13 17 30 14 13 13 16 29 20 17\n",
      " 15 21 16 32 16 21 26 14 16 11 22 35 34 16 15 15 35 32 16 23 17 15 16 12\n",
      " 29 14 23 13 16 14 13 17]\n",
      "pred:  [27 35 33 14 17 14 34 29 17 15 23 35 14 15 15 17 15 21 35 12 15 15 23 21\n",
      " 15 14 26 16 35 13 34 33 35 21 14 35 22 35 31 30 23 15 22 14 14 16 22 16\n",
      " 35 12 27 22 14 15 14 28 21 29 17 13 28 17 23 14 15 21 14 15 21 16 11 14\n",
      " 23 27 17 16 16 21 14 16 14 13 15 29 14 30 27 21 16 34 36 16 16 14 13 30\n",
      " 14 16 28 22 30 28 14 11 34 21 35 21 26 20 15 16 21 23 16 15 30 11 26 20\n",
      " 31 11 15 15 28 22 32 29]\n",
      "Epoch 18: Iteration 300: with minibatch training loss = 0.0207 and accuracy of 0.82\n",
      "pred:  [13 26 14 12 21 35 15 15 15 15 16 31 16 14 34 16 12 16 30 17 35 30 23 16\n",
      " 22 17 20 17 14 17 21 21 21 14 16 26 30 20 14 23 23 14 14 30 14 35 31 24\n",
      " 13 15 17 18 29 15 21 21 27 21 21 15 16 23 17 31 17 17 13 21 34 16 18 35\n",
      " 35 16 28 16 16 14 31 15 34 13 16 35 17 34 36 21 15 21 13 35 23 29 35 21\n",
      " 17 21 15 34 30 16 14 26 35 16 13 16 22 16 15 13 35 29 30 14 13 31 27 29\n",
      " 17 23 35 26 21 14 15 30]\n",
      "pred:  [14 29 34 14 36 29 29 13 30 22 16 23 15 17 13 12 21 15 15 15 34 29 18 23\n",
      " 14 31 15 17 30 17 35 16 21 15 21 29 15 30 14 11 31 23 15 21 15 16 35 15\n",
      " 32 23 16 22 29 23 14 17 14 12 21 15 31 29 16 15 21 36 26 13 21 21 15 31\n",
      " 34 15 21 17 23 15 27 14 14 20 13 14 16 13 12 34 21 14 34 29 26 20 26 13\n",
      " 20 27 29 14 16 16 15 17 16 22 23 23 16 30 30 16 35 14 36 11 24 11 26 13\n",
      " 27 17 21 12 36 31 33 20]\n",
      "pred:  [15 14 21 21 21 26 21 14 28 21 23 11 14 35 16 16 15 16 17 21 21 26 22 14\n",
      " 35 17 27 22 21 15 16 14 14 23 23 20 35 15 30 15 17 22 17 26 35 30 30 21\n",
      " 15 29 14 15 14 13 15 35 21 15 15 11 26 14 21 14 23 21 23 14 15 29 27 15\n",
      " 35 27 26 16 15 18 34 27]\n",
      "Epoch 19 Overall loss = 0.0206 and accuracy of 0.833\n",
      "pred:  [23 12 16 17 35 14 16 14 15 22 15 31 23 29 17 30 30 26 23 36 23 11 17 20\n",
      " 13 16 15 22 11 16 16 29 29 17 14 31 15 13 15 31 21 14 18 16 14 14 14 35\n",
      " 13 31 23 16 35 11 30 35 23 14 16 16 34 23 15 14 14 13 35 35 27 14 15 15\n",
      " 15 21 14 16 15 21 30 17 29 36 26 15 31 16 16 17 22 17 35 17 32 34 15 23\n",
      " 14 32 22 23 15 17 21 14 34 35 22 31 14 16 14 20 14 23 14 17 21 21 14 21\n",
      " 13 16 35 14 23 27 16 35]\n",
      "pred:  [14 35 14 12 36 20 34 36 16 14 34 34 15 22 35 11 29 11 26 29 17 31 14 17\n",
      " 17 21 15 21 20 15 34 35 15 29 12 15 15 35 36 15 21 21 31 33 17 30 34 35\n",
      " 16 21 21 22 17 14 23 34 17 15 35 32 14 14 17 34 18 36 15 21 15 32 27 14\n",
      " 35 31 15 29 17 27 13 17 21 17 17 16 15 27 11 16 16 16 14 30 16 14 26 12\n",
      " 22 32 15 13 14 31 20 16 16 26 14 14 13 15 17 27 18 34 30 15 21 16 31 27\n",
      " 23 14 23 21 29 14 21 29]\n",
      "Epoch 19: Iteration 305: with minibatch training loss = 0.0183 and accuracy of 0.87\n",
      "pred:  [21 15 34 26 34 29 14 14 18 21 16 16 12 36 15 16 35 26 16 15 28 29 14 31\n",
      " 21 35 16 34 12 31 17 31 31 17 31 15 27 30 22 11 13 15 16 29 21 35 35 21\n",
      " 15 14 29 23 16 22 34 22 29 17 31 29 16 34 17 29 27 14 14 21 17 21 13 11\n",
      " 16 14 13 30 23 23 14 28 20 16 27 29 23 22 20 28 18 34 14 35 30 17 11 15\n",
      " 14 23 15 23 29 15 15 28 17 14 17 36 29 21 14 17 14 27 16 16 17 24 18 29\n",
      " 26 35 30 21 34 12 35 23]\n",
      "pred:  [21 26 14 29 15 20 16 30 22 17 36 15 21 15 31 27 29 27 15 29 16 29 27 29\n",
      " 34 26 23 13 21 12 24 16 21 26 16 17 15 15 34 26 11 21 17 17 20 23 14 20\n",
      " 31 35 23 29 14 26 22 21 17 27 12 14 14 21 21 14 29 12 16 26 14 28 17 26\n",
      " 15 30 23 30 17 21 21 31 15 28 32 18 29 18 22 14 34 26 29 16 34 21 35 27\n",
      " 34 26 16 17 14 16 12 29 23 13 21 31 14 17 16 21 20 14 16 15 16 17 14 26\n",
      " 20 29 16 34 29 11 17 17]\n",
      "pred:  [26 26 30 15 29 16 17 32 35 36 34 14 26 12 17 21 16 32 22 17 31 17 14 17\n",
      " 14 18 14 14 21 16 35 14 20 29 31 17 12 27 23 22 30 12 13 16 26 17 14 16\n",
      " 26 16 15 27 16 13 14 15 22 21 15 16 14 34 22 35 21 12 26 14 31 14 32 34\n",
      " 16 29 31 17 15 21 36 17 34 34 26 31 30 31 32 16 14 29 16 35 21 28 31 16\n",
      " 35 20 22 15 13 11 31 35 11 29 12 12 21 34 29 14 33 14 34 35 14 27 17 21\n",
      " 11 32 13 34 14 13 17 34]\n",
      "pred:  [16 29 32 30 13 16 29 27 17 12 21 21 16 17 34 29 17 27 26 15 21 36 15 14\n",
      " 15 23 13 34 20 13 36 22 13 29 13 36 23 15 14 15 29 17 17 28 30 22 33 17\n",
      " 16 23 20 26 34 22 14 16 23 17 14 20 23 21 29 11 23 14 18 18 21 12 26 26\n",
      " 26 17 14 15 13 15 35 17 15 23 26 17 33 35 21 11 13 16 17 14 31 16 21 18\n",
      " 34 29 21 14 18 26 14 12 21 16 16 13 13 21 26 18 14 26 23 31 17 20 21 16\n",
      " 34 16 20 16 35 14 14 34]\n",
      "pred:  [17 21 20 15 14 34 32 34 16 14 36 17 22 29 14 29 26 14 35 14 34 12 13 14\n",
      " 23 14 22 29 13 36 29 21 23 23 11 29 34 22 14 11 21 35 32 26 29 12 16 22\n",
      " 35 26 29 12 11 14 17 35 35 22 14 15 12 17 35 21 13 15 26 28 26 17 23 14\n",
      " 27 29 15 16 14 15 34 16 28 16 16 22 14 21 16 23 23 15 35 17 29 34 35 15\n",
      " 15 35 13 17 34 16 16 29 15 29 21 16 14 32 29 29 26 15 16 21 31 26 21 17\n",
      " 21 15 23 17 23 22 16 29]\n",
      "Epoch 19: Iteration 310: with minibatch training loss = 0.0222 and accuracy of 0.82\n",
      "pred:  [15 34 15 21 15 36 20 31 26 14 16 15 16 14 11 35 31 23 17 14 35 20 28 11\n",
      " 15 23 16 16 34 34 35 21 15 35 34 15 21 16 29 17 23 26 35 23 17 28 16 20\n",
      " 21 34 15 35 35 35 14 32 14 23 31 21 15 15 30 29 35 21 15 31 16 14 31 23\n",
      " 21 16 16 21 35 12 26 22 16 34 36 15 36 15 14 29 13 13 23 26 16 23 17 15\n",
      " 29 13 30 12 14 14 22 13 14 27 16 15 35 30 29 26 28 12 29 36 21 30 30 15\n",
      " 22 15 36 15 29 21 14 15]\n",
      "pred:  [27 16 34 13 29 16 26 16 17 34 31 21 34 27 12 13 17 29 23 15 26 32 36 15\n",
      " 12 26 23 27 26 16 14 31 17 15 31 12 12 35 15 32 34 16 21 29 22 32 13 15\n",
      " 21 15 35 21 27 15 30 35 22 34 24 21 29 21 14 14 16 16 35 15 16 21 26 26\n",
      " 36 36 15 16 12 13 16 23 12 15 26 29 29 27 14 30 12 13 17 17 28 35 11 14\n",
      " 35 28 27 21 23 22 14 17 11 11 35 21 22 16 17 11 29 16 23 34 21 30 22 23\n",
      " 17 14 16 28 21 22 30 35]\n",
      "pred:  [34 22 13 34 13 36 36 14 14 21 30 26 12 29 35 29 16 23 22 23 28 20 35 12\n",
      " 30 34 15 22 29 35 21 29 21 14 13 21 14 29 15 29 23 29 14 16 35 32 35 16\n",
      " 32 13 17 16 14 14 27 36 30 35 34 23 28 16 34 21 17 14 17 15 16 20 35 25\n",
      " 34 35 15 16 35 21 14 29 34 17 35 35 30 22 34 17 18 14 23 17 35 18 12 16\n",
      " 21 35 17 16 14 22 22 36 16 15 34 15 29 29 13 14 16 36 13 22 21 31 31 16\n",
      " 34 21 32 16 15 29 17 32]\n",
      "pred:  [29 22 14 16 14 13 36 17 14 36 18 36 21 14 14 14 14 23 23 27 13 21 14 27\n",
      " 18 17 21 29 15 29 35 15 13 34 16 32 13 22 26 32 20 17 14 30 12 31 26 33\n",
      " 11 13 14 35 30 15 30 29 29 15 23 32 30 11 14 23 21 30 34 15 31 17 21 17\n",
      " 16 15 14 29 12 11 15 26 35 31 16 35 17 16 13 13 30 15 16 20 16 34 23 11\n",
      " 21 16 29 13 21 15 15 16 14 11 12 17 16 30 35 26 24 32 29 14 32 15 15 26\n",
      " 15 17 23 32 35 26 30 14]\n",
      "pred:  [21 11 31 27 15 31 35 34 29 35 23 17 35 17 30 35 16 28 18 15 12 17 12 30\n",
      " 30 35 17 13 15 17 16 15 13 35 24 14 28 31 29 16 23 15 32 32 22 35 17 35\n",
      " 13 17 29 21 34 23 14 30 15 16 21 22 17 23 26 35 21 31 22 20 21 36 34 16\n",
      " 13 21 20 14 14 32 35 17 14 29 29 17 16 13 13 17 31 14 13 13 16 29 20 17\n",
      " 15 21 16 26 16 23 26 14 16 11 22 35 34 16 15 15 35 32 16 23 17 15 16 12\n",
      " 31 14 29 13 16 14 32 17]\n",
      "Epoch 19: Iteration 315: with minibatch training loss = 0.0166 and accuracy of 0.88\n",
      "pred:  [27 35 33 13 17 14 34 29 17 15 23 35 14 15 15 17 15 22 35 12 15 15 23 21\n",
      " 15 14 36 16 26 12 34 29 35 21 14 35 22 35 31 26 23 15 22 14 17 16 16 16\n",
      " 35 12 27 22 14 15 13 28 21 30 17 13 35 17 23 14 15 21 14 15 21 16 11 14\n",
      " 23 26 17 16 16 21 14 16 14 13 15 29 14 30 27 21 16 34 26 16 16 14 12 30\n",
      " 14 16 29 22 30 28 14 11 34 21 35 22 35 20 15 16 32 23 16 15 30 11 26 20\n",
      " 31 11 15 15 21 22 30 29]\n",
      "pred:  [13 35 14 12 21 35 15 15 15 15 18 32 16 14 34 13 12 16 31 17 35 30 23 16\n",
      " 20 17 20 17 14 17 21 21 21 14 16 26 36 20 14 23 35 14 14 31 14 29 31 24\n",
      " 13 15 17 18 29 15 14 21 27 21 21 15 16 23 17 31 17 17 12 21 34 16 17 26\n",
      " 33 16 28 16 16 14 31 15 35 13 16 35 17 34 29 21 15 21 13 35 23 29 35 21\n",
      " 17 21 15 34 26 16 14 26 35 18 14 16 22 16 15 13 35 29 26 14 13 31 27 29\n",
      " 17 23 35 35 21 14 15 30]\n",
      "pred:  [14 29 33 14 30 29 30 13 30 22 22 23 15 17 13 12 21 15 32 15 34 33 18 29\n",
      " 14 31 15 17 30 17 35 16 21 15 21 30 15 25 14 11 31 23 32 21 15 16 26 32\n",
      " 32 23 17 22 29 23 14 17 14 12 21 15 31 29 16 15 21 36 26 13 21 21 15 31\n",
      " 34 15 21 17 23 15 27 14 14 20 14 14 16 13 12 34 21 14 34 29 26 20 26 13\n",
      " 20 27 32 14 16 16 15 17 16 22 23 23 16 26 26 16 35 14 36 11 23 11 26 16\n",
      " 27 17 21 12 29 31 16 20]\n",
      "pred:  [15 14 22 21 21 31 21 14 29 21 23 11 14 35 16 16 15 16 17 21 21 26 21 14\n",
      " 36 17 27 22 21 15 16 14 14 23 23 20 26 15 26 15 17 20 17 26 35 25 30 21\n",
      " 15 29 14 15 14 13 13 35 21 21 15 12 26 14 21 14 23 21 29 14 15 29 27 14\n",
      " 26 27 26 16 15 18 34 27]\n",
      "Epoch 20 Overall loss = 0.0181 and accuracy of 0.86\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.018095606744289398, 0.86)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver.save(sess, './training_data/stixelnet_model.ckpt')\n",
    "print('Training')\n",
    "run_model(session=sess, predict=y_out, loss_val=mean_loss, Xd=X_train, yd=y_train, \n",
    "          epochs=20, batch_size=128, print_every=5, training=train_step)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      "pred:  [27 30 21 27 27 30 12 22 22 12 36 11 27 29 22 12 31 30 25 21 23 16 30 11\n",
      " 15 15 11 17 16 30 22 34 15 31 22 11 33 16 27 27 22 31 14 15 22 32 34 31\n",
      " 29 15 15 12 30 15 32 11 30 35 16 35 23 29 22 30 20 27 11 12 11 15 35 30\n",
      " 21 27 22 29 21 12 32 20 32 21 32 27 30 11 20 33 26 12 35 14 35 33 12 35\n",
      " 29 26 35 35 36 35 30 21 11 36 15 27 26 22 35 30 23 22 30 30 15 20 26 12\n",
      " 26 34 29 29 22 30 35 26]\n",
      "pred:  [34 15 35 30 30 15 35 12 21 25 29 36 30 29 12 27 16 36 29 35 23 35 27 12\n",
      " 22 11 32 22 15 27 35 12 12 21 27 22 23 27 35 29 30 32 27 29 17 29 35 12\n",
      " 31 35 11 33 27 30 22 29 35 34 30 21 33 32 35 16 27 11 29 35 35 30 30 15\n",
      " 27 20 29 35 27 26 20 35 21 21 35 29 29 27 35 15 35 35 14 29 15 11 20 15\n",
      " 23 30 31 35 21 35 12 15 35 35 26 12 31 35 15 27 12 30 29 29 29 30 15 26\n",
      " 27 34 15 12 27 23 15 12]\n",
      "pred:  [23 30 31 27 29 22 15 15 21 30 23 35 27 27 30 35 35 35 15 17 34 11 33 15\n",
      " 16 23 22 13 35 23 16 15 32 22 35 27 27 22 35 15 27 20 35 26 33 13 29 12\n",
      " 12 27 21 36 22 15 12 35 35 29 30 29 15 11 22 29 22 22 30 27 30 31 22 33\n",
      " 36 35 22 12 15 33 35 36 14 26 35 27 26 15 33 26 35 29 22 29 15 15 27 25\n",
      " 35 35 35 15 22 35 34 29 34 30 12 35 13 22 11 35 35 34 29 15 27 15 35 29\n",
      " 15 15 12 34 32 15 11 12]\n",
      "pred:  [32 29 30 11 22 15 12 11 36 12 27 11 29 35 29 35 23 27 27 22 32 13 11 15\n",
      " 35 12 30 11 29 29 22 35 35 17 22 15 32 21 31 34 23 35 32 29 29 35 34 35\n",
      " 15 25 27 35 15 35 15 12 12 29 29 29 33 30 15 15 23 21 20 27 29 33 15 35\n",
      " 22 32 27 35 15 23 26 15 15 30 15 16 29 33 33 30 21 29 22 26 31 23 11 23\n",
      " 12 31 35 21 23 22 34 25 27 27 36 35 30 29 36 20 35 23 30 22]\n",
      "Epoch 1 Overall loss = 0.198 and accuracy of 0.088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.19800741314888, 0.088)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Validation')\n",
    "run_model(session=sess, predict=y_out, loss_val=mean_loss, Xd=X_val, yd=y_val, \n",
    "          epochs=1, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from preprocessing.preprocess_func_v02_new import *\n",
    "#preprocess_filtering_data(date='2011_09_26', serieses = [5], dir_path='/home/shahar_zuler/ProjectNexar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation2\n",
      "pred:  [21 32 25 31 31 30 30 30 20 31 30 21 30 21 20 20 20 30 21 21 21 20 31 21\n",
      " 31 30 21 26 21 21 20 21 21 20 26 20 20 21 31 31 21 20 21 30 21 21 20 21\n",
      " 31 32 30 36 21 31 30 30 31 30 31 21 21 36 14 21 30 30 31 21 31 21 14 31\n",
      " 26 21 20 20 31 14 32 21 30 20 21 20 22 31 36 21 17 30 20 26 31 36 30 30\n",
      " 31 21 31 21 16 30 30 36 26 31 31 20 21 31 21 20 34 20 20 26 21 36 30 31\n",
      " 21 20 11 21 26 30 26 30]\n",
      "pred:  [36 21 30 25 30 31 31 21 21 20 30 30 20 30 26 21 18 20 21 21 31 21 31 18\n",
      " 31 30 30 31 20 21 20 30 30 31 26 31 31 34 36 26 31 21 20 30 21 14 36 20\n",
      " 21 20 20 20 21 36 21 21 31 30 21 21 30 20 21 21 14 31 21 26 30 30 20 21\n",
      " 17 21 21 30 21 26 14 21 30 21 21 20 31 32 21 32 21 31 21 26 21 21 30 20\n",
      " 21 31 30 20 30 31 31 21 30 30 30 21 20 30 21 30 26 31 20 20 20 31 31 30\n",
      " 21 20 34 20 36 20 31 30]\n",
      "pred:  [21 30 21 20 21 25 20 36 32 30 21 30 20 30 20 21 21 31 31 21 30 36 20 21\n",
      " 21 20 36 21 21 31 21 20 30 31 20 20 31 21 36 20 31 21 30 20 30 21 20 21\n",
      " 21 25 31 26 30 21 31 30 20 31 21 17 22 36 30 18 26 31 20 21 30 21 21 21\n",
      " 20 20 21 31 21 31 36 20 21 30 26 21 21 36 31 31 32 26 31 31 34 31 14 21\n",
      " 26 31 21 31 20 21 30 30 31 30 31 20 31 31 21 21 21 30 21 14 20 14 20 31\n",
      " 21 30 31 20 30 30 26 21]\n",
      "pred:  [30 30 26 21 21 20 13 30 20 20 36 21 31 21 36 20 30 31 36 21 17 21 21 31\n",
      " 31 20 26 21 21 18 20 32 30 31 36 21 30 30 26 21 31 30 26 21 21 31 21 21\n",
      " 25 21 31 21 36 31 31 20 31 26 32 21 21 30 30 26 20 30 30 26 34 36 30 21\n",
      " 31 20 31 30 21 31 21 31 17 30 21 21 21 20 31 30 20 30 20 26 32 26 31 21\n",
      " 20 21 30 31 30 30 20 31 21 14 21 20 21 21 31 30 34 36 36 31 20 20 21 31\n",
      " 20 30 21 30 36 30 31 21]\n",
      "pred:  [36 31 31 21 30 20 21 31 26 14 18 20 21 21 21 26 20 31 20 26 31 20 31 21\n",
      " 36 31 20 30 20 20 26 31 21 30 26 21 30 31 34 20 30 30 26 14 31 30 21 20\n",
      " 13 32 21 31 14 31 30 21 21 36 21 30 14 20 36 21 11 20 21 26 36 21 30 31\n",
      " 21 30 21 20 30 14 20 21 30 30 21 30 30 31 14 20 20 20 26 20 22 14 20 31\n",
      " 31 34 20 30 32 31 21 25 25 26 21 30 21 21 20 21 31 26 20 21 30 21 31 21\n",
      " 31 36 14 26 14 36 36 30]\n",
      "pred:  [16 34 21 30 20 20 20 30 26 31 20 20 30 21 17 20 32 21 26 21 30 25 31 17\n",
      " 31 31 22 21 30 31 31 21 31 31 30 20 21 31 16 26 20 30 31 26 34 20 21 20\n",
      " 21 25 30 16 30 13 30 21 21 31 30 20 21 30 20 21 26 26 21 31 30 36 14 17\n",
      " 20 21 31 26 21 31 20 14 30 31 21 21 21 14 21 21 17 21 30 21 30 31 20 31\n",
      " 30 30 26 21 31 20 20 32 21 30 31 20 20 21 31 31 21 21 34 36 31 26 31 31\n",
      " 21 21 21 20 21 20 21 31]\n",
      "pred:  [26 22 32 21 31 20 26 30 17 30 21 20 30 26 20 30 30 21 20 30 20 31 21 30\n",
      " 21 14 20 20 30 30 20 20 31 20 31 21 26 31 21 17 21 20 20 31 30 30 17 21\n",
      " 30 21 31 21 20 26 17 36 17 20 20 16 34 20 21 21 20 34 26 26 31 31 31 21\n",
      " 21 31 20 20 31 26 30 20 21 21 21 26 31 36 32 36 14 31 21 31 21 20 20 17\n",
      " 31 31 30 21 21 20 16 26 26 26 31 25 36 31 30 36 30 31 31 30 21 20 21 21\n",
      " 20 21 20 21 21 14 20 21]\n",
      "pred:  [20 21 20 21 26 34 31 21 20 21 21 21 31 30 21 21 30 21 21 14 21 21 30 30\n",
      " 20 36 30 11 31 20 31 21 30 20 17 26 30 30 26 32 17 31 31 30 31 20 31 31\n",
      " 21 21 20 21 30 31 34 20 20 21 21 21 21 21 31 21 20 31 31 31 31 31 31 30\n",
      " 31 36 26 20 30 26 30 25 32 31 21 21 30 30 21 20 36 30 31 26 30 20 21 31\n",
      " 30 21 21 11 21 30 30 30 21 21 21 30 31 21 21 20 30 31 31 20 32 20 21 21\n",
      " 26 36 25 14 31 31 30 14]\n",
      "pred:  [21 20 20 21 32 31 21 14 21 20 36 21 21 21 30 25 30 14 21 36 30 31 31 16\n",
      " 20 21 26 34 30 17 14 31 32 21 21 30 21 30 26 30 21 21 25 14 31 30 14 26\n",
      " 30 21 20 31 21 31 21 20 21 21 36 21 20 26 20 21 31 20 21 30 21 30 31 33\n",
      " 30 31 21 17 20 31 20 20 26 21 36 21 30 21 34 21 20 21 31 21 20 32 30 31\n",
      " 31 21 32 36 17 31 21 21 20 16 21 11 31 31 30 30 31 30 30 31 21 21 30 31\n",
      " 30 21 31 17 34 26 21 11]\n",
      "pred:  [30 20 31 30 32 31 30 14 17 26 20 31 20 36 30 20 31 15 18 20 21 21 30 26\n",
      " 21 31 20 31 26 36 31 30 21 30 21 31 20 30 32 31 21 26 13 30 21 31 21 21\n",
      " 11 20 21 30 16 25 30 30 30 21 31 20 21 21 31 30 21 31 30 26 36 30 31 16\n",
      " 31 21 21 36 31 25 30 21 31 21 21 21 21 31 17 20 17 31 21 21 31 20 21 11\n",
      " 36 20 31 20 30 30 21 21 20 31 21 31 21 31 31 31 21 30 36 30 21 25 31 20\n",
      " 21 31 31 31 21 20 30 30]\n",
      "pred:  [30 30 21 30 20 32 20 20 31 31 21 30 30 36 32 21 21 20 36 20 21 21 30 26\n",
      " 31 30 31 20 31 31 20 21 20 34 31 21 21 13 31 30 21 26 31 18 31 30 21 31\n",
      " 21 31 20 21 30 30 20 30 36 31 21 21 31 32 31 21 21 31 21 31 21 30 31 21\n",
      " 30 16 20 36 21 26 21 20 30 20 20 21 31 22 20 21 30 20 30 36 21 31 14 16\n",
      " 30 30 31 21 25 20 21 31 21 20 21 21 30 30 31 26 34 30 30 21 20 21 31 31\n",
      " 21 21 26 30 30 30 20 21]\n",
      "pred:  [16 26 31 21 20 20 20 31 20 21 14 31 26 31 30 30 21 21 31 31 31 34 20 26\n",
      " 30 21 30 30 14 30 31 21 17 30 17 17 31 30 26 31 36 26 31 31 25 36 31 36\n",
      " 21 36 31 20 20 17 26 21 31 36 30 20 21 20 31 30 21 30 21 20 31 20 21 20\n",
      " 20 20 30 21 21 31 31 16 21 36 21 26 16 31 21 21 21 18 20 26 21 21 30 30\n",
      " 30 20 21 34 30 31 21 18 20 21 21 34 30 21 31 30 20 31 31 36 14 20 31 21\n",
      " 21 30 17 21 21 31 34 20]\n",
      "pred:  [30 30 21 21 13 21 31 25 31 20 17 14 21 34 20 30 30 21 31 21 21 21 21 30\n",
      " 32 31 21 21 26 25 18 14 36 31 21 30 21 31 20 21 20 14 11 30 30 20 31 21\n",
      " 31 36 31 31 21 30 30 31 26 20 21 30 21 31 31 30 21 20 30 31 26 21 20 21\n",
      " 21 14 20 20 21 31 31 36 31 36 21 20 20 34 30 20 31 21 30 21 21 36 31 21\n",
      " 31 32 30 32 30 30 17 20 21 36 30 21 30 31 31 31 30 31 30 21 31 26 30 30\n",
      " 21 31 30 31 30 13 20 32]\n",
      "pred:  [32 30 31 21 30 14 20 30 25 20 20 36 31 21 20 31 20 31 26 30 31 31 30 31\n",
      " 31 32 21 26 20 20 31 30 31 21 21 26 21 21 31 34 21 36 20 21 31 20 36 20\n",
      " 30 30 36 31 30 21 21 31 26 21 25 17 20 31 31 30 31 26 30 21 30 31 31 17\n",
      " 20 30 31 34 30 31 30 21 31 36 31 21 31 21 21 30 21 30 30 20 31 31 21 30\n",
      " 20 31 21 20 30 26 17 14 21 31 14 30 20 30 14 18 31 21 21 21 26 16 21 21\n",
      " 30 21 25 30 30 21 21 20]\n",
      "pred:  [32 14 21 14 30 16 34 20 17 32 20 13 21 30 21 21 21 21 31 20 26 21 36 26\n",
      " 30 26 30 30 17 20 20 20 21 14 21 21 30 30 26 26 17 21 30 20 21 16 17 20\n",
      " 34 30 21 21 21 21 21 30 21 20 30 13 30 20 21 30 20 30 26 36 21 21 21 21\n",
      " 30 36 30 31 21 20 36 30 20 31 30 21 31 34 30 21 20 26 36 21 26 31 36 30\n",
      " 36 30 20 20 21 21 36 21 31 31 20 31 31 31 31 36 11 31 20 31 31 13 17 26\n",
      " 31 30 21 20 31 30 31 11]\n",
      "pred:  [16 17 17 21 31 20 30 31 21 36 20 20 30 31 26 20 31 14 21 20 36 30 21 30\n",
      " 21 31 30 18 17 21 20 21 21 21 31 31 31 20 21 31 36 31 26 26 26 21 31 31\n",
      " 20 30 20 21 30 31 26 14 31 20 21 21 31 26 21 30 31 17 21 31 25 30 31 20\n",
      " 20 30 21 36 31 20 20 31 21 20 20 20 32 20 30 21 30 21 20 26 14 21 20 30\n",
      " 20 31 30 17 26 30 21 21 20 31 20 25 26 30 20 20 30 26 22 20 31 30 32 18\n",
      " 31 31 20 21 34 30 30 21]\n",
      "pred:  [31 36 30 31 26 20 31 21 21 31 20 25 21 36 26 36 30 36 21 30 30 20 30 31\n",
      " 21 18 20 32 36 30 21 25 30 31 25 21 20 21 16 31 30 31 34 30 20 20 17 30\n",
      " 31 30 31 30 30 11 21 13 30 26 21 20 13 31 20 21 32 16 21 26 31 34 31 31\n",
      " 30 30 14 31 26 30 21 31 17 20 25 26 20 20 36 30 31 34 26 20 31 31 21 21\n",
      " 34 21 30 14 31 26 36 14 21 25 21 20 26 31 21 36 30 36 30 31 30 30 36 31\n",
      " 20 31 20 31 30 31 31 30]\n",
      "pred:  [31 25 31 31 21 21 30 31 26 20 21 17 31 31 21 32 32 14 20 31 21 21 21 21\n",
      " 20 31 36 36 20 21 20 20 32 30 26 21 31 31 34 30 31 21 30 30 21 21 25 20\n",
      " 21 30 32 21 34 21 36 30 36 36 36 20 20 30 21 21 31 31 16 30 30 30 21 31\n",
      " 31 16 31 30 20 26 21 21 30 31 21 31 31 30 21 36 30 21 21 30 36 22 31 21\n",
      " 30 31 30 30 26 20 31 31 30 21 36 31 30 31 36 36 31 20 31 21 21 20 21 34\n",
      " 30 20 21 30 20 31 31 20]\n",
      "pred:  [30 21 30 21 20 36 25 20 31 31 31 26 31 20 26 26 30 32 11 34 21 30 36 30\n",
      " 30 30 21 30 21 30 31 17 20 30 31 31 31 31 30 20 31 21 20 20 21 21 31 30\n",
      " 36 31 13 21 30 32 26 13 36 30 20 30 36 21 31 21 21 30 34 30 32 36 20 30\n",
      " 21 20 20 30 21 21 31 30 21 21 31 22 11 26 21 20 30 31 31 26 31 31 14 26\n",
      " 21 30 36 30 21 21 30 14 36 31 20 26 30 21 26 20 34 31 26 32 20 30 20 30\n",
      " 31 26 30 30 20 31 36 30]\n",
      "pred:  [21 20 20 36 21 30 30 20 17 20 26 21 21 30 20 31 30 20 21 30 31 31 31 31\n",
      " 30 21 26 20 20 21 26 21 31 20 21 31 31 31 36 20 31 31 21 20 30 30 26 20\n",
      " 21 21 21 34 33 32 20 20 21 25 21 21 21 31 34 32 20 36 21 20 20 21 21]\n",
      "Epoch 1 Overall loss = 0.13 and accuracy of 0.169\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.1295195860811295, 0.1685976827806632)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Validation2')\n",
    "X5 = np.load('X_train_5.npy')\n",
    "y5 = np.load('y_train_5.npy')\n",
    "run_model(session=sess, predict=y_out, loss_val=mean_loss, Xd=X5, yd=y5, \n",
    "          epochs=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
