{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10376550926337413516\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 145227776\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 17768915914651481093\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "from preprocess_func_new import *\n",
    "from matplotlib.image import imread\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../datasets/stixels'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path = os.path.join('..','datasets','stixels')\n",
    "img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "tfrec_train_directory = os.path.join('..','datasets','stixels','train','tfrec_batch_size_'+str(batch_size))\n",
    "if os.path.exists(tfrec_train_directory):\n",
    "    print('WARNIING: dir '+tfrec_train_directory+ ' already exists!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(tfrec_train_directory):\n",
    "    os.makedirs(tfrec_train_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_no_obstacles_stixels(labels_df, percent = 2):\n",
    "    random.seed(481)\n",
    "    num_stx_with_obst = len(labels_df.index[labels_df['Label'] != 46].tolist())    \n",
    "    no_obst_train_idx = labels_df.index[labels_df['Label'] == 46].tolist()\n",
    "    use_idx = random.sample(no_obst_train_idx, int(num_stx_with_obst*percent/100))\n",
    "    for idx in use_idx:\n",
    "        labels_df.at[idx, 'Use_stixel'] = 1\n",
    "    return labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#merging all TEST csv files, keeping ALL precent of \"no obstical\"\n",
    "labels_test = []\n",
    "for root, dirs, files in os.walk(os.path.join(img_path,'test')):\n",
    "    for file in files:\n",
    "        if '.csv' in file and not 'labels_test.csv' in file:\n",
    "            tmp=pd.read_csv(os.path.join(img_path,'test',file))\n",
    "            if(tmp.isnull().values.any()):\n",
    "                print('Nan in ',file)\n",
    "            if len(labels_test)==0:\n",
    "                labels_test = tmp\n",
    "            else:\n",
    "                labels_test = labels_test.append(tmp, ignore_index=True)\n",
    "                \n",
    "labels_test = add_no_obstacles_stixels(labels_df=labels_test, percent = 100) #we took all the stixels, 100%!!\n",
    "labels_test = labels_test[labels_test['Use_stixel'] == 1]\n",
    "labels_test = labels_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: dir ../datasets/stixels/test/sum_csv already exists\n"
     ]
    }
   ],
   "source": [
    "sum_csv_test_path = os.path.join(img_path,'test', 'sum_csv')\n",
    "if not os.path.exists(sum_csv_test_path):\n",
    "    os.makedirs(sum_csv_test_path)\n",
    "    print('new dir created: ')\n",
    "    print(sum_csv_test_path)\n",
    "else:\n",
    "    print('WARNING: dir '+ sum_csv_test_path +' already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_test.to_csv( os.path.join(sum_csv_test_path,'labels_test_b16.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#merging all VAL csv files, keeping only 10 precent of \"no obstical\"\n",
    "\n",
    "labels_val = []\n",
    "for root, dirs, files in os.walk(os.path.join(img_path,'val')):\n",
    "    for file in files:\n",
    "        if '.csv' in file and not 'labels_val.csv' in file:\n",
    "            tmp=pd.read_csv(os.path.join(img_path,'val',file))\n",
    "            if(tmp.isnull().values.any()):\n",
    "                print('Nan in ',file)\n",
    "            if len(labels_val)==0:\n",
    "                labels_val = tmp\n",
    "            else:\n",
    "                labels_val = labels_val.append(tmp, ignore_index=True)\n",
    "                \n",
    "labels_val = add_no_obstacles_stixels(labels_df=labels_val, percent = 2)\n",
    "labels_val = labels_val[labels_val['Use_stixel'] == 1]\n",
    "labels_val = labels_val.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: dir ../datasets/stixels/val/sum_csv already exists\n"
     ]
    }
   ],
   "source": [
    "sum_csv_val_path = os.path.join(img_path,'val', 'sum_csv')\n",
    "if not os.path.exists(sum_csv_val_path):\n",
    "    os.makedirs(sum_csv_val_path)\n",
    "    print('new dir created: ')\n",
    "    print(sum_csv_val_path)\n",
    "else:\n",
    "    print('WARNING: dir '+ sum_csv_val_path +' already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_val.to_csv( os.path.join(sum_csv_val_path,'labels_val_b16.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels_train = []\n",
    "for root, dirs, files in os.walk(os.path.join(img_path,'train')):\n",
    "    for file in files:\n",
    "        if '.csv' in file and not 'labels_train.csv' in file:\n",
    "            tmp=pd.read_csv(os.path.join(img_path,'train',file))\n",
    "            if(tmp.isnull().values.any()):\n",
    "                print('Nan in ',file)\n",
    "            if len(labels_train)==0:\n",
    "                labels_train = tmp\n",
    "            else:\n",
    "                labels_train = labels_train.append(tmp, ignore_index=True)\n",
    "                \n",
    "labels_train = add_no_obstacles_stixels(labels_df=labels_train, percent = 2)\n",
    "labels_train = labels_train[labels_train['Use_stixel'] == 1]\n",
    "labels_train = labels_train.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum_csv_path = os.path.join(img_path,'train', 'sum_csv')\n",
    "if not os.path.exists(sum_csv_path):\n",
    "    os.makedirs(sum_csv_path)\n",
    "    print('new dir created: ')\n",
    "    print(sum_csv_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_train.to_csv(os.path.join(sum_csv_path,'labels_train_b16.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train=pd.read_csv(os.path.join(sum_csv_path,'labels_train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs=list(range(len(labels_train)))\n",
    "random.seed(481)\n",
    "random.shuffle(idxs) \n",
    "\n",
    "batches_idx = [idxs[x:x+batch_size] for x in range(0, len(idxs), batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_progress(count, total):\n",
    "    # Percentage completion.\n",
    "    pct_complete = float(count) / total\n",
    "\n",
    "    # Status-message.\n",
    "    # Note the \\r which means the line should overwrite itself.\n",
    "    msg = \"\\r- Progress: {0:.1%}\".format(pct_complete)\n",
    "\n",
    "    # Print it.\n",
    "    sys.stdout.write(msg)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wrap_int64(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wrap_bytes(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert(image_paths, labels, out_path):\n",
    "    # Args:\n",
    "    # image_paths   List of file-paths for the images.\n",
    "    # labels        Class-labels for the images.\n",
    "    # out_path      File-path for the TFRecords output file.\n",
    "    \n",
    "    #print('')\n",
    "    #print(\"Converting: \" + out_path)\n",
    "    \n",
    "    # Number of images. Used when printing the progress.\n",
    "    num_images = len(image_paths)\n",
    "    \n",
    "    # Open a TFRecordWriter for the output-file.\n",
    "    with tf.python_io.TFRecordWriter(out_path) as writer:\n",
    "        \n",
    "        # Iterate over all the image-paths and class-labels.\n",
    "        for i, (path, label) in enumerate(zip(image_paths, labels)):\n",
    "            # Print the percentage-progress.\n",
    "            #######print_progress(count=i, total=num_images-1)\n",
    "            \n",
    "            with open(path, 'rb') as f:\n",
    "                img_raw = f.read()\n",
    "           \n",
    "            # Create a dict with the data we want to save in the\n",
    "            # TFRecords file. You can add more relevant data here.\n",
    "            data = \\\n",
    "                {\n",
    "                    'image': wrap_bytes(img_raw),\n",
    "                    'label': wrap_int64(label)\n",
    "                } \n",
    "\n",
    "            # Wrap the data as TensorFlow Features.\n",
    "            feature = tf.train.Features(feature=data)\n",
    "\n",
    "            # Wrap again as a TensorFlow Example.\n",
    "            example = tf.train.Example(features=feature)\n",
    "\n",
    "            # Serialize the data.\n",
    "            serialized = example.SerializeToString()\n",
    "            \n",
    "            # Write the serialized data to the TFRecords file.\n",
    "            writer.write(serialized)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in batches_idx:\n",
    "    batch_labels=labels_train.loc[batch]\n",
    "    batch_names_list=list(batch_labels['Name'])\n",
    "    batch_labels=np.array(batch_labels['Label'])\n",
    "    batch_image_paths_train=[]\n",
    "    for name in batch_names_list:\n",
    "        batch_image_paths_train.append(os.path.join(img_path, 'train', str(name)+'.png')) \n",
    "    batch_path_tfrecords_train = os.path.join(tfrec_train_directory, \"train\"+str(batch[0]).zfill(6)+\".tfrecords\") \n",
    "    convert(image_paths=batch_image_paths_train,\n",
    "        labels=batch_labels,\n",
    "        out_path=batch_path_tfrecords_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#VAL: make batches of different sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run this cell only if sum_scv already exists:\n",
    "labels_val=pd.read_csv(os.path.join(sum_csv_val_path,'labels_val.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_batch_size = batch_size\n",
    "test_batch_size = batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idxs=list(range(len(labels_val)))\n",
    "val_batches_idx = [val_idxs[x:x+val_batch_size] for x in range(0, len(val_idxs), val_batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrec_val_directory = os.path.join('..','datasets','stixels','val','tfrec_batch_size_'+str(val_batch_size))\n",
    "if os.path.exists(tfrec_val_directory):\n",
    "    print('WARNIING: dir '+tfrec_val_directory+ ' already exists!')\n",
    "if not os.path.exists(tfrec_val_directory):\n",
    "    os.makedirs(tfrec_val_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for batch in val_batches_idx:\n",
    "    val_batch_labels=labels_val.loc[batch]\n",
    "    val_batch_names_list=list(val_batch_labels['Name'])\n",
    "    val_batch_labels=np.array(val_batch_labels['Label'])\n",
    "    batch_image_paths_val=[]\n",
    "    for name in val_batch_names_list:\n",
    "        batch_image_paths_val.append(os.path.join(img_path, 'val', str(name)+'.png')) \n",
    "    batch_path_tfrecords_val = os.path.join(tfrec_val_directory, \"val\"+str(batch[0]).zfill(6)+\".tfrecords\") \n",
    "    convert(image_paths=batch_image_paths_val,\n",
    "        labels=val_batch_labels,\n",
    "        out_path=batch_path_tfrecords_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #THIS CELL IS ONLY FOR TFRECS WITH NO BATCHES:\n",
    "# val_names_list=list(labels_val['Name'])\n",
    "# val_labels=np.array(labels_val['Label'])\n",
    "# image_paths_val=[]\n",
    "# for name in val_names_list:\n",
    "#     image_paths_val.append(os.path.join(img_path, 'val', name + '.png')) \n",
    "# path_tfrecords_val = os.path.join(tfrec_val_directory, \"val.tfrecords\")\n",
    "\n",
    "# convert(image_paths=image_paths_val,\n",
    "#         labels=val_labels,\n",
    "#         out_path=path_tfrecords_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TEST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run this cell only if sum_scv already exists:\n",
    "labels_test=pd.read_csv(os.path.join(sum_csv_test_path,'labels_test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_idxs=list(range(len(labels_test)))\n",
    "test_batches_idx = [test_idxs[x:x+test_batch_size] for x in range(0, len(test_idxs), test_batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfrec_test_directory = os.path.join('..','datasets','stixels','test','tfrec_batch_size_'+str(test_batch_size))\n",
    "if os.path.exists(tfrec_test_directory):\n",
    "    print('WARNIING: dir '+tfrec_test_directory+ ' already exists!')\n",
    "if not os.path.exists(tfrec_test_directory):\n",
    "    os.makedirs(tfrec_test_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for batch in test_batches_idx:\n",
    "    test_batch_labels=labels_test.loc[batch]\n",
    "    test_batch_names_list=list(test_batch_labels['Name'])\n",
    "    test_batch_labels=np.array(test_batch_labels['Label'])\n",
    "    batch_image_paths_test=[]\n",
    "    for name in test_batch_names_list:\n",
    "        batch_image_paths_test.append(os.path.join(img_path, 'test', str(name)+'.png')) \n",
    "    batch_path_tfrecords_test = os.path.join(tfrec_test_directory, \"test\"+str(batch[0]).zfill(6)+\".tfrecords\") \n",
    "    convert(image_paths=batch_image_paths_test,\n",
    "        labels=test_batch_labels,\n",
    "        out_path=batch_path_tfrecords_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #THIS CELL IS ONLY FOR TFRECS WITH NO BATCHES:\n",
    "# test_names_list=list(labels_test['Name'])\n",
    "# test_labels=np.array(labels_test['Label'])\n",
    "# image_paths_test=[]\n",
    "# for name in test_names_list:\n",
    "#     image_paths_test.append(os.path.join(img_path, 'test', name+'.png')) \n",
    "# path_tfrecords_test = os.path.join(tfrec_test_directory, \"test.tfrecords\")\n",
    "# convert(image_paths=image_paths_test,\n",
    "#         labels=test_labels,\n",
    "#         out_path=path_tfrecords_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
